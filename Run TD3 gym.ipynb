{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f4ebec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c46327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Hacky fix to import from parent directory\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "path_to_project = path_to_this_notebook[:path_to_this_notebook.find('note')]\n",
    "sys.path.append(path_to_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e372283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.td3_code.agents.td3 import TD3Agent\n",
    "from src.td3_code.memory.trajectory_replay_buffer import TrajectoryMemoryBuffer\n",
    "from src.td3_code.memory.transition_replay_buffer import TransitionMemoryBuffer\n",
    "from src.td3_code.runners.runner import Runner\n",
    "\n",
    "from src.utils.plot_results import plot_results\n",
    "\n",
    "from src.samplers.load_samplers import load_samplers\n",
    "from src.environments.create_env import create_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c51bde",
   "metadata": {},
   "source": [
    "## Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"path_to_data\": \"./data/\",\n",
    "    \"t0_hr\": 6.0,  # When the episode start (default value 6AM)\n",
    "    \"dt_min\": 30,  # Timestep size\n",
    "    \"ev_dt_min\": 60,  # Timestep size for EV arrivals\n",
    "    \"ev_sampling_dt_min\": 60,  # How EV sessions are sampled from the data\n",
    "    \"apply_gaussian_noise\": False,  # Make data noisy\n",
    "    \"ev_utility_coef_mean\": 1,  # Mean value of the utility coefficient for the EVs\n",
    "    \"ev_utility_coef_scale\": 0.13,  # STD of the utility coefficient for the EVs\n",
    "    \"days_per_month_train\": 20,  # Days per month for training\n",
    "    \"ev_session_months_train\": [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "    ],\n",
    "    # Months to sample EV sessions for training\n",
    "    \"grid_to_use\": \"ieee16\",  # What grid topology to use. Now supports only IEEE16.\n",
    "    \"ev_session_months_test\": [\"05\", \"12\"],  # Months to sample EV sessions for test\n",
    "    \"n_ps_pvs\": 4,  # Amount of solar panels that use PecanStreet data\n",
    "    \"n_canopy_pvs\": 0,  # Amount of solar panels that use canopy data\n",
    "    \"canopy_pv_rated_power\": 250,  # Rated power of these panels\n",
    "    \"n_loads\": 0,  # Amount of inflexible loads\n",
    "    \"n_feeders\": 1,  # Amount of feeders\n",
    "    \"n_ev_chargers\": 4,  # Amount of EV chargers\n",
    "    \"ps_pvs_rated_power\": 4,  # Rated power of these panels\n",
    "    \"avg_evs_per_day\": 3.5,  # Scaling of the EV arrival rate\n",
    "    \"feeder_p_min\": -5,  # Capacity of the feeders\n",
    "    \"g\": 4,  # Conductance of each line\n",
    "    \"i_max\": 25,  # Capacity of each line\n",
    "}\n",
    "\n",
    "# all config options that do not effect the samplers, to improve cache hits\n",
    "env_config = {\n",
    "    # New and improved config options\n",
    "    \"environment_type\": \"gym\",\n",
    "    \"use_constraint_projection\": False,\n",
    "    \"use_rescaled_actions\": True,\n",
    "    \"normalize_environment_outputs\": True,\n",
    "    \"default_episode_index\": 6,\n",
    "\n",
    "    \"violations_in_reward\" : False,  # Don't use with EV only\n",
    "    \"one_reward_target\" : False,     # Don't use\n",
    "\n",
    "    \"random_epoch_order\" : True,\n",
    "\n",
    "    \"utility_reward_factor\" : 1e-2, # default 1e-2\n",
    "    \"current_reward_factor\" : 0, # default 1e-4\n",
    "    \"max_current_reward_factor\" : 0, # default 1e-1\n",
    "    \"power_reward_factor\" : 0, # default 1e-4\n",
    "    \"solver_difference_reward_factor\" : 0, # default 1e-2\n",
    "\n",
    "    \"EV_only\" : True, # Switch between a model with EV only outputs\n",
    "    \"predicting_bounds\": True,\n",
    "    \"lossless_solver\" : False, # Requires false for EV only\n",
    "    \"solver_iterations\" : 800,  # more iterations is a better solution but slower\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af5762",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54265e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload samplers, it is necessary to avoid re-loading data each time env is created\n",
    "(ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    " price_sampler, price_metadata, ev_sampler, elaadnl_metadata) = load_samplers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee5d4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = create_env({**config, **env_config}, ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    "                 price_sampler, price_metadata, ev_sampler, elaadnl_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca282843",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.plot_grid(bbox=(0, 0, 500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d93b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dim = env.observation_space.shape[0]\n",
    "action_dim =  env.action_space.shape[0]\n",
    "max_action_value = env.action_space.high[0]\n",
    "scheme = {'observations': env.observation_space.shape, \n",
    "          'observations_next': env.observation_space.shape,\n",
    "          'actions': env.action_space.shape,\n",
    "          'done': (1, ), 'reward': (1, ), 'reset_mask': (1, )}\n",
    "\n",
    "print(scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76234e90",
   "metadata": {},
   "source": [
    "## Configure agent and runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = {\n",
    "    \"nlp_width\": 8,\n",
    "    \"nlp_length\": 4,\n",
    "    \"lstm_width\": 0,\n",
    "    \"lstm_length\": 0,\n",
    "    \"lstm_dims\": [],\n",
    "    \"hidden_dims\": [64, 64],\n",
    "    \"actor_lr\": 1e-4,\n",
    "    \"critic_lr\": 1e-4,\n",
    "    \"discount\": 0.96,\n",
    "    \"tau\": 0.001,\n",
    "    \"policy_noise\": 0.4,\n",
    "    \"min_policy_noise\": 0.1,\n",
    "    \"policy_decay_factor\": 1, # 0.999 is 6% after 1500 epochs ^1500x47\n",
    "    \"noise_clip\": 2,\n",
    "    \"policy_update_freq\": 4,\n",
    "    \"batch_size\": 16,\n",
    "    \"min_size_to_sample\": 10,\n",
    "    \"n_eps\": 1001,\n",
    "    \"test_each\": 50,\n",
    "    \"n_test_episodes\": 10,\n",
    "    \"memory\": \"traj\", # traj, traj_trans, trans. traj seems the most promising\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_runner(config):\n",
    "    memory_traj_trans = TrajectoryMemoryBuffer(scheme=scheme, max_size=int(1e6/200), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                              use_transitions=True, sample_during_episode=True)\n",
    "\n",
    "    memory_trans = TransitionMemoryBuffer(scheme=scheme, max_size=int(1e6), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                          sample_during_episode=True)\n",
    "\n",
    "\n",
    "    memory_traj = TrajectoryMemoryBuffer(scheme=scheme, max_size=int(1e6/200), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                         use_transitions=False, sample_during_episode=False)\n",
    "\n",
    "    agent = TD3Agent(observation_dim, action_dim, 1, config['lstm_dims'], config['hidden_dims'],\n",
    "                     actor_lr=config['actor_lr'], critic_lr=config['critic_lr'],  discount=config['discount'], tau=config['tau'],\n",
    "                     policy_noise=config['policy_noise'], min_policy_noise=config[\"min_policy_noise\"],\n",
    "                     noise_clip=config['noise_clip'], noise_decay=config[\"policy_decay_factor\"],\n",
    "                     policy_update_freq=config['policy_update_freq'])\n",
    "\n",
    "    # Can choose which of the buffers to use by changing the second argument\n",
    "    if agent_config['memory'] == 'traj':\n",
    "        runner = Runner(env, memory_traj, agent, config['default_episode_index'])\n",
    "    elif agent_config['memory'] == 'traj_trans':\n",
    "        runner = Runner(env, memory_traj_trans, agent, config['default_episode_index'])\n",
    "    elif agent_config['memory'] == 'trans':\n",
    "        runner = Runner(env, memory_trans, agent, config['default_episode_index'])\n",
    "\n",
    "    return runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc33d67",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1c54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\", config={**agent_config, **config, **env_config}) as run:\n",
    "        # Recalculate the hidden dims and lstm dims\n",
    "        nlp_width = wandb.config[\"nlp_width\"]\n",
    "        nlp_length = wandb.config[\"nlp_length\"]\n",
    "        lstm_width = wandb.config[\"lstm_width\"]\n",
    "        lstm_length = wandb.config[\"lstm_length\"]\n",
    "        actor_lr = wandb.config[\"actor_lr\"]\n",
    "        dims = {\n",
    "            \"hidden_dims\" : [2**nlp_width for _ in range(nlp_length)],\n",
    "            \"lstm_dims\" : [2**lstm_width for _ in range(lstm_length)],\n",
    "            \"critic_lr\" : actor_lr,\n",
    "        }\n",
    "\n",
    "        wandb.config.update(dims)\n",
    "\n",
    "        wandbconfig = wandb.config\n",
    "        runner = create_runner(wandbconfig)\n",
    "\n",
    "        batch_size = wandbconfig['batch_size']\n",
    "\n",
    "        n_eps = wandbconfig['n_eps']\n",
    "        print_each = 50\n",
    "        test_each = wandbconfig['test_each']\n",
    "        n_test_episodes = wandbconfig['n_test_episodes']\n",
    "\n",
    "        keys_to_print = ['reward']\n",
    "\n",
    "        train_results = defaultdict(list)\n",
    "        test_results = defaultdict(list)\n",
    "\n",
    "        for ep in range(1, n_eps):\n",
    "            episode_results = runner.run(train=True, save_to_memory=True, train_bath_size=batch_size)\n",
    "\n",
    "            for key, val in episode_results.items():\n",
    "                train_results[key].append(val)\n",
    "                wandb.log({f\"train_{key}\": val, \"epoch\":ep})\n",
    "\n",
    "            if ep % print_each == 0:\n",
    "                print('Training episode %d    ' % ep)\n",
    "\n",
    "                for key in keys_to_print:\n",
    "                    print('    %s=%.2f' % (key, np.mean(train_results[key][-print_each:])))\n",
    "\n",
    "                print()\n",
    "\n",
    "            if ep % test_each == 0:\n",
    "                current_test_results = defaultdict(list)\n",
    "\n",
    "                for test_ep in range(n_test_episodes):\n",
    "                    episode_results = runner.run(train=False, save_to_memory=False)\n",
    "\n",
    "                    for key, val in episode_results.items():\n",
    "                        current_test_results[key].append(val)\n",
    "\n",
    "                current_test_results = {key: np.mean(val) for key, val in current_test_results.items()}\n",
    "\n",
    "                for key, val in current_test_results.items():\n",
    "                    test_results[key].append(val)\n",
    "                    wandb.log({f\"test_{key}\": val, \"epoch\":ep})\n",
    "\n",
    "                print('Test run after episode %d:' % ep)\n",
    "\n",
    "                for key in keys_to_print:\n",
    "                    print('    %s=%.2f' % (key, current_test_results[key]))\n",
    "\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a59124",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import warnings\n",
    "# # warnings.filterwarnings('ignore', category=UserWarning) # make the\n",
    "# warnings.filterwarnings('ignore')\n",
    "# logging.getLogger('pyomo.core').setLevel(logging.ERROR)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6dcfb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run a wandb parameter sweep to find the best performing hyperparpameters\n",
    "\n",
    "see https://docs.wandb.ai/guides/sweeps/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05309700",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\" : \"Predicting EV max bound LSTM with loss sweep 1\",\n",
    "  \"method\" : \"bayes\",\n",
    "  \"metric\" : {\n",
    "      \"name\" : \"test_reward\",\n",
    "      \"goal\" : \"maximize\"\n",
    "  },\n",
    "  \"parameters\" : {\n",
    "    \"nlp_width\" : {\n",
    "        \"min\" : 6,\n",
    "        \"max\" : 8,\n",
    "    },\n",
    "    \"nlp_length\" : {\n",
    "        \"min\" : 2,\n",
    "        \"max\" : 5,\n",
    "    },\n",
    "    \"lstm_width\" : {\n",
    "        \"min\" : 6,\n",
    "        \"max\" : 8,\n",
    "    },\n",
    "    \"lstm_length\" : {\n",
    "        \"min\" : 1,\n",
    "        \"max\" : 3,\n",
    "    },\n",
    "    \"policy_update_freq\" : {\n",
    "        \"min\" : 3,\n",
    "        \"max\" : 6,\n",
    "    },\n",
    "    \"actor_lr\" : {\n",
    "        \"min\" : 8e-5,\n",
    "        \"max\" : 4e-3,\n",
    "    },\n",
    "    \"discount\" : {\n",
    "        \"min\" : 0.96,\n",
    "        \"max\" : 0.999,\n",
    "    },\n",
    "    \"tau\" : {\n",
    "        \"min\" : 0.0001,\n",
    "        \"max\" : 0.005,\n",
    "    },\n",
    "    \"policy_noise\": {\n",
    "        \"min\" : 0.3,\n",
    "        \"max\" : 1.0,\n",
    "    },\n",
    "    \"noise_clip\": {\n",
    "        \"min\" : 1.5,\n",
    "        \"max\" : 4.0,\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7f5cf",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "manual_id = \"l9xuut1q\"\n",
    "\n",
    "count = 10 # number of runs to execute\n",
    "wandb.agent(manual_id, function=train, count=count, project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89dffcf",
   "metadata": {},
   "source": [
    "## Plot results locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_results['reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1eec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_results, final_results_list = runner.run(train=False, save_to_memory=False, final=True)\n",
    "\n",
    "print('Reward = %.2f' % episode_results['reward'])\n",
    "plot_results(env, final_results_list, figsize=(12, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428de757",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"constraints_violation\" : wandb.plot.line_series(\n",
    "          xs=list(range(len(env.timesteps_str[:-1]))),\n",
    "          ys=[[res['i_constraints_violation'] for res in final_results_list],\n",
    "          [res['power_flow_constraints_violation'] for res in final_results_list]],\n",
    "          keys=[\"I violation\", \"P violation\"],\n",
    "          title=\"Constraint violations\",\n",
    "          xname=\"Time\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [res['reward'] for res in final_results_list]\n",
    "feeders_price = [res['feeders_power_price'] for res in final_results_list]\n",
    "pvs_price = [res['pvs_power_price'] for res in final_results_list]\n",
    "evs_welfare = [res['evs_social_welfare'] for res in final_results_list]\n",
    "\n",
    "wandb.log({\"objective\" : wandb.plot.line_series(\n",
    "          xs=list(range(len(env.timesteps_str[:-1]))),\n",
    "          ys=[rewards, feeders_price, pvs_price, evs_welfare],\n",
    "          keys=[\"Total reward\", \"Feeders price\", \"PVs price\", \"EVs welfare\"],\n",
    "          title=\"Objective\",\n",
    "          xname=\"Time\")})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad96f5e9cd6d467318bf15c6be1d9bcdfbc0d0800f27162604e062abc89e5b1b"
  },
  "kernelspec": {
   "display_name": "RL-EVCP",
   "language": "python",
   "name": "rl-evcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
