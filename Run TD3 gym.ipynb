{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f4ebec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c46327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "152a8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Hacky fix to import from parent directory\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "path_to_project = path_to_this_notebook[:path_to_this_notebook.find('note')]\n",
    "sys.path.append(path_to_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e372283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.td3_code.agents.td3 import TD3Agent\n",
    "from src.td3_code.memory.trajectory_replay_buffer import TrajectoryMemoryBuffer\n",
    "from src.td3_code.memory.transition_replay_buffer import TransitionMemoryBuffer\n",
    "from src.td3_code.runners.runner import Runner\n",
    "\n",
    "from src.utils.plot_results import plot_results\n",
    "\n",
    "from src.samplers.load_samplers import load_samplers\n",
    "from src.environments.create_env import create_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d0159",
   "metadata": {},
   "source": [
    "## Weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298c65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb.init(project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c51bde",
   "metadata": {},
   "source": [
    "## Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"path_to_data\": \"./data/\",\n",
    "    \"t0_hr\": 6.0,  # When the episode start (default value 6AM)\n",
    "    \"dt_min\": 30,  # Timestep size\n",
    "    \"ev_dt_min\": 60,  # Timestep size for EV arrivals\n",
    "    \"ev_sampling_dt_min\": 60,  # How EV sessions are sampled from the data\n",
    "    \"apply_gaussian_noise\": False,  # Make data noisy\n",
    "    \"ev_utility_coef_mean\": 1,  # Mean value of the utility coefficient for the EVs\n",
    "    \"ev_utility_coef_scale\": 0.13,  # STD of the utility coefficient for the EVs\n",
    "    \"days_per_month_train\": 20,  # Days per month for training\n",
    "    \"ev_session_months_train\": [\n",
    "        \"01\",\n",
    "        # \"02\",\n",
    "        # \"03\",\n",
    "        # \"04\",\n",
    "        # \"06\",\n",
    "        # \"07\",\n",
    "        # \"08\",\n",
    "        # \"09\",\n",
    "        # \"10\",\n",
    "        # \"11\",\n",
    "    ],\n",
    "    # Months to sample EV sessions for training\n",
    "    \"grid_to_use\": \"ieee16\",  # What grid topology to use. Now supports only IEEE16.\n",
    "    \"ev_session_months_test\": [\"05\", \"12\"],  # Months to sample EV sessions for test\n",
    "    \"n_ps_pvs\": 4,  # Amount of solar panels that use PecanStreet data\n",
    "    \"n_canopy_pvs\": 0,  # Amount of solar panels that use canopy data\n",
    "    \"canopy_pv_rated_power\": 250,  # Rated power of these panels\n",
    "    \"n_loads\": 0,  # Amount of inflexible loads\n",
    "    \"n_feeders\": 1,  # Amount of feeders\n",
    "    \"n_ev_chargers\": 4,  # Amount of EV chargers\n",
    "    \"ps_pvs_rated_power\": 4,  # Rated power of these panels\n",
    "    \"avg_evs_per_day\": 3.5,  # Scaling of the EV arrival rate\n",
    "    \"feeder_p_min\": -5,  # Capacity of the feeders\n",
    "    \"g\": 4,  # Conductance of each line\n",
    "    \"i_max\": 25,  # Capacity of each line\n",
    "    \n",
    "    # New and improved config options\n",
    "    \"environment_type\": \"gym\",\n",
    "    \"use_constraint_projection\": False,\n",
    "    \"use_rescaled_actions\": True,\n",
    "    \"normalize_environment_outputs\": True,\n",
    "    \"default_episode_index\": None,\n",
    "\n",
    "    \"violations_in_reward\" : False,\n",
    "    \"one_reward_target\" : False,\n",
    "\n",
    "    \"random_epoch_order\" : False,\n",
    "}\n",
    "\n",
    "# wandb.config.update(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af5762",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54265e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path_to_data': './data/', 't0_hr': 6.0, 'dt_min': 30, 'ev_dt_min': 60, 'ev_sampling_dt_min': 60, 'apply_gaussian_noise': False, 'ev_utility_coef_mean': 1, 'ev_utility_coef_scale': 0.13, 'days_per_month_train': 20, 'ev_session_months_train': ['01'], 'grid_to_use': 'ieee16', 'ev_session_months_test': ['05', '12'], 'n_ps_pvs': 4, 'n_canopy_pvs': 0, 'canopy_pv_rated_power': 250, 'n_loads': 0, 'n_feeders': 1, 'n_ev_chargers': 4, 'ps_pvs_rated_power': 4, 'avg_evs_per_day': 3.5, 'feeder_p_min': -5, 'g': 4, 'i_max': 25, 'environment_type': 'gym', 'use_constraint_projection': False, 'use_rescaled_actions': True, 'normalize_environment_outputs': True, 'default_episode_index': None, 'violations_in_reward': False, 'one_reward_target': False, 'random_epoch_order': False}\n",
      "loading strait from cache\n"
     ]
    }
   ],
   "source": [
    "# Preload samplers, it is necessary to avoid re-loading data each time env is created\n",
    "(ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    " price_sampler, price_metadata, ev_sampler, elaadnl_metadata) = load_samplers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee5d4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = create_env(config, ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    "                 price_sampler, price_metadata, ev_sampler, elaadnl_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca282843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500pt\" height=\"500pt\" viewBox=\"0 0 500 500\" version=\"1.1\">\n<defs>\n<g>\n<symbol overflow=\"visible\" id=\"glyph0-0\">\n<path style=\"stroke:none;\" d=\"M 0.320312 0 L 0.320312 -7.171875 L 6.015625 -7.171875 L 6.015625 0 Z M 5.117188 -0.898438 L 5.117188 -6.273438 L 1.21875 -6.273438 L 1.21875 -0.898438 Z M 5.117188 -0.898438 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-1\">\n<path style=\"stroke:none;\" d=\"M 0.855469 -7.171875 L 5.828125 -7.171875 L 5.828125 -6.292969 L 1.828125 -6.292969 L 1.828125 -4.117188 L 5.347656 -4.117188 L 5.347656 -3.261719 L 1.828125 -3.261719 L 1.828125 0 L 0.855469 0 Z M 0.855469 -7.171875 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-2\">\n<path style=\"stroke:none;\" d=\"M 2.820312 -5.347656 C 3.191406 -5.347656 3.554688 -5.257812 3.902344 -5.085938 C 4.25 -4.910156 4.515625 -4.6875 4.695312 -4.410156 C 4.871094 -4.144531 4.992188 -3.835938 5.046875 -3.484375 C 5.101562 -3.246094 5.125 -2.859375 5.125 -2.335938 L 1.292969 -2.335938 C 1.308594 -1.804688 1.4375 -1.378906 1.671875 -1.058594 C 1.90625 -0.738281 2.265625 -0.578125 2.757812 -0.578125 C 3.21875 -0.578125 3.585938 -0.726562 3.859375 -1.03125 C 4.015625 -1.207031 4.125 -1.410156 4.1875 -1.640625 L 5.054688 -1.640625 C 5.03125 -1.449219 4.957031 -1.234375 4.828125 -1 C 4.699219 -0.761719 4.554688 -0.570312 4.394531 -0.421875 C 4.128906 -0.160156 3.796875 0.015625 3.402344 0.109375 C 3.191406 0.160156 2.953125 0.1875 2.6875 0.1875 C 2.035156 0.1875 1.484375 -0.0507812 1.03125 -0.523438 C 0.578125 -1 0.351562 -1.660156 0.351562 -2.515625 C 0.351562 -3.355469 0.578125 -4.035156 1.035156 -4.5625 C 1.492188 -5.085938 2.085938 -5.347656 2.820312 -5.347656 Z M 4.222656 -3.03125 C 4.1875 -3.414062 4.105469 -3.71875 3.976562 -3.945312 C 3.734375 -4.367188 3.332031 -4.578125 2.769531 -4.578125 C 2.367188 -4.578125 2.027344 -4.433594 1.753906 -4.144531 C 1.480469 -3.851562 1.335938 -3.480469 1.320312 -3.03125 Z M 4.222656 -3.03125 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-3\">\n<path style=\"stroke:none;\" d=\"M 1.203125 -2.554688 C 1.203125 -1.992188 1.320312 -1.523438 1.558594 -1.148438 C 1.796875 -0.769531 2.175781 -0.582031 2.699219 -0.582031 C 3.105469 -0.582031 3.441406 -0.757812 3.703125 -1.105469 C 3.964844 -1.457031 4.097656 -1.957031 4.097656 -2.613281 C 4.097656 -3.273438 3.960938 -3.761719 3.691406 -4.078125 C 3.421875 -4.398438 3.085938 -4.554688 2.691406 -4.554688 C 2.25 -4.554688 1.890625 -4.386719 1.613281 -4.046875 C 1.339844 -3.710938 1.203125 -3.210938 1.203125 -2.554688 Z M 2.523438 -5.320312 C 2.925781 -5.320312 3.261719 -5.238281 3.53125 -5.070312 C 3.6875 -4.972656 3.863281 -4.800781 4.0625 -4.554688 L 4.0625 -7.195312 L 4.90625 -7.195312 L 4.90625 0 L 4.117188 0 L 4.117188 -0.726562 C 3.910156 -0.40625 3.667969 -0.171875 3.390625 -0.03125 C 3.109375 0.113281 2.789062 0.1875 2.425781 0.1875 C 1.84375 0.1875 1.339844 -0.0585938 0.914062 -0.550781 C 0.488281 -1.039062 0.273438 -1.691406 0.273438 -2.503906 C 0.273438 -3.265625 0.46875 -3.925781 0.855469 -4.484375 C 1.246094 -5.042969 1.800781 -5.320312 2.523438 -5.320312 Z M 2.523438 -5.320312 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-4\">\n<path style=\"stroke:none;\" d=\"M 0.667969 -5.230469 L 1.503906 -5.230469 L 1.503906 -4.328125 C 1.570312 -4.503906 1.738281 -4.714844 2.007812 -4.96875 C 2.273438 -5.21875 2.582031 -5.347656 2.929688 -5.347656 C 2.945312 -5.347656 2.972656 -5.34375 3.011719 -5.34375 C 3.050781 -5.339844 3.117188 -5.332031 3.210938 -5.320312 L 3.210938 -4.394531 C 3.160156 -4.40625 3.113281 -4.410156 3.070312 -4.414062 C 3.023438 -4.417969 2.976562 -4.417969 2.925781 -4.417969 C 2.484375 -4.417969 2.140625 -4.277344 1.90625 -3.992188 C 1.667969 -3.707031 1.546875 -3.378906 1.546875 -3.007812 L 1.546875 0 L 0.667969 0 Z M 0.667969 -5.230469 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-5\">\n<path style=\"stroke:none;\" d=\"M 2.703125 -6.992188 C 3.609375 -6.992188 4.265625 -6.621094 4.667969 -5.875 C 4.980469 -5.296875 5.136719 -4.507812 5.136719 -3.507812 C 5.136719 -2.554688 4.996094 -1.769531 4.710938 -1.148438 C 4.300781 -0.257812 3.632812 0.191406 2.699219 0.191406 C 1.859375 0.191406 1.234375 -0.175781 0.824219 -0.902344 C 0.484375 -1.511719 0.3125 -2.328125 0.3125 -3.355469 C 0.3125 -4.148438 0.414062 -4.832031 0.621094 -5.398438 C 1.003906 -6.460938 1.699219 -6.992188 2.703125 -6.992188 Z M 2.695312 -0.609375 C 3.152344 -0.609375 3.515625 -0.8125 3.785156 -1.214844 C 4.054688 -1.617188 4.1875 -2.371094 4.1875 -3.472656 C 4.1875 -4.265625 4.09375 -4.917969 3.898438 -5.433594 C 3.703125 -5.945312 3.320312 -6.203125 2.757812 -6.203125 C 2.242188 -6.203125 1.863281 -5.957031 1.625 -5.472656 C 1.382812 -4.984375 1.265625 -4.265625 1.265625 -3.320312 C 1.265625 -2.609375 1.339844 -2.035156 1.492188 -1.601562 C 1.726562 -0.941406 2.128906 -0.609375 2.695312 -0.609375 Z M 2.695312 -0.609375 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-6\">\n<path style=\"stroke:none;\" d=\"M 0.957031 -4.953125 L 0.957031 -5.625 C 1.59375 -5.6875 2.035156 -5.789062 2.285156 -5.933594 C 2.535156 -6.078125 2.722656 -6.421875 2.847656 -6.960938 L 3.539062 -6.960938 L 3.539062 0 L 2.601562 0 L 2.601562 -4.953125 Z M 0.957031 -4.953125 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph0-7\">\n<path style=\"stroke:none;\" d=\"M 0.3125 0 C 0.34375 -0.601562 0.46875 -1.125 0.6875 -1.570312 C 0.902344 -2.015625 1.324219 -2.421875 1.953125 -2.789062 L 2.890625 -3.328125 C 3.3125 -3.574219 3.605469 -3.78125 3.773438 -3.953125 C 4.039062 -4.226562 4.175781 -4.535156 4.175781 -4.882812 C 4.175781 -5.289062 4.054688 -5.613281 3.808594 -5.851562 C 3.5625 -6.089844 3.238281 -6.210938 2.832031 -6.210938 C 2.230469 -6.210938 1.8125 -5.984375 1.582031 -5.527344 C 1.457031 -5.28125 1.390625 -4.945312 1.375 -4.511719 L 0.484375 -4.511719 C 0.492188 -5.121094 0.605469 -5.617188 0.820312 -6 C 1.203125 -6.679688 1.875 -7.015625 2.835938 -7.015625 C 3.636719 -7.015625 4.222656 -6.800781 4.59375 -6.367188 C 4.960938 -5.933594 5.148438 -5.453125 5.148438 -4.921875 C 5.148438 -4.363281 4.949219 -3.882812 4.554688 -3.484375 C 4.328125 -3.253906 3.917969 -2.976562 3.328125 -2.648438 L 2.660156 -2.273438 C 2.34375 -2.097656 2.089844 -1.933594 1.910156 -1.773438 C 1.585938 -1.488281 1.378906 -1.175781 1.292969 -0.828125 L 5.113281 -0.828125 L 5.113281 0 Z M 0.3125 0 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-0\">\n<path style=\"stroke:none;\" d=\"M 0.484375 0 L 0.484375 -10.757812 L 9.023438 -10.757812 L 9.023438 0 Z M 7.675781 -1.347656 L 7.675781 -9.410156 L 1.832031 -9.410156 L 1.832031 -1.347656 Z M 7.675781 -1.347656 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-1\">\n<path style=\"stroke:none;\" d=\"M 1.28125 -10.757812 L 9.125 -10.757812 L 9.125 -9.441406 L 2.703125 -9.441406 L 2.703125 -6.175781 L 8.640625 -6.175781 L 8.640625 -4.929688 L 2.703125 -4.929688 L 2.703125 -1.28125 L 9.234375 -1.28125 L 9.234375 0 L 1.28125 0 Z M 1.28125 -10.757812 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-2\">\n<path style=\"stroke:none;\" d=\"M 1.992188 -10.757812 L 5.082031 -1.597656 L 8.136719 -10.757812 L 9.769531 -10.757812 L 5.84375 0 L 4.300781 0 L 0.382812 -10.757812 Z M 1.992188 -10.757812 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-3\">\n<path style=\"stroke:none;\" d=\"M 5.675781 -11.050781 C 7.039062 -11.050781 8.09375 -10.695312 8.847656 -9.976562 C 9.601562 -9.257812 10.015625 -8.441406 10.101562 -7.53125 L 8.679688 -7.53125 C 8.519531 -8.222656 8.195312 -8.773438 7.714844 -9.175781 C 7.234375 -9.582031 6.558594 -9.785156 5.691406 -9.785156 C 4.632812 -9.785156 3.777344 -9.414062 3.125 -8.667969 C 2.472656 -7.921875 2.144531 -6.78125 2.144531 -5.242188 C 2.144531 -3.984375 2.441406 -2.960938 3.027344 -2.179688 C 3.617188 -1.394531 4.496094 -1.003906 5.660156 -1.003906 C 6.734375 -1.003906 7.554688 -1.414062 8.117188 -2.242188 C 8.414062 -2.675781 8.636719 -3.246094 8.78125 -3.953125 L 10.203125 -3.953125 C 10.074219 -2.820312 9.65625 -1.871094 8.941406 -1.105469 C 8.085938 -0.183594 6.9375 0.277344 5.484375 0.277344 C 4.234375 0.277344 3.1875 -0.101562 2.335938 -0.855469 C 1.21875 -1.859375 0.660156 -3.402344 0.660156 -5.492188 C 0.660156 -7.078125 1.078125 -8.382812 1.917969 -9.398438 C 2.828125 -10.5 4.078125 -11.050781 5.675781 -11.050781 Z M 5.675781 -11.050781 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-4\">\n<path style=\"stroke:none;\" d=\"M 0.96875 -10.796875 L 2.285156 -10.796875 L 2.285156 -6.78125 C 2.597656 -7.175781 2.878906 -7.457031 3.128906 -7.617188 C 3.554688 -7.894531 4.082031 -8.035156 4.71875 -8.035156 C 5.855469 -8.035156 6.625 -7.636719 7.03125 -6.839844 C 7.25 -6.40625 7.359375 -5.804688 7.359375 -5.03125 L 7.359375 0 L 6.007812 0 L 6.007812 -4.945312 C 6.007812 -5.519531 5.933594 -5.941406 5.785156 -6.210938 C 5.546875 -6.640625 5.097656 -6.855469 4.4375 -6.855469 C 3.890625 -6.855469 3.394531 -6.667969 2.953125 -6.292969 C 2.507812 -5.914062 2.285156 -5.203125 2.285156 -4.160156 L 2.285156 0 L 0.96875 0 Z M 0.96875 -10.796875 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-5\">\n<path style=\"stroke:none;\" d=\"M 1.976562 -2.085938 C 1.976562 -1.707031 2.117188 -1.40625 2.394531 -1.1875 C 2.671875 -0.96875 3.003906 -0.855469 3.382812 -0.855469 C 3.847656 -0.855469 4.296875 -0.964844 4.730469 -1.179688 C 5.464844 -1.535156 5.828125 -2.117188 5.828125 -2.929688 L 5.828125 -3.992188 C 5.667969 -3.890625 5.460938 -3.804688 5.207031 -3.734375 C 4.953125 -3.667969 4.703125 -3.617188 4.460938 -3.589844 L 3.664062 -3.484375 C 3.183594 -3.421875 2.824219 -3.324219 2.585938 -3.1875 C 2.179688 -2.957031 1.976562 -2.589844 1.976562 -2.085938 Z M 5.171875 -4.753906 C 5.472656 -4.792969 5.675781 -4.917969 5.777344 -5.132812 C 5.835938 -5.25 5.867188 -5.421875 5.867188 -5.640625 C 5.867188 -6.089844 5.707031 -6.414062 5.386719 -6.617188 C 5.066406 -6.820312 4.609375 -6.921875 4.015625 -6.921875 C 3.324219 -6.921875 2.835938 -6.734375 2.546875 -6.363281 C 2.386719 -6.160156 2.28125 -5.855469 2.234375 -5.449219 L 1.003906 -5.449219 C 1.027344 -6.414062 1.339844 -7.089844 1.945312 -7.46875 C 2.546875 -7.847656 3.246094 -8.035156 4.042969 -8.035156 C 4.964844 -8.035156 5.714844 -7.859375 6.292969 -7.507812 C 6.863281 -7.15625 7.148438 -6.609375 7.148438 -5.867188 L 7.148438 -1.347656 C 7.148438 -1.210938 7.175781 -1.101562 7.234375 -1.019531 C 7.289062 -0.9375 7.40625 -0.894531 7.585938 -0.894531 C 7.644531 -0.894531 7.710938 -0.898438 7.785156 -0.90625 C 7.859375 -0.914062 7.9375 -0.921875 8.019531 -0.9375 L 8.019531 0.0351562 C 7.816406 0.09375 7.660156 0.132812 7.550781 0.148438 C 7.445312 0.160156 7.296875 0.167969 7.113281 0.167969 C 6.65625 0.167969 6.328125 0.0078125 6.125 -0.316406 C 6.015625 -0.484375 5.941406 -0.726562 5.894531 -1.039062 C 5.625 -0.6875 5.242188 -0.382812 4.738281 -0.125 C 4.234375 0.132812 3.679688 0.265625 3.078125 0.265625 C 2.347656 0.265625 1.753906 0.0429688 1.292969 -0.398438 C 0.832031 -0.839844 0.601562 -1.394531 0.601562 -2.058594 C 0.601562 -2.785156 0.828125 -3.351562 1.28125 -3.75 C 1.734375 -4.148438 2.332031 -4.398438 3.070312 -4.488281 Z M 5.171875 -4.753906 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-6\">\n<path style=\"stroke:none;\" d=\"M 1.003906 -7.84375 L 2.257812 -7.84375 L 2.257812 -6.488281 C 2.359375 -6.753906 2.609375 -7.074219 3.011719 -7.453125 C 3.410156 -7.832031 3.871094 -8.019531 4.394531 -8.019531 C 4.417969 -8.019531 4.460938 -8.015625 4.519531 -8.011719 C 4.578125 -8.007812 4.679688 -8 4.820312 -7.984375 L 4.820312 -6.59375 C 4.742188 -6.605469 4.667969 -6.617188 4.601562 -6.621094 C 4.535156 -6.625 4.464844 -6.628906 4.386719 -6.628906 C 3.722656 -6.628906 3.210938 -6.414062 2.855469 -5.988281 C 2.5 -5.5625 2.320312 -5.070312 2.320312 -4.511719 L 2.320312 0 L 1.003906 0 Z M 1.003906 -7.84375 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-7\">\n<path style=\"stroke:none;\" d=\"M 3.734375 -7.984375 C 4.351562 -7.984375 4.886719 -7.832031 5.347656 -7.53125 C 5.597656 -7.359375 5.851562 -7.109375 6.109375 -6.78125 L 6.109375 -7.769531 L 7.324219 -7.769531 L 7.324219 -0.636719 C 7.324219 0.359375 7.179688 1.144531 6.882812 1.722656 C 6.335938 2.785156 5.304688 3.316406 3.785156 3.316406 C 2.941406 3.316406 2.230469 3.128906 1.65625 2.75 C 1.078125 2.371094 0.757812 1.78125 0.6875 0.972656 L 2.027344 0.972656 C 2.09375 1.324219 2.21875 1.597656 2.410156 1.789062 C 2.707031 2.082031 3.175781 2.226562 3.816406 2.226562 C 4.828125 2.226562 5.488281 1.871094 5.800781 1.15625 C 5.984375 0.738281 6.070312 -0.0117188 6.058594 -1.089844 C 5.792969 -0.691406 5.476562 -0.394531 5.105469 -0.199219 C 4.734375 -0.00390625 4.242188 0.09375 3.632812 0.09375 C 2.78125 0.09375 2.039062 -0.207031 1.402344 -0.808594 C 0.765625 -1.414062 0.445312 -2.410156 0.445312 -3.800781 C 0.445312 -5.113281 0.769531 -6.140625 1.410156 -6.878906 C 2.050781 -7.617188 2.828125 -7.984375 3.734375 -7.984375 Z M 6.109375 -3.953125 C 6.109375 -4.925781 5.90625 -5.648438 5.507812 -6.117188 C 5.109375 -6.585938 4.597656 -6.820312 3.976562 -6.820312 C 3.050781 -6.820312 2.414062 -6.382812 2.074219 -5.515625 C 1.890625 -5.050781 1.800781 -4.445312 1.800781 -3.691406 C 1.800781 -2.808594 1.980469 -2.136719 2.339844 -1.671875 C 2.699219 -1.210938 3.179688 -0.980469 3.785156 -0.980469 C 4.734375 -0.980469 5.398438 -1.410156 5.785156 -2.261719 C 6 -2.746094 6.109375 -3.3125 6.109375 -3.953125 Z M 6.109375 -3.953125 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-8\">\n<path style=\"stroke:none;\" d=\"M 4.234375 -8.019531 C 4.789062 -8.019531 5.328125 -7.890625 5.851562 -7.628906 C 6.375 -7.367188 6.773438 -7.027344 7.046875 -6.613281 C 7.308594 -6.21875 7.484375 -5.757812 7.574219 -5.230469 C 7.652344 -4.867188 7.691406 -4.292969 7.691406 -3.5 L 1.941406 -3.5 C 1.964844 -2.703125 2.152344 -2.066406 2.503906 -1.585938 C 2.855469 -1.105469 3.402344 -0.863281 4.136719 -0.863281 C 4.828125 -0.863281 5.375 -1.089844 5.785156 -1.546875 C 6.019531 -1.808594 6.1875 -2.113281 6.285156 -2.460938 L 7.582031 -2.460938 C 7.546875 -2.171875 7.433594 -1.851562 7.238281 -1.496094 C 7.046875 -1.144531 6.832031 -0.855469 6.59375 -0.628906 C 6.191406 -0.238281 5.695312 0.0234375 5.105469 0.160156 C 4.789062 0.238281 4.429688 0.277344 4.027344 0.277344 C 3.050781 0.277344 2.222656 -0.078125 1.546875 -0.789062 C 0.867188 -1.5 0.527344 -2.492188 0.527344 -3.773438 C 0.527344 -5.03125 0.867188 -6.054688 1.554688 -6.839844 C 2.238281 -7.625 3.128906 -8.019531 4.234375 -8.019531 Z M 6.335938 -4.546875 C 6.28125 -5.117188 6.15625 -5.578125 5.960938 -5.917969 C 5.601562 -6.554688 4.996094 -6.871094 4.152344 -6.871094 C 3.546875 -6.871094 3.039062 -6.652344 2.628906 -6.214844 C 2.21875 -5.777344 2 -5.222656 1.976562 -4.546875 Z M 6.335938 -4.546875 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-9\">\n<path style=\"stroke:none;\" d=\"M 3.898438 0.285156 C 2.65625 0.285156 1.757812 -0.0546875 1.199219 -0.734375 C 0.640625 -1.417969 0.359375 -2.246094 0.359375 -3.222656 L 1.734375 -3.222656 C 1.792969 -2.542969 1.921875 -2.050781 2.117188 -1.742188 C 2.457031 -1.191406 3.078125 -0.914062 3.96875 -0.914062 C 4.664062 -0.914062 5.21875 -1.101562 5.640625 -1.472656 C 6.058594 -1.84375 6.269531 -2.320312 6.269531 -2.90625 C 6.269531 -3.628906 6.046875 -4.136719 5.605469 -4.421875 C 5.164062 -4.710938 4.550781 -4.855469 3.765625 -4.855469 C 3.675781 -4.855469 3.585938 -4.855469 3.496094 -4.851562 C 3.40625 -4.851562 3.316406 -4.847656 3.222656 -4.839844 L 3.222656 -6.007812 C 3.359375 -5.992188 3.472656 -5.980469 3.566406 -5.976562 C 3.660156 -5.972656 3.757812 -5.96875 3.867188 -5.96875 C 4.359375 -5.96875 4.765625 -6.046875 5.082031 -6.203125 C 5.640625 -6.476562 5.917969 -6.964844 5.917969 -7.667969 C 5.917969 -8.191406 5.734375 -8.59375 5.359375 -8.875 C 4.988281 -9.160156 4.558594 -9.300781 4.066406 -9.300781 C 3.1875 -9.300781 2.578125 -9.007812 2.242188 -8.421875 C 2.054688 -8.101562 1.949219 -7.640625 1.925781 -7.046875 L 0.621094 -7.046875 C 0.621094 -7.828125 0.777344 -8.492188 1.089844 -9.039062 C 1.628906 -10.015625 2.574219 -10.503906 3.925781 -10.503906 C 4.996094 -10.503906 5.824219 -10.265625 6.410156 -9.789062 C 6.996094 -9.3125 7.289062 -8.625 7.289062 -7.71875 C 7.289062 -7.074219 7.113281 -6.554688 6.765625 -6.152344 C 6.550781 -5.902344 6.273438 -5.707031 5.933594 -5.566406 C 6.484375 -5.414062 6.914062 -5.125 7.226562 -4.691406 C 7.535156 -4.257812 7.691406 -3.730469 7.691406 -3.105469 C 7.691406 -2.105469 7.359375 -1.289062 6.703125 -0.660156 C 6.042969 -0.03125 5.109375 0.285156 3.898438 0.285156 Z M 3.898438 0.285156 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-10\">\n<path style=\"stroke:none;\" d=\"M 4.957031 -3.714844 L 4.957031 -8.46875 L 1.597656 -3.714844 Z M 4.980469 0 L 4.980469 -2.5625 L 0.382812 -2.5625 L 0.382812 -3.851562 L 5.1875 -10.515625 L 6.296875 -10.515625 L 6.296875 -3.714844 L 7.84375 -3.714844 L 7.84375 -2.5625 L 6.296875 -2.5625 L 6.296875 0 Z M 4.980469 0 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-11\">\n<path style=\"stroke:none;\" d=\"M 1.851562 -2.671875 C 1.941406 -1.921875 2.289062 -1.402344 2.898438 -1.113281 C 3.210938 -0.96875 3.574219 -0.894531 3.984375 -0.894531 C 4.765625 -0.894531 5.34375 -1.140625 5.71875 -1.640625 C 6.09375 -2.140625 6.285156 -2.691406 6.285156 -3.296875 C 6.285156 -4.027344 6.0625 -4.59375 5.613281 -4.996094 C 5.167969 -5.394531 4.632812 -5.59375 4.007812 -5.59375 C 3.554688 -5.59375 3.164062 -5.507812 2.839844 -5.332031 C 2.515625 -5.15625 2.234375 -4.914062 2.007812 -4.601562 L 0.863281 -4.664062 L 1.664062 -10.3125 L 7.113281 -10.3125 L 7.113281 -9.039062 L 2.652344 -9.039062 L 2.203125 -6.125 C 2.449219 -6.308594 2.679688 -6.449219 2.898438 -6.539062 C 3.289062 -6.703125 3.742188 -6.78125 4.253906 -6.78125 C 5.21875 -6.78125 6.03125 -6.472656 6.703125 -5.851562 C 7.371094 -5.230469 7.703125 -4.445312 7.703125 -3.492188 C 7.703125 -2.5 7.398438 -1.628906 6.785156 -0.871094 C 6.171875 -0.113281 5.195312 0.265625 3.851562 0.265625 C 2.996094 0.265625 2.242188 0.0234375 1.585938 -0.457031 C 0.929688 -0.9375 0.5625 -1.675781 0.484375 -2.671875 Z M 1.851562 -2.671875 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-12\">\n<path style=\"stroke:none;\" d=\"M 4.386719 -10.53125 C 5.558594 -10.53125 6.375 -10.226562 6.835938 -9.621094 C 7.296875 -9.011719 7.53125 -8.386719 7.53125 -7.742188 L 6.226562 -7.742188 C 6.148438 -8.15625 6.023438 -8.480469 5.851562 -8.714844 C 5.535156 -9.15625 5.054688 -9.375 4.410156 -9.375 C 3.671875 -9.375 3.085938 -9.035156 2.652344 -8.351562 C 2.21875 -7.671875 1.976562 -6.695312 1.925781 -5.425781 C 2.230469 -5.871094 2.609375 -6.203125 3.070312 -6.421875 C 3.488281 -6.617188 3.957031 -6.714844 4.476562 -6.714844 C 5.355469 -6.714844 6.121094 -6.4375 6.773438 -5.875 C 7.429688 -5.3125 7.757812 -4.476562 7.757812 -3.363281 C 7.757812 -2.410156 7.445312 -1.566406 6.828125 -0.832031 C 6.207031 -0.0976562 5.320312 0.269531 4.175781 0.269531 C 3.195312 0.269531 2.347656 -0.101562 1.632812 -0.847656 C 0.921875 -1.589844 0.5625 -2.84375 0.5625 -4.605469 C 0.5625 -5.910156 0.722656 -7.015625 1.039062 -7.925781 C 1.648438 -9.664062 2.765625 -10.53125 4.386719 -10.53125 Z M 4.292969 -0.902344 C 4.984375 -0.902344 5.503906 -1.132812 5.847656 -1.601562 C 6.191406 -2.066406 6.363281 -2.617188 6.363281 -3.25 C 6.363281 -3.789062 6.210938 -4.300781 5.902344 -4.785156 C 5.59375 -5.273438 5.035156 -5.515625 4.226562 -5.515625 C 3.660156 -5.515625 3.164062 -5.328125 2.734375 -4.953125 C 2.308594 -4.574219 2.09375 -4.007812 2.09375 -3.25 C 2.09375 -2.585938 2.289062 -2.03125 2.675781 -1.578125 C 3.066406 -1.125 3.601562 -0.902344 4.292969 -0.902344 Z M 4.292969 -0.902344 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-13\">\n<path style=\"stroke:none;\" d=\"M 7.84375 -10.3125 L 7.84375 -9.164062 C 7.507812 -8.835938 7.058594 -8.265625 6.5 -7.457031 C 5.941406 -6.644531 5.445312 -5.773438 5.015625 -4.835938 C 4.59375 -3.921875 4.269531 -3.089844 4.050781 -2.335938 C 3.910156 -1.851562 3.726562 -1.074219 3.5 0 L 2.042969 0 C 2.375 -2 3.109375 -3.992188 4.242188 -5.976562 C 4.910156 -7.140625 5.613281 -8.140625 6.351562 -8.988281 L 0.550781 -8.988281 L 0.550781 -10.3125 Z M 7.84375 -10.3125 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-14\">\n<path style=\"stroke:none;\" d=\"M 4.078125 -6.09375 C 4.660156 -6.09375 5.113281 -6.257812 5.441406 -6.582031 C 5.769531 -6.90625 5.933594 -7.292969 5.933594 -7.742188 C 5.933594 -8.132812 5.777344 -8.492188 5.464844 -8.820312 C 5.152344 -9.144531 4.675781 -9.308594 4.035156 -9.308594 C 3.402344 -9.308594 2.941406 -9.144531 2.660156 -8.820312 C 2.375 -8.492188 2.234375 -8.109375 2.234375 -7.667969 C 2.234375 -7.175781 2.417969 -6.789062 2.78125 -6.511719 C 3.148438 -6.234375 3.582031 -6.09375 4.078125 -6.09375 Z M 4.160156 -0.902344 C 4.769531 -0.902344 5.277344 -1.066406 5.679688 -1.394531 C 6.082031 -1.726562 6.285156 -2.21875 6.285156 -2.871094 C 6.285156 -3.550781 6.078125 -4.066406 5.660156 -4.417969 C 5.246094 -4.769531 4.714844 -4.945312 4.066406 -4.945312 C 3.4375 -4.945312 2.921875 -4.765625 2.523438 -4.40625 C 2.125 -4.046875 1.925781 -3.550781 1.925781 -2.914062 C 1.925781 -2.367188 2.109375 -1.894531 2.472656 -1.496094 C 2.835938 -1.097656 3.398438 -0.902344 4.160156 -0.902344 Z M 2.285156 -5.589844 C 1.917969 -5.746094 1.632812 -5.929688 1.429688 -6.136719 C 1.042969 -6.527344 0.851562 -7.035156 0.851562 -7.660156 C 0.851562 -8.441406 1.132812 -9.113281 1.699219 -9.675781 C 2.265625 -10.238281 3.070312 -10.515625 4.109375 -10.515625 C 5.113281 -10.515625 5.902344 -10.253906 6.476562 -9.722656 C 7.046875 -9.191406 7.332031 -8.574219 7.332031 -7.867188 C 7.332031 -7.210938 7.164062 -6.683594 6.832031 -6.277344 C 6.648438 -6.046875 6.359375 -5.824219 5.96875 -5.601562 C 6.402344 -5.402344 6.746094 -5.171875 6.996094 -4.914062 C 7.460938 -4.425781 7.691406 -3.792969 7.691406 -3.011719 C 7.691406 -2.085938 7.378906 -1.304688 6.761719 -0.664062 C 6.140625 -0.0195312 5.265625 0.300781 4.132812 0.300781 C 3.109375 0.300781 2.246094 0.0234375 1.542969 -0.53125 C 0.835938 -1.085938 0.484375 -1.890625 0.484375 -2.945312 C 0.484375 -3.566406 0.632812 -4.101562 0.9375 -4.550781 C 1.242188 -5.003906 1.6875 -5.347656 2.285156 -5.589844 Z M 2.285156 -5.589844 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-15\">\n<path style=\"stroke:none;\" d=\"M 1.992188 -2.535156 C 2.03125 -1.808594 2.3125 -1.304688 2.835938 -1.023438 C 3.101562 -0.878906 3.40625 -0.804688 3.742188 -0.804688 C 4.371094 -0.804688 4.910156 -1.066406 5.355469 -1.59375 C 5.796875 -2.117188 6.113281 -3.183594 6.296875 -4.789062 C 6.003906 -4.324219 5.644531 -4 5.210938 -3.8125 C 4.777344 -3.625 4.3125 -3.53125 3.816406 -3.53125 C 2.804688 -3.53125 2.003906 -3.84375 1.417969 -4.476562 C 0.828125 -5.105469 0.535156 -5.914062 0.535156 -6.90625 C 0.535156 -7.859375 0.824219 -8.695312 1.40625 -9.417969 C 1.988281 -10.140625 2.84375 -10.503906 3.976562 -10.503906 C 5.503906 -10.503906 6.558594 -9.8125 7.140625 -8.4375 C 7.464844 -7.679688 7.625 -6.734375 7.625 -5.59375 C 7.625 -4.3125 7.429688 -3.171875 7.046875 -2.183594 C 6.40625 -0.53125 5.320312 0.292969 3.792969 0.292969 C 2.769531 0.292969 1.988281 0.0234375 1.457031 -0.511719 C 0.925781 -1.050781 0.660156 -1.722656 0.660156 -2.535156 Z M 3.992188 -4.6875 C 4.515625 -4.6875 4.992188 -4.859375 5.421875 -5.203125 C 5.855469 -5.546875 6.070312 -6.148438 6.070312 -7.007812 C 6.070312 -7.78125 5.878906 -8.355469 5.488281 -8.734375 C 5.101562 -9.113281 4.605469 -9.300781 4.007812 -9.300781 C 3.363281 -9.300781 2.851562 -9.085938 2.472656 -8.652344 C 2.09375 -8.222656 1.90625 -7.644531 1.90625 -6.921875 C 1.90625 -6.238281 2.070312 -5.695312 2.402344 -5.292969 C 2.734375 -4.890625 3.265625 -4.6875 3.992188 -4.6875 Z M 3.992188 -4.6875 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-16\">\n<path style=\"stroke:none;\" d=\"M 1.4375 -7.425781 L 1.4375 -8.4375 C 2.386719 -8.53125 3.050781 -8.683594 3.429688 -8.902344 C 3.804688 -9.121094 4.085938 -9.632812 4.269531 -10.445312 L 5.308594 -10.445312 L 5.308594 0 L 3.902344 0 L 3.902344 -7.425781 Z M 1.4375 -7.425781 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-17\">\n<path style=\"stroke:none;\" d=\"M 4.058594 -10.488281 C 5.414062 -10.488281 6.398438 -9.929688 7 -8.8125 C 7.46875 -7.945312 7.703125 -6.761719 7.703125 -5.257812 C 7.703125 -3.832031 7.492188 -2.652344 7.066406 -1.722656 C 6.453125 -0.382812 5.445312 0.285156 4.050781 0.285156 C 2.789062 0.285156 1.851562 -0.261719 1.238281 -1.355469 C 0.726562 -2.269531 0.46875 -3.492188 0.46875 -5.03125 C 0.46875 -6.222656 0.621094 -7.246094 0.929688 -8.101562 C 1.507812 -9.691406 2.546875 -10.488281 4.058594 -10.488281 Z M 4.042969 -0.914062 C 4.726562 -0.914062 5.269531 -1.21875 5.675781 -1.824219 C 6.082031 -2.429688 6.285156 -3.558594 6.285156 -5.207031 C 6.285156 -6.398438 6.136719 -7.378906 5.84375 -8.148438 C 5.550781 -8.917969 4.984375 -9.300781 4.136719 -9.300781 C 3.359375 -9.300781 2.792969 -8.9375 2.433594 -8.207031 C 2.074219 -7.476562 1.898438 -6.402344 1.898438 -4.980469 C 1.898438 -3.910156 2.011719 -3.050781 2.242188 -2.402344 C 2.59375 -1.410156 3.195312 -0.914062 4.042969 -0.914062 Z M 4.042969 -0.914062 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-18\">\n<path style=\"stroke:none;\" d=\"M 0.46875 0 C 0.515625 -0.902344 0.703125 -1.6875 1.027344 -2.359375 C 1.351562 -3.027344 1.988281 -3.636719 2.929688 -4.183594 L 4.335938 -4.996094 C 4.964844 -5.363281 5.40625 -5.671875 5.660156 -5.933594 C 6.0625 -6.339844 6.261719 -6.800781 6.261719 -7.324219 C 6.261719 -7.933594 6.078125 -8.417969 5.710938 -8.777344 C 5.347656 -9.136719 4.859375 -9.316406 4.25 -9.316406 C 3.34375 -9.316406 2.71875 -8.976562 2.375 -8.289062 C 2.1875 -7.925781 2.085938 -7.417969 2.066406 -6.765625 L 0.726562 -6.765625 C 0.742188 -7.679688 0.90625 -8.425781 1.230469 -9 C 1.800781 -10.015625 2.808594 -10.523438 4.253906 -10.523438 C 5.457031 -10.523438 6.335938 -10.199219 6.886719 -9.550781 C 7.441406 -8.902344 7.71875 -8.179688 7.71875 -7.382812 C 7.71875 -6.542969 7.425781 -5.824219 6.832031 -5.230469 C 6.492188 -4.882812 5.878906 -4.460938 4.996094 -3.96875 L 3.992188 -3.414062 C 3.511719 -3.148438 3.136719 -2.898438 2.863281 -2.660156 C 2.375 -2.234375 2.066406 -1.761719 1.941406 -1.246094 L 7.667969 -1.246094 L 7.667969 0 Z M 0.46875 0 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-19\">\n<path style=\"stroke:none;\" d=\"M 1.28125 -10.757812 L 6.125 -10.757812 C 7.082031 -10.757812 7.851562 -10.488281 8.4375 -9.949219 C 9.023438 -9.410156 9.316406 -8.652344 9.316406 -7.675781 C 9.316406 -6.835938 9.054688 -6.105469 8.53125 -5.480469 C 8.007812 -4.859375 7.207031 -4.546875 6.125 -4.546875 L 2.738281 -4.546875 L 2.738281 0 L 1.28125 0 Z M 7.84375 -7.667969 C 7.84375 -8.460938 7.550781 -8.996094 6.964844 -9.28125 C 6.644531 -9.429688 6.203125 -9.507812 5.640625 -9.507812 L 2.738281 -9.507812 L 2.738281 -5.777344 L 5.640625 -5.777344 C 6.292969 -5.777344 6.824219 -5.917969 7.234375 -6.195312 C 7.640625 -6.472656 7.84375 -6.964844 7.84375 -7.667969 Z M 7.84375 -7.667969 \"/>\n</symbol>\n<symbol overflow=\"visible\" id=\"glyph1-20\">\n<path style=\"stroke:none;\" d=\"M 0 1.875 L 0 1.136719 L 8.34375 1.136719 L 8.34375 1.875 Z M 0 1.875 \"/>\n</symbol>\n</g>\n</defs>\n<g id=\"surface8\">\n<rect x=\"0\" y=\"0\" width=\"500\" height=\"500\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 429.222656 391.757812 L 371.554688 346.730469 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 246.445312 148.40625 L 262.9375 105.816406 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 30 235.667969 L 100.589844 249.144531 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 371.554688 346.730469 L 397.339844 272.171875 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 371.554688 346.730469 L 312.574219 397.257812 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 397.339844 272.171875 L 375.472656 198.160156 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 397.339844 272.171875 L 470 273.964844 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 312.574219 397.257812 L 238.515625 402.363281 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 312.574219 397.257812 L 327.898438 470 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 238.515625 402.363281 L 169.851562 379.882812 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 262.9375 105.816406 L 340.675781 127.207031 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 262.9375 105.816406 L 182.023438 118.597656 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 340.675781 127.207031 L 375.472656 198.160156 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 340.675781 127.207031 L 401.929688 84.722656 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 340.675781 127.207031 L 341.621094 55.753906 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 182.023438 118.597656 L 132.414062 178.976562 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 182.023438 118.597656 L 145.445312 55.46875 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 401.929688 84.722656 L 446.082031 30 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 100.589844 249.144531 L 132.414062 178.976562 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 100.589844 249.144531 L 115.675781 327.078125 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 115.675781 327.078125 L 169.851562 379.882812 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 115.675781 327.078125 L 58.625 371.589844 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 423.222656 385.757812 L 429.222656 397.757812 L 435.222656 385.757812 Z M 423.222656 385.757812 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 240.445312 142.40625 L 246.445312 154.40625 L 252.445312 142.40625 Z M 240.445312 142.40625 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 24 229.667969 L 30 241.667969 L 36 229.667969 Z M 24 229.667969 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 365.554688 340.730469 L 377.554688 340.730469 L 377.554688 352.730469 L 365.554688 352.730469 Z M 365.554688 340.730469 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 391.339844 266.171875 L 403.339844 266.171875 L 403.339844 278.171875 L 391.339844 278.171875 Z M 391.339844 266.171875 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 306.574219 391.257812 L 318.574219 391.257812 L 318.574219 403.257812 L 306.574219 403.257812 Z M 306.574219 391.257812 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 232.515625 396.363281 L 244.515625 396.363281 L 244.515625 408.363281 L 232.515625 408.363281 Z M 232.515625 396.363281 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 256.9375 99.816406 L 268.9375 99.816406 L 268.9375 111.816406 L 256.9375 111.816406 Z M 256.9375 99.816406 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 334.675781 121.207031 L 346.675781 121.207031 L 346.675781 133.207031 L 334.675781 133.207031 Z M 334.675781 121.207031 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 176.023438 112.597656 L 188.023438 112.597656 L 188.023438 124.597656 L 176.023438 124.597656 Z M 176.023438 112.597656 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 369.472656 192.160156 L 381.472656 192.160156 L 381.472656 204.160156 L 369.472656 204.160156 Z M 369.472656 192.160156 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 395.929688 78.722656 L 407.929688 78.722656 L 407.929688 90.722656 L 395.929688 90.722656 Z M 395.929688 78.722656 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 94.589844 243.144531 L 106.589844 243.144531 L 106.589844 255.144531 L 94.589844 255.144531 Z M 94.589844 243.144531 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 126.414062 172.976562 L 138.414062 172.976562 L 138.414062 184.976562 L 126.414062 184.976562 Z M 126.414062 172.976562 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 109.675781 321.078125 L 121.675781 321.078125 L 121.675781 333.078125 L 109.675781 333.078125 Z M 109.675781 321.078125 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 163.851562 373.882812 L 175.851562 373.882812 L 175.851562 385.882812 L 163.851562 385.882812 Z M 163.851562 373.882812 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 321.898438 476 L 327.898438 464 L 333.898438 476 Z M 321.898438 476 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 464 279.964844 L 470 267.964844 L 476 279.964844 Z M 464 279.964844 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 335.621094 61.753906 L 341.621094 49.753906 L 347.621094 61.753906 Z M 335.621094 61.753906 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 139.445312 61.46875 L 145.445312 49.46875 L 151.445312 61.46875 Z M 139.445312 61.46875 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 440.082031 36 L 446.082031 24 L 452.082031 36 Z M 440.082031 36 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,64.705882%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 52.625 377.589844 L 58.625 365.589844 L 64.625 377.589844 Z M 52.625 377.589844 \"/>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph0-1\" x=\"410.382812\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"416.491211\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"422.052734\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-3\" x=\"427.614258\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"433.175781\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-4\" x=\"438.737305\" y=\"410.957031\"/>\n  <use xlink:href=\"#glyph0-5\" x=\"442.067383\" y=\"410.957031\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph0-1\" x=\"228.40625\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"234.514648\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"240.076172\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-3\" x=\"245.637695\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"251.199219\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-4\" x=\"256.760742\" y=\"167.605469\"/>\n  <use xlink:href=\"#glyph0-6\" x=\"260.09082\" y=\"167.605469\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph0-1\" x=\"11.15625\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"17.264648\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"22.826172\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-3\" x=\"28.387695\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-2\" x=\"33.949219\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-4\" x=\"39.510742\" y=\"254.867188\"/>\n  <use xlink:href=\"#glyph0-7\" x=\"42.84082\" y=\"254.867188\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"329.96875\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"339.973633\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"349.978516\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"360.811035\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"369.15332\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"377.495605\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"382.490723\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"390.833008\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"399.175293\" y=\"369.78125\"/>\n  <use xlink:href=\"#glyph1-9\" x=\"404.17041\" y=\"369.78125\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"355.675781\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"365.680664\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"375.685547\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"386.518066\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"394.860352\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"403.202637\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"408.197754\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"416.540039\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"424.882324\" y=\"295.226562\"/>\n  <use xlink:href=\"#glyph1-10\" x=\"429.877441\" y=\"295.226562\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"270.980469\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"280.985352\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"290.990234\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"301.822754\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"310.165039\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"318.507324\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"323.502441\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"331.844727\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"340.187012\" y=\"420.3125\"/>\n  <use xlink:href=\"#glyph1-11\" x=\"345.182129\" y=\"420.3125\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"196.894531\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"206.899414\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"216.904297\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"227.736816\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"236.079102\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"244.421387\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"249.416504\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"257.758789\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"266.101074\" y=\"425.414062\"/>\n  <use xlink:href=\"#glyph1-12\" x=\"271.096191\" y=\"425.414062\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"221.273438\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"231.27832\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"241.283203\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"252.115723\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"260.458008\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"268.800293\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"273.79541\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"282.137695\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"290.47998\" y=\"128.871094\"/>\n  <use xlink:href=\"#glyph1-13\" x=\"295.475098\" y=\"128.871094\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"299.089844\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"309.094727\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"319.099609\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"329.932129\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"338.274414\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"346.616699\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"351.611816\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"359.954102\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"368.296387\" y=\"150.257812\"/>\n  <use xlink:href=\"#glyph1-14\" x=\"373.291504\" y=\"150.257812\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"140.46875\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"150.473633\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"160.478516\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"171.311035\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"179.65332\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"187.995605\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"192.990723\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"201.333008\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"209.675293\" y=\"141.652344\"/>\n  <use xlink:href=\"#glyph1-15\" x=\"214.67041\" y=\"141.652344\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"329.707031\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"339.711914\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"349.716797\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"360.549316\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"368.891602\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"377.233887\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"382.229004\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"390.571289\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"398.913574\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"403.908691\" y=\"221.214844\"/>\n  <use xlink:href=\"#glyph1-17\" x=\"412.250977\" y=\"221.214844\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"357.359375\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"367.364258\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"377.369141\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"388.20166\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"396.543945\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"404.88623\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"409.881348\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"418.223633\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"426.565918\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"431.561035\" y=\"107.773438\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"439.90332\" y=\"107.773438\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"54.816406\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"64.821289\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"74.826172\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"85.658691\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"94.000977\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"102.343262\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"107.338379\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"115.680664\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"124.022949\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"129.018066\" y=\"272.199219\"/>\n  <use xlink:href=\"#glyph1-18\" x=\"137.360352\" y=\"272.199219\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"86.65625\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"96.661133\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"106.666016\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"117.498535\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"125.84082\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"134.183105\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"139.178223\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"147.520508\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"155.862793\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"160.85791\" y=\"202.03125\"/>\n  <use xlink:href=\"#glyph1-9\" x=\"169.200195\" y=\"202.03125\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"69.84375\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"79.848633\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"89.853516\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"100.686035\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"109.02832\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"117.370605\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"122.365723\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"130.708008\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"139.050293\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"144.04541\" y=\"350.132812\"/>\n  <use xlink:href=\"#glyph1-10\" x=\"152.387695\" y=\"350.132812\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-1\" x=\"124.085938\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"134.09082\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-3\" x=\"144.095703\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-4\" x=\"154.928223\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-5\" x=\"163.270508\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"171.612793\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-7\" x=\"176.60791\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-8\" x=\"184.950195\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-6\" x=\"193.29248\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"198.287598\" y=\"402.9375\"/>\n  <use xlink:href=\"#glyph1-11\" x=\"206.629883\" y=\"402.9375\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"305.03125\" y=\"492.757812\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"315.036133\" y=\"492.757812\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"325.041016\" y=\"492.757812\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"333.383301\" y=\"492.757812\"/>\n  <use xlink:href=\"#glyph1-12\" x=\"341.725586\" y=\"492.757812\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"447.089844\" y=\"296.726562\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"457.094727\" y=\"296.726562\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"467.099609\" y=\"296.726562\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"475.441895\" y=\"296.726562\"/>\n  <use xlink:href=\"#glyph1-13\" x=\"483.78418\" y=\"296.726562\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"318.789062\" y=\"78.515625\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"328.793945\" y=\"78.515625\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"338.798828\" y=\"78.515625\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"347.141113\" y=\"78.515625\"/>\n  <use xlink:href=\"#glyph1-14\" x=\"355.483398\" y=\"78.515625\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"122.644531\" y=\"78.226562\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"132.649414\" y=\"78.226562\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"142.654297\" y=\"78.226562\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"150.996582\" y=\"78.226562\"/>\n  <use xlink:href=\"#glyph1-15\" x=\"159.338867\" y=\"78.226562\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"423.242188\" y=\"52.757812\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"433.24707\" y=\"52.757812\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"443.251953\" y=\"52.757812\"/>\n  <use xlink:href=\"#glyph1-18\" x=\"451.594238\" y=\"52.757812\"/>\n  <use xlink:href=\"#glyph1-17\" x=\"459.936523\" y=\"52.757812\"/>\n</g>\n<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n  <use xlink:href=\"#glyph1-19\" x=\"36.980469\" y=\"394.347656\"/>\n  <use xlink:href=\"#glyph1-2\" x=\"46.985352\" y=\"394.347656\"/>\n  <use xlink:href=\"#glyph1-20\" x=\"56.990234\" y=\"394.347656\"/>\n  <use xlink:href=\"#glyph1-18\" x=\"65.33252\" y=\"394.347656\"/>\n  <use xlink:href=\"#glyph1-16\" x=\"73.674805\" y=\"394.347656\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<igraph.drawing.Plot at 0x15aa07880>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.plot_grid(bbox=(0, 0, 500, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c059bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0d93b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dim = env.observation_space.shape[0]\n",
    "action_dim =  env.action_space.shape[0]\n",
    "max_action_value = env.action_space.high[0]\n",
    "scheme = {'observations': env.observation_space.shape, \n",
    "          'observations_next': env.observation_space.shape,\n",
    "          'actions': env.action_space.shape,\n",
    "          'done': (1, ), 'reward': (1, ), 'reset_mask': (1, )}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76234e90",
   "metadata": {},
   "source": [
    "## Configure agent and runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89c0a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = {\n",
    "    \"nlp_width\": 7,\n",
    "    \"nlp_length\": 4,\n",
    "    \"lstm_width\": 6,\n",
    "    \"lstm_length\": 1,\n",
    "    \"lstm_dims\": [],\n",
    "    \"hidden_dims\": [128, 128, 128],\n",
    "    \"actor_lr\": 5e-4,\n",
    "    \"critic_lr\": 5e-4,\n",
    "    \"discount\": 0.99,\n",
    "    \"tau\": 0.005,\n",
    "    \"policy_noise\": 0.1,\n",
    "    \"noise_clip\": 0.2,\n",
    "    \"policy_update_freq\": 2,\n",
    "    \"batch_size\": 16,\n",
    "    \"min_size_to_sample\": 10,\n",
    "    \"n_eps\": 100001,\n",
    "    \"test_each\": 50,\n",
    "    \"n_test_episodes\": 1,\n",
    "    \"memory\": \"traj\", # traj, traj_trans, trans. traj seems the most promising\n",
    "}\n",
    "\n",
    "# wandb.config.update(agent_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a702f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_runner(config):\n",
    "    memory_traj_trans = TrajectoryMemoryBuffer(scheme=scheme, max_size=int(1e6/200), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                              use_transitions=True, sample_during_episode=True)\n",
    "\n",
    "    memory_trans = TransitionMemoryBuffer(scheme=scheme, max_size=int(1e6), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                          sample_during_episode=True)\n",
    "\n",
    "\n",
    "    memory_traj = TrajectoryMemoryBuffer(scheme=scheme, max_size=int(1e6/200), min_size_to_sample=config['min_size_to_sample'],\n",
    "                                         use_transitions=False, sample_during_episode=False)\n",
    "\n",
    "    agent = TD3Agent(observation_dim, action_dim, 1, config['lstm_dims'], config['hidden_dims'],\n",
    "                     actor_lr=config['actor_lr'], critic_lr=config['critic_lr'],  discount=config['discount'], tau=config['tau'],\n",
    "                     policy_noise=config['policy_noise'], noise_clip=config['noise_clip'], policy_update_freq=config['policy_update_freq'])\n",
    "\n",
    "    # Can choose which of the buffers to use by changing the second argument\n",
    "    if agent_config['memory'] == 'traj':\n",
    "        runner = Runner(env, memory_traj, agent, config['default_episode_index'])\n",
    "    elif agent_config['memory'] == 'traj_trans':\n",
    "        runner = Runner(env, memory_traj_trans, agent, config['default_episode_index'])\n",
    "    elif agent_config['memory'] == 'trans':\n",
    "        runner = Runner(env, memory_trans, agent, config['default_episode_index'])\n",
    "\n",
    "    return runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc33d67",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba1c54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\", config={**agent_config, **config}) as run:\n",
    "        # Recalculate the hidden dims and lstm dims\n",
    "        nlp_width = wandb.config[\"nlp_width\"]\n",
    "        nlp_length = wandb.config[\"nlp_length\"]\n",
    "        lstm_width = wandb.config[\"lstm_width\"]\n",
    "        lstm_length = wandb.config[\"lstm_length\"]\n",
    "        dims = {\n",
    "            \"hidden_dims\" : [2**nlp_width for _ in range(nlp_length)],\n",
    "            \"lstm_dims\" : [2**lstm_width for _ in range(lstm_length)]\n",
    "        }\n",
    "\n",
    "        wandb.config.update(dims)\n",
    "\n",
    "        wandbconfig = wandb.config\n",
    "        runner = create_runner(wandbconfig)\n",
    "\n",
    "        batch_size = wandbconfig['batch_size']\n",
    "\n",
    "        n_eps = wandbconfig['n_eps']\n",
    "        print_each = 50\n",
    "        test_each = wandbconfig['test_each']\n",
    "        n_test_episodes = wandbconfig['n_test_episodes']\n",
    "\n",
    "        keys_to_print = ['reward', 'greedy_reward', 'deterministic_reward', 'max_reward']\n",
    "\n",
    "        train_results = defaultdict(list)\n",
    "        test_results = defaultdict(list)\n",
    "\n",
    "        for ep in range(1, n_eps):\n",
    "            episode_results = runner.run(train=True, save_to_memory=True, train_bath_size=batch_size)\n",
    "\n",
    "            for key, val in episode_results.items():\n",
    "                train_results[key].append(val)\n",
    "                wandb.log({f\"train_{key}\": val, \"epoch\":ep})\n",
    "\n",
    "            if ep % print_each == 0:\n",
    "                print('Training episode %d    ' % ep)\n",
    "\n",
    "                for key in keys_to_print:\n",
    "                    if key in train_results:\n",
    "                        print('    %s=%.2f' % (key, np.mean(train_results[key][-print_each:])))\n",
    "\n",
    "                print()\n",
    "\n",
    "            if ep % test_each == 0:\n",
    "                current_test_results = defaultdict(list)\n",
    "\n",
    "                for test_ep in range(n_test_episodes):\n",
    "                    episode_results = runner.run(train=False, save_to_memory=False)\n",
    "\n",
    "                    for key, val in episode_results.items():\n",
    "                        current_test_results[key].append(val)\n",
    "\n",
    "                current_test_results = {key: np.mean(val) for key, val in current_test_results.items()}\n",
    "\n",
    "                for key, val in current_test_results.items():\n",
    "                    test_results[key].append(val)\n",
    "                    wandb.log({f\"test_{key}\": val, \"epoch\":ep})\n",
    "\n",
    "                print('Test run after episode %d:' % ep)\n",
    "\n",
    "                for key in keys_to_print:\n",
    "                    if key in current_test_results:\n",
    "                        print('    %s=%.2f' % (key, current_test_results[key]))\n",
    "\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfransdb\u001b[0m (\u001b[33melectric-vehicle-charging\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fransdeboer/Projects/RL-EVCP/wandb/run-20220603_034202-2c1qeiul</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/electric-vehicle-charging/electric-vehicle-charging-rl/runs/2c1qeiul\" target=\"_blank\">devoted-hill-155</a></strong> to <a href=\"https://wandb.ai/electric-vehicle-charging/electric-vehicle-charging-rl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 50    \n",
      "    reward=290.70\n",
      "\n",
      "Test run after episode 50:\n",
      "    reward=192.59\n",
      "    greedy_reward=212.51\n",
      "    deterministic_reward=213.93\n",
      "    max_reward=216.39\n",
      "\n",
      "Training episode 100    \n",
      "    reward=250.45\n",
      "\n",
      "Test run after episode 100:\n",
      "    reward=292.05\n",
      "    greedy_reward=304.56\n",
      "    deterministic_reward=344.68\n",
      "    max_reward=420.33\n",
      "\n",
      "Training episode 150    \n",
      "    reward=220.49\n",
      "\n",
      "Test run after episode 150:\n",
      "    reward=191.32\n",
      "    greedy_reward=301.19\n",
      "    deterministic_reward=304.11\n",
      "    max_reward=308.80\n",
      "\n",
      "Training episode 200    \n",
      "    reward=263.98\n",
      "\n",
      "Test run after episode 200:\n",
      "    reward=144.15\n",
      "    greedy_reward=162.08\n",
      "    deterministic_reward=176.86\n",
      "    max_reward=180.13\n",
      "\n",
      "Training episode 250    \n",
      "    reward=218.85\n",
      "\n",
      "Test run after episode 250:\n",
      "    reward=148.39\n",
      "    greedy_reward=419.09\n",
      "    deterministic_reward=421.55\n",
      "    max_reward=494.16\n",
      "\n",
      "Training episode 300    \n",
      "    reward=125.36\n",
      "\n",
      "Test run after episode 300:\n",
      "    reward=90.54\n",
      "    greedy_reward=319.24\n",
      "    deterministic_reward=335.58\n",
      "    max_reward=402.82\n",
      "\n",
      "Training episode 350    \n",
      "    reward=151.38\n",
      "\n",
      "Test run after episode 350:\n",
      "    reward=172.67\n",
      "    greedy_reward=227.15\n",
      "    deterministic_reward=249.85\n",
      "    max_reward=260.05\n",
      "\n",
      "Training episode 400    \n",
      "    reward=291.82\n",
      "\n",
      "Test run after episode 400:\n",
      "    reward=372.35\n",
      "    greedy_reward=420.78\n",
      "    deterministic_reward=436.53\n",
      "    max_reward=464.49\n",
      "\n",
      "Training episode 450    \n",
      "    reward=320.31\n",
      "\n",
      "Test run after episode 450:\n",
      "    reward=270.51\n",
      "    greedy_reward=279.27\n",
      "    deterministic_reward=310.11\n",
      "    max_reward=320.38\n",
      "\n",
      "Training episode 500    \n",
      "    reward=331.36\n",
      "\n",
      "Test run after episode 500:\n",
      "    reward=241.43\n",
      "    greedy_reward=312.29\n",
      "    deterministic_reward=313.79\n",
      "    max_reward=348.53\n",
      "\n",
      "Training episode 550    \n",
      "    reward=301.22\n",
      "\n",
      "Test run after episode 550:\n",
      "    reward=238.51\n",
      "    greedy_reward=300.62\n",
      "    deterministic_reward=304.55\n",
      "    max_reward=311.28\n",
      "\n",
      "Training episode 600    \n",
      "    reward=257.83\n",
      "\n",
      "Test run after episode 600:\n",
      "    reward=221.82\n",
      "    greedy_reward=309.28\n",
      "    deterministic_reward=321.49\n",
      "    max_reward=328.14\n",
      "\n",
      "Training episode 650    \n",
      "    reward=257.87\n",
      "\n",
      "Test run after episode 650:\n",
      "    reward=268.87\n",
      "    greedy_reward=326.42\n",
      "    deterministic_reward=330.49\n",
      "    max_reward=372.69\n",
      "\n",
      "Training episode 700    \n",
      "    reward=250.41\n",
      "\n",
      "Test run after episode 700:\n",
      "    reward=191.89\n",
      "    greedy_reward=297.23\n",
      "    deterministic_reward=301.39\n",
      "    max_reward=306.99\n",
      "\n",
      "Training episode 750    \n",
      "    reward=258.55\n",
      "\n",
      "Test run after episode 750:\n",
      "    reward=275.08\n",
      "    greedy_reward=330.78\n",
      "    deterministic_reward=341.34\n",
      "    max_reward=356.99\n",
      "\n",
      "Training episode 800    \n",
      "    reward=266.89\n",
      "\n",
      "Test run after episode 800:\n",
      "    reward=267.03\n",
      "    greedy_reward=324.46\n",
      "    deterministic_reward=322.74\n",
      "    max_reward=349.47\n",
      "\n",
      "Training episode 850    \n",
      "    reward=307.22\n",
      "\n",
      "Test run after episode 850:\n",
      "    reward=363.51\n",
      "    greedy_reward=374.39\n",
      "    deterministic_reward=389.97\n",
      "    max_reward=443.55\n",
      "\n",
      "Training episode 900    \n",
      "    reward=319.21\n",
      "\n",
      "Test run after episode 900:\n",
      "    reward=261.57\n",
      "    greedy_reward=320.88\n",
      "    deterministic_reward=331.54\n",
      "    max_reward=335.06\n",
      "\n",
      "Training episode 950    \n",
      "    reward=278.01\n",
      "\n",
      "Test run after episode 950:\n",
      "    reward=314.51\n",
      "    greedy_reward=312.83\n",
      "    deterministic_reward=347.43\n",
      "    max_reward=376.24\n",
      "\n",
      "Training episode 1000    \n",
      "    reward=287.99\n",
      "\n",
      "Test run after episode 1000:\n",
      "    reward=353.97\n",
      "    greedy_reward=428.21\n",
      "    deterministic_reward=444.35\n",
      "    max_reward=505.74\n",
      "\n",
      "Training episode 1050    \n",
      "    reward=287.54\n",
      "\n",
      "Test run after episode 1050:\n",
      "    reward=232.28\n",
      "    greedy_reward=360.70\n",
      "    deterministic_reward=378.76\n",
      "    max_reward=404.39\n",
      "\n",
      "Training episode 1100    \n",
      "    reward=305.42\n",
      "\n",
      "Test run after episode 1100:\n",
      "    reward=302.04\n",
      "    greedy_reward=331.87\n",
      "    deterministic_reward=353.86\n",
      "    max_reward=388.53\n",
      "\n",
      "Training episode 1150    \n",
      "    reward=329.43\n",
      "\n",
      "Test run after episode 1150:\n",
      "    reward=448.54\n",
      "    greedy_reward=400.39\n",
      "    deterministic_reward=432.28\n",
      "    max_reward=480.85\n",
      "\n",
      "Training episode 1200    \n",
      "    reward=332.16\n",
      "\n",
      "Test run after episode 1200:\n",
      "    reward=275.12\n",
      "    greedy_reward=262.05\n",
      "    deterministic_reward=300.89\n",
      "    max_reward=312.29\n",
      "\n",
      "Training episode 1250    \n",
      "    reward=334.43\n",
      "\n",
      "Test run after episode 1250:\n",
      "    reward=353.14\n",
      "    greedy_reward=317.17\n",
      "    deterministic_reward=330.23\n",
      "    max_reward=357.57\n",
      "\n",
      "Training episode 1300    \n",
      "    reward=364.04\n",
      "\n",
      "Test run after episode 1300:\n",
      "    reward=346.68\n",
      "    greedy_reward=273.05\n",
      "    deterministic_reward=331.67\n",
      "    max_reward=349.76\n",
      "\n",
      "Training episode 1350    \n",
      "    reward=360.35\n",
      "\n",
      "Test run after episode 1350:\n",
      "    reward=487.81\n",
      "    greedy_reward=329.17\n",
      "    deterministic_reward=328.74\n",
      "    max_reward=490.58\n",
      "\n",
      "Training episode 1400    \n",
      "    reward=375.51\n",
      "\n",
      "Test run after episode 1400:\n",
      "    reward=352.79\n",
      "    greedy_reward=330.21\n",
      "    deterministic_reward=342.29\n",
      "    max_reward=356.39\n",
      "\n",
      "Training episode 1450    \n",
      "    reward=354.23\n",
      "\n",
      "Test run after episode 1450:\n",
      "    reward=193.70\n",
      "    greedy_reward=180.65\n",
      "    deterministic_reward=190.56\n",
      "    max_reward=197.32\n",
      "\n",
      "Training episode 1500    \n",
      "    reward=352.00\n",
      "\n",
      "Test run after episode 1500:\n",
      "    reward=384.11\n",
      "    greedy_reward=350.80\n",
      "    deterministic_reward=372.77\n",
      "    max_reward=388.93\n",
      "\n",
      "Training episode 1550    \n",
      "    reward=357.05\n",
      "\n",
      "Test run after episode 1550:\n",
      "    reward=357.77\n",
      "    greedy_reward=331.90\n",
      "    deterministic_reward=350.96\n",
      "    max_reward=364.33\n",
      "\n",
      "Training episode 1600    \n",
      "    reward=356.99\n",
      "\n",
      "Test run after episode 1600:\n",
      "    reward=221.58\n",
      "    greedy_reward=220.47\n",
      "    deterministic_reward=222.14\n",
      "    max_reward=224.42\n",
      "\n",
      "Training episode 1650    \n",
      "    reward=352.13\n",
      "\n",
      "Test run after episode 1650:\n",
      "    reward=242.05\n",
      "    greedy_reward=240.83\n",
      "    deterministic_reward=241.96\n",
      "    max_reward=244.72\n",
      "\n",
      "Training episode 1700    \n",
      "    reward=376.48\n",
      "\n",
      "Test run after episode 1700:\n",
      "    reward=445.76\n",
      "    greedy_reward=356.61\n",
      "    deterministic_reward=397.94\n",
      "    max_reward=445.79\n",
      "\n",
      "Training episode 1750    \n",
      "    reward=357.84\n",
      "\n",
      "Test run after episode 1750:\n",
      "    reward=394.60\n",
      "    greedy_reward=333.27\n",
      "    deterministic_reward=373.95\n",
      "    max_reward=394.60\n",
      "\n",
      "Training episode 1800    \n",
      "    reward=364.55\n",
      "\n",
      "Test run after episode 1800:\n",
      "    reward=338.13\n",
      "    greedy_reward=324.31\n",
      "    deterministic_reward=327.28\n",
      "    max_reward=338.13\n",
      "\n",
      "Training episode 1850    \n",
      "    reward=340.11\n",
      "\n",
      "Test run after episode 1850:\n",
      "    reward=341.83\n",
      "    greedy_reward=314.95\n",
      "    deterministic_reward=333.03\n",
      "    max_reward=341.84\n",
      "\n",
      "Training episode 1900    \n",
      "    reward=349.14\n",
      "\n",
      "Test run after episode 1900:\n",
      "    reward=475.26\n",
      "    greedy_reward=361.32\n",
      "    deterministic_reward=372.53\n",
      "    max_reward=475.27\n",
      "\n",
      "Training episode 1950    \n",
      "    reward=375.92\n",
      "\n",
      "Test run after episode 1950:\n",
      "    reward=508.78\n",
      "    greedy_reward=423.66\n",
      "    deterministic_reward=430.83\n",
      "    max_reward=508.79\n",
      "\n",
      "Training episode 2000    \n",
      "    reward=366.36\n",
      "\n",
      "Test run after episode 2000:\n",
      "    reward=343.93\n",
      "    greedy_reward=268.85\n",
      "    deterministic_reward=289.15\n",
      "    max_reward=343.94\n",
      "\n",
      "Training episode 2050    \n",
      "    reward=357.80\n",
      "\n",
      "Test run after episode 2050:\n",
      "    reward=212.32\n",
      "    greedy_reward=277.78\n",
      "    deterministic_reward=286.38\n",
      "    max_reward=294.07\n",
      "\n",
      "Training episode 2100    \n",
      "    reward=325.34\n",
      "\n",
      "Test run after episode 2100:\n",
      "    reward=392.57\n",
      "    greedy_reward=308.10\n",
      "    deterministic_reward=344.04\n",
      "    max_reward=421.03\n",
      "\n",
      "Training episode 2150    \n",
      "    reward=344.02\n",
      "\n",
      "Test run after episode 2150:\n",
      "    reward=299.01\n",
      "    greedy_reward=321.19\n",
      "    deterministic_reward=330.69\n",
      "    max_reward=339.85\n",
      "\n",
      "Training episode 2200    \n",
      "    reward=306.18\n",
      "\n",
      "Test run after episode 2200:\n",
      "    reward=232.97\n",
      "    greedy_reward=233.87\n",
      "    deterministic_reward=238.51\n",
      "    max_reward=248.75\n",
      "\n",
      "Training episode 2250    \n",
      "    reward=304.91\n",
      "\n",
      "Test run after episode 2250:\n",
      "    reward=283.37\n",
      "    greedy_reward=307.72\n",
      "    deterministic_reward=329.16\n",
      "    max_reward=338.72\n",
      "\n",
      "Training episode 2300    \n",
      "    reward=314.51\n",
      "\n",
      "Test run after episode 2300:\n",
      "    reward=311.05\n",
      "    greedy_reward=362.02\n",
      "    deterministic_reward=382.37\n",
      "    max_reward=389.33\n",
      "\n",
      "Training episode 2350    \n",
      "    reward=311.62\n",
      "\n",
      "Test run after episode 2350:\n",
      "    reward=328.31\n",
      "    greedy_reward=309.82\n",
      "    deterministic_reward=323.31\n",
      "    max_reward=386.71\n",
      "\n",
      "Training episode 2400    \n",
      "    reward=309.97\n",
      "\n",
      "Test run after episode 2400:\n",
      "    reward=347.77\n",
      "    greedy_reward=378.11\n",
      "    deterministic_reward=383.49\n",
      "    max_reward=450.36\n",
      "\n",
      "Training episode 2450    \n",
      "    reward=287.20\n",
      "\n",
      "Test run after episode 2450:\n",
      "    reward=240.48\n",
      "    greedy_reward=283.29\n",
      "    deterministic_reward=321.07\n",
      "    max_reward=325.59\n",
      "\n",
      "Training episode 2500    \n",
      "    reward=309.24\n",
      "\n",
      "Test run after episode 2500:\n",
      "    reward=176.10\n",
      "    greedy_reward=236.57\n",
      "    deterministic_reward=241.08\n",
      "    max_reward=254.27\n",
      "\n",
      "Training episode 2550    \n",
      "    reward=299.29\n",
      "\n",
      "Test run after episode 2550:\n",
      "    reward=335.09\n",
      "    greedy_reward=364.43\n",
      "    deterministic_reward=370.85\n",
      "    max_reward=412.20\n",
      "\n",
      "Training episode 2600    \n",
      "    reward=277.01\n",
      "\n",
      "Test run after episode 2600:\n",
      "    reward=203.08\n",
      "    greedy_reward=275.67\n",
      "    deterministic_reward=288.11\n",
      "    max_reward=296.38\n",
      "\n",
      "Training episode 2650    \n",
      "    reward=232.46\n",
      "\n",
      "Test run after episode 2650:\n",
      "    reward=177.50\n",
      "    greedy_reward=340.72\n",
      "    deterministic_reward=381.99\n",
      "    max_reward=391.86\n",
      "\n",
      "Training episode 2700    \n",
      "    reward=232.83\n",
      "\n",
      "Test run after episode 2700:\n",
      "    reward=264.69\n",
      "    greedy_reward=373.86\n",
      "    deterministic_reward=397.64\n",
      "    max_reward=406.23\n",
      "\n",
      "Training episode 2750    \n",
      "    reward=206.12\n",
      "\n",
      "Test run after episode 2750:\n",
      "    reward=220.17\n",
      "    greedy_reward=364.84\n",
      "    deterministic_reward=383.35\n",
      "    max_reward=388.68\n",
      "\n",
      "Training episode 2800    \n",
      "    reward=201.05\n",
      "\n",
      "Test run after episode 2800:\n",
      "    reward=86.29\n",
      "    greedy_reward=231.61\n",
      "    deterministic_reward=239.79\n",
      "    max_reward=248.68\n",
      "\n",
      "Training episode 2850    \n",
      "    reward=194.85\n",
      "\n",
      "Test run after episode 2850:\n",
      "    reward=384.86\n",
      "    greedy_reward=448.17\n",
      "    deterministic_reward=456.09\n",
      "    max_reward=573.55\n",
      "\n",
      "Training episode 2900    \n",
      "    reward=180.37\n",
      "\n",
      "Test run after episode 2900:\n",
      "    reward=184.84\n",
      "    greedy_reward=292.91\n",
      "    deterministic_reward=304.79\n",
      "    max_reward=310.91\n",
      "\n",
      "Training episode 2950    \n",
      "    reward=166.73\n",
      "\n",
      "Test run after episode 2950:\n",
      "    reward=188.57\n",
      "    greedy_reward=367.64\n",
      "    deterministic_reward=376.98\n",
      "    max_reward=384.80\n",
      "\n",
      "Training episode 3000    \n",
      "    reward=184.38\n",
      "\n",
      "Test run after episode 3000:\n",
      "    reward=184.14\n",
      "    greedy_reward=289.71\n",
      "    deterministic_reward=351.89\n",
      "    max_reward=364.43\n",
      "\n",
      "Training episode 3050    \n",
      "    reward=168.77\n",
      "\n",
      "Test run after episode 3050:\n",
      "    reward=147.06\n",
      "    greedy_reward=364.24\n",
      "    deterministic_reward=366.18\n",
      "    max_reward=428.56\n",
      "\n",
      "Training episode 3100    \n",
      "    reward=168.42\n",
      "\n",
      "Test run after episode 3100:\n",
      "    reward=228.17\n",
      "    greedy_reward=336.91\n",
      "    deterministic_reward=345.03\n",
      "    max_reward=388.39\n",
      "\n",
      "Training episode 3150    \n",
      "    reward=185.56\n",
      "\n",
      "Test run after episode 3150:\n",
      "    reward=210.51\n",
      "    greedy_reward=305.67\n",
      "    deterministic_reward=344.73\n",
      "    max_reward=401.28\n",
      "\n",
      "Training episode 3200    \n",
      "    reward=178.91\n",
      "\n",
      "Test run after episode 3200:\n",
      "    reward=104.32\n",
      "    greedy_reward=221.41\n",
      "    deterministic_reward=247.37\n",
      "    max_reward=257.48\n",
      "\n",
      "Training episode 3250    \n",
      "    reward=192.72\n",
      "\n",
      "Test run after episode 3250:\n",
      "    reward=146.64\n",
      "    greedy_reward=293.00\n",
      "    deterministic_reward=303.03\n",
      "    max_reward=311.13\n",
      "\n",
      "Training episode 3300    \n",
      "    reward=189.64\n",
      "\n",
      "Test run after episode 3300:\n",
      "    reward=249.55\n",
      "    greedy_reward=338.31\n",
      "    deterministic_reward=340.59\n",
      "    max_reward=419.39\n",
      "\n",
      "Training episode 3350    \n",
      "    reward=209.06\n",
      "\n",
      "Test run after episode 3350:\n",
      "    reward=143.83\n",
      "    greedy_reward=353.09\n",
      "    deterministic_reward=352.91\n",
      "    max_reward=432.11\n",
      "\n",
      "Training episode 3400    \n",
      "    reward=193.66\n",
      "\n",
      "Test run after episode 3400:\n",
      "    reward=176.31\n",
      "    greedy_reward=300.60\n",
      "    deterministic_reward=299.17\n",
      "    max_reward=386.11\n",
      "\n",
      "Training episode 3450    \n",
      "    reward=196.18\n",
      "\n",
      "Test run after episode 3450:\n",
      "    reward=267.75\n",
      "    greedy_reward=344.82\n",
      "    deterministic_reward=352.08\n",
      "    max_reward=481.43\n",
      "\n",
      "Training episode 3500    \n",
      "    reward=188.53\n",
      "\n",
      "Test run after episode 3500:\n",
      "    reward=173.94\n",
      "    greedy_reward=317.68\n",
      "    deterministic_reward=338.20\n",
      "    max_reward=345.19\n",
      "\n",
      "Training episode 3550    \n",
      "    reward=220.58\n",
      "\n",
      "Test run after episode 3550:\n",
      "    reward=248.52\n",
      "    greedy_reward=404.95\n",
      "    deterministic_reward=411.74\n",
      "    max_reward=502.99\n",
      "\n",
      "Training episode 3600    \n",
      "    reward=193.36\n",
      "\n",
      "Test run after episode 3600:\n",
      "    reward=281.25\n",
      "    greedy_reward=337.68\n",
      "    deterministic_reward=377.80\n",
      "    max_reward=428.39\n",
      "\n",
      "Training episode 3650    \n",
      "    reward=219.06\n",
      "\n",
      "Test run after episode 3650:\n",
      "    reward=154.84\n",
      "    greedy_reward=294.78\n",
      "    deterministic_reward=319.56\n",
      "    max_reward=325.08\n",
      "\n",
      "Training episode 3700    \n",
      "    reward=214.27\n",
      "\n",
      "Test run after episode 3700:\n",
      "    reward=135.71\n",
      "    greedy_reward=287.40\n",
      "    deterministic_reward=287.49\n",
      "    max_reward=305.64\n",
      "\n",
      "Training episode 3750    \n",
      "    reward=206.40\n",
      "\n",
      "Test run after episode 3750:\n",
      "    reward=291.54\n",
      "    greedy_reward=328.19\n",
      "    deterministic_reward=407.88\n",
      "    max_reward=456.74\n",
      "\n",
      "Training episode 3800    \n",
      "    reward=204.00\n",
      "\n",
      "Test run after episode 3800:\n",
      "    reward=201.40\n",
      "    greedy_reward=334.85\n",
      "    deterministic_reward=347.96\n",
      "    max_reward=380.77\n",
      "\n",
      "Training episode 3850    \n",
      "    reward=205.54\n",
      "\n",
      "Test run after episode 3850:\n",
      "    reward=169.30\n",
      "    greedy_reward=255.12\n",
      "    deterministic_reward=270.98\n",
      "    max_reward=303.89\n",
      "\n",
      "Training episode 3900    \n",
      "    reward=221.22\n",
      "\n",
      "Test run after episode 3900:\n",
      "    reward=133.23\n",
      "    greedy_reward=203.65\n",
      "    deterministic_reward=212.62\n",
      "    max_reward=217.78\n",
      "\n",
      "Training episode 3950    \n",
      "    reward=215.31\n",
      "\n",
      "Test run after episode 3950:\n",
      "    reward=137.56\n",
      "    greedy_reward=357.68\n",
      "    deterministic_reward=375.10\n",
      "    max_reward=380.49\n",
      "\n",
      "Training episode 4000    \n",
      "    reward=214.53\n",
      "\n",
      "Test run after episode 4000:\n",
      "    reward=164.79\n",
      "    greedy_reward=323.65\n",
      "    deterministic_reward=349.54\n",
      "    max_reward=389.92\n",
      "\n",
      "Training episode 4050    \n",
      "    reward=206.92\n",
      "\n",
      "Test run after episode 4050:\n",
      "    reward=174.59\n",
      "    greedy_reward=277.08\n",
      "    deterministic_reward=282.58\n",
      "    max_reward=298.05\n",
      "\n",
      "Training episode 4100    \n",
      "    reward=200.30\n",
      "\n",
      "Test run after episode 4100:\n",
      "    reward=193.32\n",
      "    greedy_reward=236.35\n",
      "    deterministic_reward=259.20\n",
      "    max_reward=288.05\n",
      "\n",
      "Training episode 4150    \n",
      "    reward=196.80\n",
      "\n",
      "Test run after episode 4150:\n",
      "    reward=250.57\n",
      "    greedy_reward=318.59\n",
      "    deterministic_reward=317.02\n",
      "    max_reward=449.63\n",
      "\n",
      "Training episode 4200    \n",
      "    reward=207.14\n",
      "\n",
      "Test run after episode 4200:\n",
      "    reward=181.20\n",
      "    greedy_reward=258.58\n",
      "    deterministic_reward=275.55\n",
      "    max_reward=279.75\n",
      "\n",
      "Training episode 4250    \n",
      "    reward=226.89\n",
      "\n",
      "Test run after episode 4250:\n",
      "    reward=157.78\n",
      "    greedy_reward=317.35\n",
      "    deterministic_reward=332.97\n",
      "    max_reward=360.79\n",
      "\n",
      "Training episode 4300    \n",
      "    reward=193.67\n",
      "\n",
      "Test run after episode 4300:\n",
      "    reward=118.96\n",
      "    greedy_reward=303.14\n",
      "    deterministic_reward=311.24\n",
      "    max_reward=318.33\n",
      "\n",
      "Training episode 4350    \n",
      "    reward=203.02\n",
      "\n",
      "Test run after episode 4350:\n",
      "    reward=152.33\n",
      "    greedy_reward=240.97\n",
      "    deterministic_reward=298.41\n",
      "    max_reward=305.61\n",
      "\n",
      "Training episode 4400    \n",
      "    reward=202.83\n",
      "\n",
      "Test run after episode 4400:\n",
      "    reward=179.90\n",
      "    greedy_reward=286.52\n",
      "    deterministic_reward=309.68\n",
      "    max_reward=313.70\n",
      "\n",
      "Training episode 4450    \n",
      "    reward=201.65\n",
      "\n",
      "Test run after episode 4450:\n",
      "    reward=164.44\n",
      "    greedy_reward=283.29\n",
      "    deterministic_reward=304.32\n",
      "    max_reward=315.84\n",
      "\n",
      "Training episode 4500    \n",
      "    reward=206.17\n",
      "\n",
      "Test run after episode 4500:\n",
      "    reward=216.97\n",
      "    greedy_reward=366.78\n",
      "    deterministic_reward=378.68\n",
      "    max_reward=420.00\n",
      "\n",
      "Training episode 4550    \n",
      "    reward=203.58\n",
      "\n",
      "Test run after episode 4550:\n",
      "    reward=210.47\n",
      "    greedy_reward=405.77\n",
      "    deterministic_reward=451.30\n",
      "    max_reward=461.15\n",
      "\n",
      "Training episode 4600    \n",
      "    reward=217.04\n",
      "\n",
      "Test run after episode 4600:\n",
      "    reward=251.58\n",
      "    greedy_reward=308.80\n",
      "    deterministic_reward=306.54\n",
      "    max_reward=410.55\n",
      "\n",
      "Training episode 4650    \n",
      "    reward=223.44\n",
      "\n",
      "Test run after episode 4650:\n",
      "    reward=201.56\n",
      "    greedy_reward=264.48\n",
      "    deterministic_reward=268.73\n",
      "    max_reward=307.04\n",
      "\n",
      "Training episode 4700    \n",
      "    reward=205.62\n",
      "\n",
      "Test run after episode 4700:\n",
      "    reward=184.76\n",
      "    greedy_reward=308.15\n",
      "    deterministic_reward=357.62\n",
      "    max_reward=368.35\n",
      "\n",
      "Training episode 4750    \n",
      "    reward=207.39\n",
      "\n",
      "Test run after episode 4750:\n",
      "    reward=236.41\n",
      "    greedy_reward=338.62\n",
      "    deterministic_reward=355.03\n",
      "    max_reward=419.71\n",
      "\n",
      "Training episode 4800    \n",
      "    reward=217.73\n",
      "\n",
      "Test run after episode 4800:\n",
      "    reward=142.19\n",
      "    greedy_reward=237.97\n",
      "    deterministic_reward=244.05\n",
      "    max_reward=246.56\n",
      "\n",
      "Training episode 4850    \n",
      "    reward=215.00\n",
      "\n",
      "Test run after episode 4850:\n",
      "    reward=299.36\n",
      "    greedy_reward=347.40\n",
      "    deterministic_reward=356.18\n",
      "    max_reward=437.90\n",
      "\n",
      "Training episode 4900    \n",
      "    reward=204.59\n",
      "\n",
      "Test run after episode 4900:\n",
      "    reward=280.55\n",
      "    greedy_reward=431.19\n",
      "    deterministic_reward=440.24\n",
      "    max_reward=590.73\n",
      "\n",
      "Training episode 4950    \n",
      "    reward=196.89\n",
      "\n",
      "Test run after episode 4950:\n",
      "    reward=269.46\n",
      "    greedy_reward=381.89\n",
      "    deterministic_reward=382.10\n",
      "    max_reward=425.00\n",
      "\n",
      "Training episode 5000    \n",
      "    reward=196.91\n",
      "\n",
      "Test run after episode 5000:\n",
      "    reward=249.74\n",
      "    greedy_reward=316.23\n",
      "    deterministic_reward=335.12\n",
      "    max_reward=377.61\n",
      "\n",
      "Training episode 5050    \n",
      "    reward=223.26\n",
      "\n",
      "Test run after episode 5050:\n",
      "    reward=158.26\n",
      "    greedy_reward=225.07\n",
      "    deterministic_reward=261.34\n",
      "    max_reward=268.34\n",
      "\n",
      "Training episode 5100    \n",
      "    reward=200.15\n",
      "\n",
      "Test run after episode 5100:\n",
      "    reward=227.04\n",
      "    greedy_reward=308.10\n",
      "    deterministic_reward=333.39\n",
      "    max_reward=344.84\n",
      "\n",
      "Training episode 5150    \n",
      "    reward=201.70\n",
      "\n",
      "Test run after episode 5150:\n",
      "    reward=130.17\n",
      "    greedy_reward=217.18\n",
      "    deterministic_reward=229.27\n",
      "    max_reward=234.38\n",
      "\n",
      "Training episode 5200    \n",
      "    reward=213.80\n",
      "\n",
      "Test run after episode 5200:\n",
      "    reward=147.65\n",
      "    greedy_reward=255.33\n",
      "    deterministic_reward=268.73\n",
      "    max_reward=273.49\n",
      "\n",
      "Training episode 5250    \n",
      "    reward=204.28\n",
      "\n",
      "Test run after episode 5250:\n",
      "    reward=182.06\n",
      "    greedy_reward=255.89\n",
      "    deterministic_reward=289.34\n",
      "    max_reward=300.39\n",
      "\n",
      "Training episode 5300    \n",
      "    reward=209.67\n",
      "\n",
      "Test run after episode 5300:\n",
      "    reward=184.50\n",
      "    greedy_reward=411.45\n",
      "    deterministic_reward=410.95\n",
      "    max_reward=444.13\n",
      "\n",
      "Training episode 5350    \n",
      "    reward=188.04\n",
      "\n",
      "Test run after episode 5350:\n",
      "    reward=175.39\n",
      "    greedy_reward=309.16\n",
      "    deterministic_reward=341.08\n",
      "    max_reward=393.53\n",
      "\n",
      "Training episode 5400    \n",
      "    reward=197.78\n",
      "\n",
      "Test run after episode 5400:\n",
      "    reward=129.16\n",
      "    greedy_reward=271.22\n",
      "    deterministic_reward=290.18\n",
      "    max_reward=308.82\n",
      "\n",
      "Training episode 5450    \n",
      "    reward=190.94\n",
      "\n",
      "Test run after episode 5450:\n",
      "    reward=196.04\n",
      "    greedy_reward=317.49\n",
      "    deterministic_reward=348.00\n",
      "    max_reward=370.63\n",
      "\n",
      "Training episode 5500    \n",
      "    reward=204.44\n",
      "\n",
      "Test run after episode 5500:\n",
      "    reward=258.01\n",
      "    greedy_reward=360.29\n",
      "    deterministic_reward=368.40\n",
      "    max_reward=418.97\n",
      "\n",
      "Training episode 5550    \n",
      "    reward=204.80\n",
      "\n",
      "Test run after episode 5550:\n",
      "    reward=334.67\n",
      "    greedy_reward=427.53\n",
      "    deterministic_reward=432.56\n",
      "    max_reward=540.22\n",
      "\n",
      "Training episode 5600    \n",
      "    reward=199.59\n",
      "\n",
      "Test run after episode 5600:\n",
      "    reward=179.16\n",
      "    greedy_reward=338.50\n",
      "    deterministic_reward=346.76\n",
      "    max_reward=357.25\n",
      "\n",
      "Training episode 5650    \n",
      "    reward=196.52\n",
      "\n",
      "Test run after episode 5650:\n",
      "    reward=130.31\n",
      "    greedy_reward=257.76\n",
      "    deterministic_reward=280.99\n",
      "    max_reward=288.21\n",
      "\n",
      "Training episode 5700    \n",
      "    reward=205.48\n",
      "\n",
      "Test run after episode 5700:\n",
      "    reward=217.55\n",
      "    greedy_reward=305.48\n",
      "    deterministic_reward=323.49\n",
      "    max_reward=376.16\n",
      "\n",
      "Training episode 5750    \n",
      "    reward=203.30\n",
      "\n",
      "Test run after episode 5750:\n",
      "    reward=203.72\n",
      "    greedy_reward=415.47\n",
      "    deterministic_reward=441.37\n",
      "    max_reward=489.44\n",
      "\n",
      "Training episode 5800    \n",
      "    reward=210.02\n",
      "\n",
      "Test run after episode 5800:\n",
      "    reward=136.76\n",
      "    greedy_reward=251.54\n",
      "    deterministic_reward=264.87\n",
      "    max_reward=269.92\n",
      "\n",
      "Training episode 5850    \n",
      "    reward=223.13\n",
      "\n",
      "Test run after episode 5850:\n",
      "    reward=97.86\n",
      "    greedy_reward=257.21\n",
      "    deterministic_reward=259.11\n",
      "    max_reward=262.16\n",
      "\n",
      "Training episode 5900    \n",
      "    reward=223.29\n",
      "\n",
      "Test run after episode 5900:\n",
      "    reward=101.43\n",
      "    greedy_reward=294.26\n",
      "    deterministic_reward=329.68\n",
      "    max_reward=378.71\n",
      "\n",
      "Training episode 5950    \n",
      "    reward=197.74\n",
      "\n",
      "Test run after episode 5950:\n",
      "    reward=215.54\n",
      "    greedy_reward=323.19\n",
      "    deterministic_reward=357.53\n",
      "    max_reward=367.52\n",
      "\n",
      "Training episode 6000    \n",
      "    reward=212.06\n",
      "\n",
      "Test run after episode 6000:\n",
      "    reward=197.18\n",
      "    greedy_reward=356.48\n",
      "    deterministic_reward=374.52\n",
      "    max_reward=439.60\n",
      "\n",
      "Training episode 6050    \n",
      "    reward=212.39\n",
      "\n",
      "Test run after episode 6050:\n",
      "    reward=147.00\n",
      "    greedy_reward=388.96\n",
      "    deterministic_reward=385.70\n",
      "    max_reward=467.40\n",
      "\n",
      "Training episode 6100    \n",
      "    reward=210.37\n",
      "\n",
      "Test run after episode 6100:\n",
      "    reward=237.99\n",
      "    greedy_reward=368.88\n",
      "    deterministic_reward=368.80\n",
      "    max_reward=398.76\n",
      "\n",
      "Training episode 6150    \n",
      "    reward=211.35\n",
      "\n",
      "Test run after episode 6150:\n",
      "    reward=210.95\n",
      "    greedy_reward=342.07\n",
      "    deterministic_reward=354.11\n",
      "    max_reward=373.11\n",
      "\n",
      "Training episode 6200    \n",
      "    reward=206.16\n",
      "\n",
      "Test run after episode 6200:\n",
      "    reward=196.74\n",
      "    greedy_reward=353.72\n",
      "    deterministic_reward=353.88\n",
      "    max_reward=501.41\n",
      "\n",
      "Training episode 6250    \n",
      "    reward=213.92\n",
      "\n",
      "Test run after episode 6250:\n",
      "    reward=267.36\n",
      "    greedy_reward=367.10\n",
      "    deterministic_reward=379.33\n",
      "    max_reward=415.59\n",
      "\n",
      "Training episode 6300    \n",
      "    reward=197.58\n",
      "\n",
      "Test run after episode 6300:\n",
      "    reward=207.89\n",
      "    greedy_reward=319.10\n",
      "    deterministic_reward=335.71\n",
      "    max_reward=352.65\n",
      "\n",
      "Training episode 6350    \n",
      "    reward=209.20\n",
      "\n",
      "Test run after episode 6350:\n",
      "    reward=149.00\n",
      "    greedy_reward=268.82\n",
      "    deterministic_reward=277.58\n",
      "    max_reward=315.49\n",
      "\n",
      "Training episode 6400    \n",
      "    reward=200.04\n",
      "\n",
      "Test run after episode 6400:\n",
      "    reward=174.40\n",
      "    greedy_reward=304.35\n",
      "    deterministic_reward=314.03\n",
      "    max_reward=324.76\n",
      "\n",
      "Training episode 6450    \n",
      "    reward=213.49\n",
      "\n",
      "Test run after episode 6450:\n",
      "    reward=319.62\n",
      "    greedy_reward=344.10\n",
      "    deterministic_reward=372.10\n",
      "    max_reward=437.66\n",
      "\n",
      "Training episode 6500    \n",
      "    reward=204.78\n",
      "\n",
      "Test run after episode 6500:\n",
      "    reward=105.55\n",
      "    greedy_reward=242.31\n",
      "    deterministic_reward=268.89\n",
      "    max_reward=271.43\n",
      "\n",
      "Training episode 6550    \n",
      "    reward=210.94\n",
      "\n",
      "Test run after episode 6550:\n",
      "    reward=206.20\n",
      "    greedy_reward=320.53\n",
      "    deterministic_reward=325.45\n",
      "    max_reward=337.73\n",
      "\n",
      "Training episode 6600    \n",
      "    reward=206.06\n",
      "\n",
      "Test run after episode 6600:\n",
      "    reward=153.38\n",
      "    greedy_reward=311.62\n",
      "    deterministic_reward=320.46\n",
      "    max_reward=325.63\n",
      "\n",
      "Training episode 6650    \n",
      "    reward=209.01\n",
      "\n",
      "Test run after episode 6650:\n",
      "    reward=139.39\n",
      "    greedy_reward=339.59\n",
      "    deterministic_reward=356.59\n",
      "    max_reward=366.99\n",
      "\n",
      "Training episode 6700    \n",
      "    reward=219.13\n",
      "\n",
      "Test run after episode 6700:\n",
      "    reward=229.11\n",
      "    greedy_reward=341.92\n",
      "    deterministic_reward=361.36\n",
      "    max_reward=367.03\n",
      "\n",
      "Training episode 6750    \n",
      "    reward=204.27\n",
      "\n",
      "Test run after episode 6750:\n",
      "    reward=247.49\n",
      "    greedy_reward=306.51\n",
      "    deterministic_reward=334.40\n",
      "    max_reward=340.60\n",
      "\n",
      "Training episode 6800    \n",
      "    reward=206.48\n",
      "\n",
      "Test run after episode 6800:\n",
      "    reward=183.92\n",
      "    greedy_reward=315.20\n",
      "    deterministic_reward=328.90\n",
      "    max_reward=336.68\n",
      "\n",
      "Training episode 6850    \n",
      "    reward=197.97\n",
      "\n",
      "Test run after episode 6850:\n",
      "    reward=222.41\n",
      "    greedy_reward=302.75\n",
      "    deterministic_reward=329.48\n",
      "    max_reward=412.77\n",
      "\n",
      "Training episode 6900    \n",
      "    reward=218.02\n",
      "\n",
      "Test run after episode 6900:\n",
      "    reward=166.38\n",
      "    greedy_reward=360.25\n",
      "    deterministic_reward=360.76\n",
      "    max_reward=469.28\n",
      "\n",
      "Training episode 6950    \n",
      "    reward=192.34\n",
      "\n",
      "Test run after episode 6950:\n",
      "    reward=189.75\n",
      "    greedy_reward=255.65\n",
      "    deterministic_reward=261.75\n",
      "    max_reward=267.05\n",
      "\n",
      "Training episode 7000    \n",
      "    reward=200.93\n",
      "\n",
      "Test run after episode 7000:\n",
      "    reward=206.95\n",
      "    greedy_reward=356.39\n",
      "    deterministic_reward=390.66\n",
      "    max_reward=426.20\n",
      "\n",
      "Training episode 7050    \n",
      "    reward=206.70\n",
      "\n",
      "Test run after episode 7050:\n",
      "    reward=222.17\n",
      "    greedy_reward=357.68\n",
      "    deterministic_reward=386.60\n",
      "    max_reward=392.05\n",
      "\n",
      "Training episode 7100    \n",
      "    reward=211.22\n",
      "\n",
      "Test run after episode 7100:\n",
      "    reward=229.79\n",
      "    greedy_reward=317.93\n",
      "    deterministic_reward=320.62\n",
      "    max_reward=340.49\n",
      "\n",
      "Training episode 7150    \n",
      "    reward=217.52\n",
      "\n",
      "Test run after episode 7150:\n",
      "    reward=194.23\n",
      "    greedy_reward=261.33\n",
      "    deterministic_reward=287.06\n",
      "    max_reward=332.84\n",
      "\n",
      "Training episode 7200    \n",
      "    reward=191.84\n",
      "\n",
      "Test run after episode 7200:\n",
      "    reward=196.48\n",
      "    greedy_reward=401.97\n",
      "    deterministic_reward=403.81\n",
      "    max_reward=458.20\n",
      "\n",
      "Training episode 7250    \n",
      "    reward=198.84\n",
      "\n",
      "Test run after episode 7250:\n",
      "    reward=202.18\n",
      "    greedy_reward=256.05\n",
      "    deterministic_reward=289.96\n",
      "    max_reward=310.95\n",
      "\n",
      "Training episode 7300    \n",
      "    reward=194.39\n",
      "\n",
      "Test run after episode 7300:\n",
      "    reward=176.13\n",
      "    greedy_reward=306.95\n",
      "    deterministic_reward=332.32\n",
      "    max_reward=344.83\n",
      "\n",
      "Training episode 7350    \n",
      "    reward=204.80\n",
      "\n",
      "Test run after episode 7350:\n",
      "    reward=169.76\n",
      "    greedy_reward=310.39\n",
      "    deterministic_reward=323.00\n",
      "    max_reward=328.22\n",
      "\n",
      "Training episode 7400    \n",
      "    reward=203.74\n",
      "\n",
      "Test run after episode 7400:\n",
      "    reward=173.70\n",
      "    greedy_reward=303.56\n",
      "    deterministic_reward=322.51\n",
      "    max_reward=331.07\n",
      "\n",
      "Training episode 7450    \n",
      "    reward=189.55\n",
      "\n",
      "Test run after episode 7450:\n",
      "    reward=220.94\n",
      "    greedy_reward=318.24\n",
      "    deterministic_reward=337.90\n",
      "    max_reward=346.37\n",
      "\n",
      "Training episode 7500    \n",
      "    reward=204.76\n",
      "\n",
      "Test run after episode 7500:\n",
      "    reward=157.61\n",
      "    greedy_reward=268.82\n",
      "    deterministic_reward=285.44\n",
      "    max_reward=291.00\n",
      "\n",
      "Training episode 7550    \n",
      "    reward=206.21\n",
      "\n",
      "Test run after episode 7550:\n",
      "    reward=291.11\n",
      "    greedy_reward=347.83\n",
      "    deterministic_reward=346.16\n",
      "    max_reward=500.79\n",
      "\n",
      "Training episode 7600    \n",
      "    reward=193.31\n",
      "\n",
      "Test run after episode 7600:\n",
      "    reward=202.49\n",
      "    greedy_reward=337.59\n",
      "    deterministic_reward=362.72\n",
      "    max_reward=383.06\n",
      "\n",
      "Training episode 7650    \n",
      "    reward=216.96\n",
      "\n",
      "Test run after episode 7650:\n",
      "    reward=77.24\n",
      "    greedy_reward=169.41\n",
      "    deterministic_reward=173.72\n",
      "    max_reward=175.61\n",
      "\n",
      "Training episode 7700    \n",
      "    reward=220.96\n",
      "\n",
      "Test run after episode 7700:\n",
      "    reward=318.59\n",
      "    greedy_reward=314.20\n",
      "    deterministic_reward=342.55\n",
      "    max_reward=493.75\n",
      "\n",
      "Training episode 7750    \n",
      "    reward=207.83\n",
      "\n",
      "Test run after episode 7750:\n",
      "    reward=165.00\n",
      "    greedy_reward=388.58\n",
      "    deterministic_reward=408.37\n",
      "    max_reward=427.40\n",
      "\n",
      "Training episode 7800    \n",
      "    reward=217.94\n",
      "\n",
      "Test run after episode 7800:\n",
      "    reward=219.02\n",
      "    greedy_reward=292.60\n",
      "    deterministic_reward=298.97\n",
      "    max_reward=304.36\n",
      "\n",
      "Training episode 7850    \n",
      "    reward=207.07\n",
      "\n",
      "Test run after episode 7850:\n",
      "    reward=98.43\n",
      "    greedy_reward=241.98\n",
      "    deterministic_reward=252.59\n",
      "    max_reward=255.74\n",
      "\n",
      "Training episode 7900    \n",
      "    reward=199.06\n",
      "\n",
      "Test run after episode 7900:\n",
      "    reward=118.39\n",
      "    greedy_reward=281.04\n",
      "    deterministic_reward=316.13\n",
      "    max_reward=329.53\n",
      "\n",
      "Training episode 7950    \n",
      "    reward=208.97\n",
      "\n",
      "Test run after episode 7950:\n",
      "    reward=190.09\n",
      "    greedy_reward=275.34\n",
      "    deterministic_reward=283.88\n",
      "    max_reward=345.94\n",
      "\n",
      "Training episode 8000    \n",
      "    reward=212.98\n",
      "\n",
      "Test run after episode 8000:\n",
      "    reward=178.40\n",
      "    greedy_reward=308.38\n",
      "    deterministic_reward=311.96\n",
      "    max_reward=337.37\n",
      "\n",
      "Training episode 8050    \n",
      "    reward=196.22\n",
      "\n",
      "Test run after episode 8050:\n",
      "    reward=187.97\n",
      "    greedy_reward=330.85\n",
      "    deterministic_reward=343.62\n",
      "    max_reward=368.83\n",
      "\n",
      "Training episode 8100    \n",
      "    reward=206.81\n",
      "\n",
      "Test run after episode 8100:\n",
      "    reward=314.19\n",
      "    greedy_reward=431.00\n",
      "    deterministic_reward=451.37\n",
      "    max_reward=546.33\n",
      "\n",
      "Training episode 8150    \n",
      "    reward=201.99\n",
      "\n",
      "Test run after episode 8150:\n",
      "    reward=143.67\n",
      "    greedy_reward=199.65\n",
      "    deterministic_reward=205.79\n",
      "    max_reward=207.91\n",
      "\n",
      "Training episode 8200    \n",
      "    reward=196.49\n",
      "\n",
      "Test run after episode 8200:\n",
      "    reward=210.41\n",
      "    greedy_reward=329.40\n",
      "    deterministic_reward=340.85\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 8250    \n",
      "    reward=216.22\n",
      "\n",
      "Test run after episode 8250:\n",
      "    reward=164.95\n",
      "    greedy_reward=291.79\n",
      "    deterministic_reward=315.20\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 8300    \n",
      "    reward=201.88\n",
      "\n",
      "Test run after episode 8300:\n",
      "    reward=212.26\n",
      "    greedy_reward=298.30\n",
      "    deterministic_reward=312.11\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 8350    \n",
      "    reward=212.95\n",
      "\n",
      "Test run after episode 8350:\n",
      "    reward=166.39\n",
      "    greedy_reward=277.11\n",
      "    deterministic_reward=299.52\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 8400    \n",
      "    reward=209.70\n",
      "\n",
      "Test run after episode 8400:\n",
      "    reward=204.21\n",
      "    greedy_reward=351.10\n",
      "    deterministic_reward=367.22\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 8450    \n",
      "    reward=206.47\n",
      "\n",
      "Test run after episode 8450:\n",
      "    reward=304.64\n",
      "    greedy_reward=349.82\n",
      "    deterministic_reward=346.49\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 8500    \n",
      "    reward=205.66\n",
      "\n",
      "Test run after episode 8500:\n",
      "    reward=209.76\n",
      "    greedy_reward=450.07\n",
      "    deterministic_reward=482.88\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 8550    \n",
      "    reward=207.88\n",
      "\n",
      "Test run after episode 8550:\n",
      "    reward=187.43\n",
      "    greedy_reward=302.94\n",
      "    deterministic_reward=328.40\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 8600    \n",
      "    reward=213.62\n",
      "\n",
      "Test run after episode 8600:\n",
      "    reward=161.21\n",
      "    greedy_reward=280.29\n",
      "    deterministic_reward=287.65\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 8650    \n",
      "    reward=207.21\n",
      "\n",
      "Test run after episode 8650:\n",
      "    reward=168.64\n",
      "    greedy_reward=291.96\n",
      "    deterministic_reward=297.41\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 8700    \n",
      "    reward=197.29\n",
      "\n",
      "Test run after episode 8700:\n",
      "    reward=188.07\n",
      "    greedy_reward=350.44\n",
      "    deterministic_reward=380.24\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 8750    \n",
      "    reward=209.20\n",
      "\n",
      "Test run after episode 8750:\n",
      "    reward=151.83\n",
      "    greedy_reward=279.22\n",
      "    deterministic_reward=287.91\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 8800    \n",
      "    reward=206.17\n",
      "\n",
      "Test run after episode 8800:\n",
      "    reward=201.75\n",
      "    greedy_reward=304.08\n",
      "    deterministic_reward=316.39\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 8850    \n",
      "    reward=204.44\n",
      "\n",
      "Test run after episode 8850:\n",
      "    reward=194.55\n",
      "    greedy_reward=223.27\n",
      "    deterministic_reward=225.08\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 8900    \n",
      "    reward=206.10\n",
      "\n",
      "Test run after episode 8900:\n",
      "    reward=171.86\n",
      "    greedy_reward=311.66\n",
      "    deterministic_reward=346.64\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 8950    \n",
      "    reward=205.98\n",
      "\n",
      "Test run after episode 8950:\n",
      "    reward=198.40\n",
      "    greedy_reward=342.69\n",
      "    deterministic_reward=372.74\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 9000    \n",
      "    reward=198.31\n",
      "\n",
      "Test run after episode 9000:\n",
      "    reward=190.03\n",
      "    greedy_reward=370.87\n",
      "    deterministic_reward=371.07\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 9050    \n",
      "    reward=192.37\n",
      "\n",
      "Test run after episode 9050:\n",
      "    reward=247.90\n",
      "    greedy_reward=285.75\n",
      "    deterministic_reward=329.73\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 9100    \n",
      "    reward=209.41\n",
      "\n",
      "Test run after episode 9100:\n",
      "    reward=178.39\n",
      "    greedy_reward=250.38\n",
      "    deterministic_reward=264.24\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 9150    \n",
      "    reward=210.64\n",
      "\n",
      "Test run after episode 9150:\n",
      "    reward=213.44\n",
      "    greedy_reward=352.83\n",
      "    deterministic_reward=368.96\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 9200    \n",
      "    reward=204.01\n",
      "\n",
      "Test run after episode 9200:\n",
      "    reward=199.11\n",
      "    greedy_reward=338.20\n",
      "    deterministic_reward=362.29\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 9250    \n",
      "    reward=220.87\n",
      "\n",
      "Test run after episode 9250:\n",
      "    reward=219.12\n",
      "    greedy_reward=314.91\n",
      "    deterministic_reward=338.16\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 9300    \n",
      "    reward=205.98\n",
      "\n",
      "Test run after episode 9300:\n",
      "    reward=350.33\n",
      "    greedy_reward=363.87\n",
      "    deterministic_reward=402.87\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 9350    \n",
      "    reward=201.59\n",
      "\n",
      "Test run after episode 9350:\n",
      "    reward=200.82\n",
      "    greedy_reward=293.12\n",
      "    deterministic_reward=330.04\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 9400    \n",
      "    reward=217.95\n",
      "\n",
      "Test run after episode 9400:\n",
      "    reward=245.24\n",
      "    greedy_reward=287.02\n",
      "    deterministic_reward=296.28\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 9450    \n",
      "    reward=211.17\n",
      "\n",
      "Test run after episode 9450:\n",
      "    reward=188.84\n",
      "    greedy_reward=296.19\n",
      "    deterministic_reward=313.11\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 9500    \n",
      "    reward=212.18\n",
      "\n",
      "Test run after episode 9500:\n",
      "    reward=232.83\n",
      "    greedy_reward=312.14\n",
      "    deterministic_reward=323.07\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 9550    \n",
      "    reward=222.34\n",
      "\n",
      "Test run after episode 9550:\n",
      "    reward=146.72\n",
      "    greedy_reward=231.18\n",
      "    deterministic_reward=236.24\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 9600    \n",
      "    reward=210.50\n",
      "\n",
      "Test run after episode 9600:\n",
      "    reward=197.50\n",
      "    greedy_reward=324.81\n",
      "    deterministic_reward=325.46\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 9650    \n",
      "    reward=214.32\n",
      "\n",
      "Test run after episode 9650:\n",
      "    reward=162.31\n",
      "    greedy_reward=302.48\n",
      "    deterministic_reward=314.16\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 9700    \n",
      "    reward=207.89\n",
      "\n",
      "Test run after episode 9700:\n",
      "    reward=191.53\n",
      "    greedy_reward=357.08\n",
      "    deterministic_reward=372.94\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 9750    \n",
      "    reward=209.87\n",
      "\n",
      "Test run after episode 9750:\n",
      "    reward=224.44\n",
      "    greedy_reward=361.35\n",
      "    deterministic_reward=375.81\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 9800    \n",
      "    reward=208.64\n",
      "\n",
      "Test run after episode 9800:\n",
      "    reward=168.46\n",
      "    greedy_reward=290.02\n",
      "    deterministic_reward=303.34\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 9850    \n",
      "    reward=192.79\n",
      "\n",
      "Test run after episode 9850:\n",
      "    reward=99.45\n",
      "    greedy_reward=213.88\n",
      "    deterministic_reward=215.61\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 9900    \n",
      "    reward=199.00\n",
      "\n",
      "Test run after episode 9900:\n",
      "    reward=173.87\n",
      "    greedy_reward=292.36\n",
      "    deterministic_reward=316.94\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 9950    \n",
      "    reward=206.92\n",
      "\n",
      "Test run after episode 9950:\n",
      "    reward=177.26\n",
      "    greedy_reward=259.95\n",
      "    deterministic_reward=273.93\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 10000    \n",
      "    reward=206.70\n",
      "\n",
      "Test run after episode 10000:\n",
      "    reward=228.26\n",
      "    greedy_reward=369.47\n",
      "    deterministic_reward=375.82\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 10050    \n",
      "    reward=195.86\n",
      "\n",
      "Test run after episode 10050:\n",
      "    reward=218.96\n",
      "    greedy_reward=392.47\n",
      "    deterministic_reward=405.97\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 10100    \n",
      "    reward=197.60\n",
      "\n",
      "Test run after episode 10100:\n",
      "    reward=218.48\n",
      "    greedy_reward=334.04\n",
      "    deterministic_reward=357.61\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 10150    \n",
      "    reward=214.55\n",
      "\n",
      "Test run after episode 10150:\n",
      "    reward=211.16\n",
      "    greedy_reward=342.81\n",
      "    deterministic_reward=380.79\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 10200    \n",
      "    reward=196.75\n",
      "\n",
      "Test run after episode 10200:\n",
      "    reward=259.54\n",
      "    greedy_reward=315.31\n",
      "    deterministic_reward=349.68\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 10250    \n",
      "    reward=218.89\n",
      "\n",
      "Test run after episode 10250:\n",
      "    reward=94.15\n",
      "    greedy_reward=341.85\n",
      "    deterministic_reward=341.06\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 10300    \n",
      "    reward=206.10\n",
      "\n",
      "Test run after episode 10300:\n",
      "    reward=110.30\n",
      "    greedy_reward=303.01\n",
      "    deterministic_reward=333.02\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 10350    \n",
      "    reward=210.18\n",
      "\n",
      "Test run after episode 10350:\n",
      "    reward=139.77\n",
      "    greedy_reward=225.51\n",
      "    deterministic_reward=230.89\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 10400    \n",
      "    reward=203.39\n",
      "\n",
      "Test run after episode 10400:\n",
      "    reward=312.15\n",
      "    greedy_reward=350.63\n",
      "    deterministic_reward=349.83\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 10450    \n",
      "    reward=199.75\n",
      "\n",
      "Test run after episode 10450:\n",
      "    reward=152.75\n",
      "    greedy_reward=231.43\n",
      "    deterministic_reward=236.96\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 10500    \n",
      "    reward=205.72\n",
      "\n",
      "Test run after episode 10500:\n",
      "    reward=143.96\n",
      "    greedy_reward=312.17\n",
      "    deterministic_reward=320.61\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 10550    \n",
      "    reward=195.20\n",
      "\n",
      "Test run after episode 10550:\n",
      "    reward=273.85\n",
      "    greedy_reward=314.92\n",
      "    deterministic_reward=365.85\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 10600    \n",
      "    reward=198.63\n",
      "\n",
      "Test run after episode 10600:\n",
      "    reward=238.62\n",
      "    greedy_reward=278.01\n",
      "    deterministic_reward=289.11\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 10650    \n",
      "    reward=216.40\n",
      "\n",
      "Test run after episode 10650:\n",
      "    reward=291.86\n",
      "    greedy_reward=387.69\n",
      "    deterministic_reward=389.44\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 10700    \n",
      "    reward=215.02\n",
      "\n",
      "Test run after episode 10700:\n",
      "    reward=178.65\n",
      "    greedy_reward=282.31\n",
      "    deterministic_reward=305.35\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 10750    \n",
      "    reward=203.48\n",
      "\n",
      "Test run after episode 10750:\n",
      "    reward=206.02\n",
      "    greedy_reward=259.54\n",
      "    deterministic_reward=290.52\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 10800    \n",
      "    reward=203.93\n",
      "\n",
      "Test run after episode 10800:\n",
      "    reward=302.03\n",
      "    greedy_reward=421.89\n",
      "    deterministic_reward=438.24\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 10850    \n",
      "    reward=211.03\n",
      "\n",
      "Test run after episode 10850:\n",
      "    reward=166.17\n",
      "    greedy_reward=266.59\n",
      "    deterministic_reward=276.51\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 10900    \n",
      "    reward=214.30\n",
      "\n",
      "Test run after episode 10900:\n",
      "    reward=139.36\n",
      "    greedy_reward=278.34\n",
      "    deterministic_reward=286.08\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 10950    \n",
      "    reward=205.70\n",
      "\n",
      "Test run after episode 10950:\n",
      "    reward=134.53\n",
      "    greedy_reward=213.27\n",
      "    deterministic_reward=227.89\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 11000    \n",
      "    reward=205.76\n",
      "\n",
      "Test run after episode 11000:\n",
      "    reward=213.21\n",
      "    greedy_reward=286.14\n",
      "    deterministic_reward=299.30\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 11050    \n",
      "    reward=200.47\n",
      "\n",
      "Test run after episode 11050:\n",
      "    reward=158.60\n",
      "    greedy_reward=312.46\n",
      "    deterministic_reward=321.26\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 11100    \n",
      "    reward=194.25\n",
      "\n",
      "Test run after episode 11100:\n",
      "    reward=223.29\n",
      "    greedy_reward=354.98\n",
      "    deterministic_reward=374.86\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 11150    \n",
      "    reward=203.17\n",
      "\n",
      "Test run after episode 11150:\n",
      "    reward=168.24\n",
      "    greedy_reward=285.31\n",
      "    deterministic_reward=314.99\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 11200    \n",
      "    reward=209.22\n",
      "\n",
      "Test run after episode 11200:\n",
      "    reward=186.05\n",
      "    greedy_reward=300.85\n",
      "    deterministic_reward=313.98\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 11250    \n",
      "    reward=216.85\n",
      "\n",
      "Test run after episode 11250:\n",
      "    reward=226.34\n",
      "    greedy_reward=363.19\n",
      "    deterministic_reward=378.06\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 11300    \n",
      "    reward=204.97\n",
      "\n",
      "Test run after episode 11300:\n",
      "    reward=200.97\n",
      "    greedy_reward=276.51\n",
      "    deterministic_reward=306.31\n",
      "    max_reward=319.32\n",
      "\n",
      "Training episode 11350    \n",
      "    reward=194.59\n",
      "\n",
      "Test run after episode 11350:\n",
      "    reward=106.52\n",
      "    greedy_reward=214.04\n",
      "    deterministic_reward=221.00\n",
      "    max_reward=225.34\n",
      "\n",
      "Training episode 11400    \n",
      "    reward=210.67\n",
      "\n",
      "Test run after episode 11400:\n",
      "    reward=262.45\n",
      "    greedy_reward=417.14\n",
      "    deterministic_reward=421.12\n",
      "    max_reward=546.74\n",
      "\n",
      "Training episode 11450    \n",
      "    reward=208.28\n",
      "\n",
      "Test run after episode 11450:\n",
      "    reward=139.32\n",
      "    greedy_reward=307.02\n",
      "    deterministic_reward=314.20\n",
      "    max_reward=319.65\n",
      "\n",
      "Training episode 11500    \n",
      "    reward=204.31\n",
      "\n",
      "Test run after episode 11500:\n",
      "    reward=129.19\n",
      "    greedy_reward=226.99\n",
      "    deterministic_reward=233.45\n",
      "    max_reward=243.54\n",
      "\n",
      "Training episode 11550    \n",
      "    reward=195.27\n",
      "\n",
      "Test run after episode 11550:\n",
      "    reward=155.91\n",
      "    greedy_reward=222.59\n",
      "    deterministic_reward=228.22\n",
      "    max_reward=230.71\n",
      "\n",
      "Training episode 11600    \n",
      "    reward=216.35\n",
      "\n",
      "Test run after episode 11600:\n",
      "    reward=206.35\n",
      "    greedy_reward=361.63\n",
      "    deterministic_reward=381.05\n",
      "    max_reward=410.50\n",
      "\n",
      "Training episode 11650    \n",
      "    reward=206.97\n",
      "\n",
      "Test run after episode 11650:\n",
      "    reward=206.51\n",
      "    greedy_reward=380.67\n",
      "    deterministic_reward=388.84\n",
      "    max_reward=403.17\n",
      "\n",
      "Training episode 11700    \n",
      "    reward=220.60\n",
      "\n",
      "Test run after episode 11700:\n",
      "    reward=239.12\n",
      "    greedy_reward=310.40\n",
      "    deterministic_reward=363.77\n",
      "    max_reward=411.02\n",
      "\n",
      "Training episode 11750    \n",
      "    reward=201.08\n",
      "\n",
      "Test run after episode 11750:\n",
      "    reward=179.40\n",
      "    greedy_reward=295.34\n",
      "    deterministic_reward=299.48\n",
      "    max_reward=300.75\n",
      "\n",
      "Training episode 11800    \n",
      "    reward=208.23\n",
      "\n",
      "Test run after episode 11800:\n",
      "    reward=211.02\n",
      "    greedy_reward=354.91\n",
      "    deterministic_reward=354.96\n",
      "    max_reward=375.10\n",
      "\n",
      "Training episode 11850    \n",
      "    reward=218.65\n",
      "\n",
      "Test run after episode 11850:\n",
      "    reward=125.27\n",
      "    greedy_reward=294.10\n",
      "    deterministic_reward=333.55\n",
      "    max_reward=347.72\n",
      "\n",
      "Training episode 11900    \n",
      "    reward=207.10\n",
      "\n",
      "Test run after episode 11900:\n",
      "    reward=213.82\n",
      "    greedy_reward=301.93\n",
      "    deterministic_reward=318.61\n",
      "    max_reward=333.23\n",
      "\n",
      "Training episode 11950    \n",
      "    reward=204.79\n",
      "\n",
      "Test run after episode 11950:\n",
      "    reward=187.15\n",
      "    greedy_reward=247.70\n",
      "    deterministic_reward=251.88\n",
      "    max_reward=315.38\n",
      "\n",
      "Training episode 12000    \n",
      "    reward=206.75\n",
      "\n",
      "Test run after episode 12000:\n",
      "    reward=157.26\n",
      "    greedy_reward=299.14\n",
      "    deterministic_reward=315.00\n",
      "    max_reward=344.52\n",
      "\n",
      "Training episode 12050    \n",
      "    reward=209.63\n",
      "\n",
      "Test run after episode 12050:\n",
      "    reward=201.03\n",
      "    greedy_reward=393.10\n",
      "    deterministic_reward=396.37\n",
      "    max_reward=501.64\n",
      "\n",
      "Training episode 12100    \n",
      "    reward=212.98\n",
      "\n",
      "Test run after episode 12100:\n",
      "    reward=141.14\n",
      "    greedy_reward=226.29\n",
      "    deterministic_reward=238.21\n",
      "    max_reward=240.74\n",
      "\n",
      "Training episode 12150    \n",
      "    reward=208.32\n",
      "\n",
      "Test run after episode 12150:\n",
      "    reward=222.62\n",
      "    greedy_reward=370.29\n",
      "    deterministic_reward=372.01\n",
      "    max_reward=429.00\n",
      "\n",
      "Training episode 12200    \n",
      "    reward=190.97\n",
      "\n",
      "Test run after episode 12200:\n",
      "    reward=213.73\n",
      "    greedy_reward=295.27\n",
      "    deterministic_reward=327.09\n",
      "    max_reward=332.83\n",
      "\n",
      "Training episode 12250    \n",
      "    reward=219.98\n",
      "\n",
      "Test run after episode 12250:\n",
      "    reward=127.52\n",
      "    greedy_reward=263.19\n",
      "    deterministic_reward=287.87\n",
      "    max_reward=292.08\n",
      "\n",
      "Training episode 12300    \n",
      "    reward=219.48\n",
      "\n",
      "Test run after episode 12300:\n",
      "    reward=74.58\n",
      "    greedy_reward=228.01\n",
      "    deterministic_reward=235.12\n",
      "    max_reward=237.14\n",
      "\n",
      "Training episode 12350    \n",
      "    reward=200.40\n",
      "\n",
      "Test run after episode 12350:\n",
      "    reward=178.12\n",
      "    greedy_reward=325.05\n",
      "    deterministic_reward=366.08\n",
      "    max_reward=395.37\n",
      "\n",
      "Training episode 12400    \n",
      "    reward=208.01\n",
      "\n",
      "Test run after episode 12400:\n",
      "    reward=149.57\n",
      "    greedy_reward=405.40\n",
      "    deterministic_reward=425.96\n",
      "    max_reward=434.18\n",
      "\n",
      "Training episode 12450    \n",
      "    reward=201.81\n",
      "\n",
      "Test run after episode 12450:\n",
      "    reward=176.46\n",
      "    greedy_reward=298.50\n",
      "    deterministic_reward=305.95\n",
      "    max_reward=312.22\n",
      "\n",
      "Training episode 12500    \n",
      "    reward=210.89\n",
      "\n",
      "Test run after episode 12500:\n",
      "    reward=133.78\n",
      "    greedy_reward=355.73\n",
      "    deterministic_reward=353.17\n",
      "    max_reward=470.55\n",
      "\n",
      "Training episode 12550    \n",
      "    reward=212.02\n",
      "\n",
      "Test run after episode 12550:\n",
      "    reward=169.86\n",
      "    greedy_reward=342.71\n",
      "    deterministic_reward=354.18\n",
      "    max_reward=360.32\n",
      "\n",
      "Training episode 12600    \n",
      "    reward=198.35\n",
      "\n",
      "Test run after episode 12600:\n",
      "    reward=248.65\n",
      "    greedy_reward=352.36\n",
      "    deterministic_reward=364.84\n",
      "    max_reward=389.11\n",
      "\n",
      "Training episode 12650    \n",
      "    reward=213.04\n",
      "\n",
      "Test run after episode 12650:\n",
      "    reward=216.19\n",
      "    greedy_reward=372.73\n",
      "    deterministic_reward=397.19\n",
      "    max_reward=441.06\n",
      "\n",
      "Training episode 12700    \n",
      "    reward=207.23\n",
      "\n",
      "Test run after episode 12700:\n",
      "    reward=187.36\n",
      "    greedy_reward=386.51\n",
      "    deterministic_reward=390.19\n",
      "    max_reward=430.66\n",
      "\n",
      "Training episode 12750    \n",
      "    reward=215.62\n",
      "\n",
      "Test run after episode 12750:\n",
      "    reward=175.21\n",
      "    greedy_reward=369.91\n",
      "    deterministic_reward=374.56\n",
      "    max_reward=402.56\n",
      "\n",
      "Training episode 12800    \n",
      "    reward=199.92\n",
      "\n",
      "Test run after episode 12800:\n",
      "    reward=173.25\n",
      "    greedy_reward=263.42\n",
      "    deterministic_reward=292.10\n",
      "    max_reward=298.77\n",
      "\n",
      "Training episode 12850    \n",
      "    reward=195.47\n",
      "\n",
      "Test run after episode 12850:\n",
      "    reward=233.30\n",
      "    greedy_reward=329.92\n",
      "    deterministic_reward=344.02\n",
      "    max_reward=448.30\n",
      "\n",
      "Training episode 12900    \n",
      "    reward=213.82\n",
      "\n",
      "Test run after episode 12900:\n",
      "    reward=198.69\n",
      "    greedy_reward=373.12\n",
      "    deterministic_reward=372.31\n",
      "    max_reward=398.83\n",
      "\n",
      "Training episode 12950    \n",
      "    reward=211.47\n",
      "\n",
      "Test run after episode 12950:\n",
      "    reward=247.00\n",
      "    greedy_reward=350.24\n",
      "    deterministic_reward=361.78\n",
      "    max_reward=495.48\n",
      "\n",
      "Training episode 13000    \n",
      "    reward=199.57\n",
      "\n",
      "Test run after episode 13000:\n",
      "    reward=202.27\n",
      "    greedy_reward=373.11\n",
      "    deterministic_reward=376.67\n",
      "    max_reward=469.99\n",
      "\n",
      "Training episode 13050    \n",
      "    reward=198.96\n",
      "\n",
      "Test run after episode 13050:\n",
      "    reward=218.37\n",
      "    greedy_reward=323.59\n",
      "    deterministic_reward=354.59\n",
      "    max_reward=363.07\n",
      "\n",
      "Training episode 13100    \n",
      "    reward=203.08\n",
      "\n",
      "Test run after episode 13100:\n",
      "    reward=227.99\n",
      "    greedy_reward=294.24\n",
      "    deterministic_reward=329.48\n",
      "    max_reward=371.89\n",
      "\n",
      "Training episode 13150    \n",
      "    reward=213.19\n",
      "\n",
      "Test run after episode 13150:\n",
      "    reward=166.91\n",
      "    greedy_reward=286.66\n",
      "    deterministic_reward=303.95\n",
      "    max_reward=310.52\n",
      "\n",
      "Training episode 13200    \n",
      "    reward=211.41\n",
      "\n",
      "Test run after episode 13200:\n",
      "    reward=347.35\n",
      "    greedy_reward=363.74\n",
      "    deterministic_reward=363.61\n",
      "    max_reward=485.30\n",
      "\n",
      "Training episode 13250    \n",
      "    reward=212.80\n",
      "\n",
      "Test run after episode 13250:\n",
      "    reward=271.72\n",
      "    greedy_reward=406.62\n",
      "    deterministic_reward=412.58\n",
      "    max_reward=526.27\n",
      "\n",
      "Training episode 13300    \n",
      "    reward=203.15\n",
      "\n",
      "Test run after episode 13300:\n",
      "    reward=210.42\n",
      "    greedy_reward=320.88\n",
      "    deterministic_reward=338.00\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 13350    \n",
      "    reward=215.94\n",
      "\n",
      "Test run after episode 13350:\n",
      "    reward=165.05\n",
      "    greedy_reward=303.80\n",
      "    deterministic_reward=317.81\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 13400    \n",
      "    reward=202.19\n",
      "\n",
      "Test run after episode 13400:\n",
      "    reward=212.28\n",
      "    greedy_reward=291.76\n",
      "    deterministic_reward=300.57\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 13450    \n",
      "    reward=212.71\n",
      "\n",
      "Test run after episode 13450:\n",
      "    reward=166.37\n",
      "    greedy_reward=277.31\n",
      "    deterministic_reward=298.05\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 13500    \n",
      "    reward=209.25\n",
      "\n",
      "Test run after episode 13500:\n",
      "    reward=204.26\n",
      "    greedy_reward=334.46\n",
      "    deterministic_reward=357.04\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 13550    \n",
      "    reward=206.67\n",
      "\n",
      "Test run after episode 13550:\n",
      "    reward=304.58\n",
      "    greedy_reward=355.11\n",
      "    deterministic_reward=352.90\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 13600    \n",
      "    reward=206.05\n",
      "\n",
      "Test run after episode 13600:\n",
      "    reward=209.76\n",
      "    greedy_reward=395.32\n",
      "    deterministic_reward=411.09\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 13650    \n",
      "    reward=207.53\n",
      "\n",
      "Test run after episode 13650:\n",
      "    reward=187.49\n",
      "    greedy_reward=311.71\n",
      "    deterministic_reward=336.62\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 13700    \n",
      "    reward=213.68\n",
      "\n",
      "Test run after episode 13700:\n",
      "    reward=161.21\n",
      "    greedy_reward=283.85\n",
      "    deterministic_reward=287.38\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 13750    \n",
      "    reward=207.21\n",
      "\n",
      "Test run after episode 13750:\n",
      "    reward=168.68\n",
      "    greedy_reward=288.56\n",
      "    deterministic_reward=297.35\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 13800    \n",
      "    reward=197.56\n",
      "\n",
      "Test run after episode 13800:\n",
      "    reward=188.04\n",
      "    greedy_reward=353.23\n",
      "    deterministic_reward=377.21\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 13850    \n",
      "    reward=208.92\n",
      "\n",
      "Test run after episode 13850:\n",
      "    reward=151.79\n",
      "    greedy_reward=285.79\n",
      "    deterministic_reward=294.44\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 13900    \n",
      "    reward=206.08\n",
      "\n",
      "Test run after episode 13900:\n",
      "    reward=201.80\n",
      "    greedy_reward=310.24\n",
      "    deterministic_reward=319.40\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 13950    \n",
      "    reward=204.27\n",
      "\n",
      "Test run after episode 13950:\n",
      "    reward=194.56\n",
      "    greedy_reward=276.64\n",
      "    deterministic_reward=282.72\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 14000    \n",
      "    reward=206.18\n",
      "\n",
      "Test run after episode 14000:\n",
      "    reward=171.79\n",
      "    greedy_reward=313.50\n",
      "    deterministic_reward=343.47\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 14050    \n",
      "    reward=206.47\n",
      "\n",
      "Test run after episode 14050:\n",
      "    reward=198.38\n",
      "    greedy_reward=351.68\n",
      "    deterministic_reward=370.14\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 14100    \n",
      "    reward=198.05\n",
      "\n",
      "Test run after episode 14100:\n",
      "    reward=190.01\n",
      "    greedy_reward=366.97\n",
      "    deterministic_reward=371.21\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 14150    \n",
      "    reward=192.61\n",
      "\n",
      "Test run after episode 14150:\n",
      "    reward=247.87\n",
      "    greedy_reward=357.95\n",
      "    deterministic_reward=401.10\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 14200    \n",
      "    reward=209.71\n",
      "\n",
      "Test run after episode 14200:\n",
      "    reward=178.48\n",
      "    greedy_reward=254.27\n",
      "    deterministic_reward=266.03\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 14250    \n",
      "    reward=210.72\n",
      "\n",
      "Test run after episode 14250:\n",
      "    reward=213.41\n",
      "    greedy_reward=398.43\n",
      "    deterministic_reward=430.21\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 14300    \n",
      "    reward=203.71\n",
      "\n",
      "Test run after episode 14300:\n",
      "    reward=199.11\n",
      "    greedy_reward=335.95\n",
      "    deterministic_reward=363.21\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 14350    \n",
      "    reward=221.03\n",
      "\n",
      "Test run after episode 14350:\n",
      "    reward=219.06\n",
      "    greedy_reward=314.27\n",
      "    deterministic_reward=334.57\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 14400    \n",
      "    reward=206.18\n",
      "\n",
      "Test run after episode 14400:\n",
      "    reward=350.33\n",
      "    greedy_reward=368.42\n",
      "    deterministic_reward=413.48\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 14450    \n",
      "    reward=201.97\n",
      "\n",
      "Test run after episode 14450:\n",
      "    reward=200.84\n",
      "    greedy_reward=279.65\n",
      "    deterministic_reward=325.99\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 14500    \n",
      "    reward=217.73\n",
      "\n",
      "Test run after episode 14500:\n",
      "    reward=245.27\n",
      "    greedy_reward=303.45\n",
      "    deterministic_reward=310.74\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 14550    \n",
      "    reward=210.92\n",
      "\n",
      "Test run after episode 14550:\n",
      "    reward=188.87\n",
      "    greedy_reward=286.93\n",
      "    deterministic_reward=314.95\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 14600    \n",
      "    reward=211.57\n",
      "\n",
      "Test run after episode 14600:\n",
      "    reward=232.82\n",
      "    greedy_reward=305.63\n",
      "    deterministic_reward=320.96\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 14650    \n",
      "    reward=221.89\n",
      "\n",
      "Test run after episode 14650:\n",
      "    reward=146.74\n",
      "    greedy_reward=220.18\n",
      "    deterministic_reward=230.49\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 14700    \n",
      "    reward=210.96\n",
      "\n",
      "Test run after episode 14700:\n",
      "    reward=197.53\n",
      "    greedy_reward=387.25\n",
      "    deterministic_reward=401.98\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 14750    \n",
      "    reward=214.11\n",
      "\n",
      "Test run after episode 14750:\n",
      "    reward=162.38\n",
      "    greedy_reward=287.34\n",
      "    deterministic_reward=303.81\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 14800    \n",
      "    reward=208.09\n",
      "\n",
      "Test run after episode 14800:\n",
      "    reward=191.55\n",
      "    greedy_reward=395.89\n",
      "    deterministic_reward=411.63\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 14850    \n",
      "    reward=210.18\n",
      "\n",
      "Test run after episode 14850:\n",
      "    reward=224.46\n",
      "    greedy_reward=318.61\n",
      "    deterministic_reward=328.29\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 14900    \n",
      "    reward=208.98\n",
      "\n",
      "Test run after episode 14900:\n",
      "    reward=168.46\n",
      "    greedy_reward=297.66\n",
      "    deterministic_reward=306.45\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 14950    \n",
      "    reward=192.65\n",
      "\n",
      "Test run after episode 14950:\n",
      "    reward=99.41\n",
      "    greedy_reward=208.53\n",
      "    deterministic_reward=212.47\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 15000    \n",
      "    reward=198.72\n",
      "\n",
      "Test run after episode 15000:\n",
      "    reward=173.89\n",
      "    greedy_reward=290.52\n",
      "    deterministic_reward=316.39\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 15050    \n",
      "    reward=207.03\n",
      "\n",
      "Test run after episode 15050:\n",
      "    reward=177.27\n",
      "    greedy_reward=264.27\n",
      "    deterministic_reward=277.21\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 15100    \n",
      "    reward=207.18\n",
      "\n",
      "Test run after episode 15100:\n",
      "    reward=228.27\n",
      "    greedy_reward=341.33\n",
      "    deterministic_reward=342.20\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 15150    \n",
      "    reward=196.10\n",
      "\n",
      "Test run after episode 15150:\n",
      "    reward=218.94\n",
      "    greedy_reward=389.91\n",
      "    deterministic_reward=397.26\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 15200    \n",
      "    reward=197.28\n",
      "\n",
      "Test run after episode 15200:\n",
      "    reward=218.45\n",
      "    greedy_reward=326.63\n",
      "    deterministic_reward=352.91\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 15250    \n",
      "    reward=214.34\n",
      "\n",
      "Test run after episode 15250:\n",
      "    reward=211.08\n",
      "    greedy_reward=342.55\n",
      "    deterministic_reward=381.86\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 15300    \n",
      "    reward=196.24\n",
      "\n",
      "Test run after episode 15300:\n",
      "    reward=259.57\n",
      "    greedy_reward=260.31\n",
      "    deterministic_reward=281.42\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 15350    \n",
      "    reward=218.88\n",
      "\n",
      "Test run after episode 15350:\n",
      "    reward=94.16\n",
      "    greedy_reward=348.61\n",
      "    deterministic_reward=347.36\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 15400    \n",
      "    reward=206.04\n",
      "\n",
      "Test run after episode 15400:\n",
      "    reward=110.29\n",
      "    greedy_reward=284.86\n",
      "    deterministic_reward=328.97\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 15450    \n",
      "    reward=209.79\n",
      "\n",
      "Test run after episode 15450:\n",
      "    reward=139.77\n",
      "    greedy_reward=229.62\n",
      "    deterministic_reward=233.35\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 15500    \n",
      "    reward=203.50\n",
      "\n",
      "Test run after episode 15500:\n",
      "    reward=312.08\n",
      "    greedy_reward=342.08\n",
      "    deterministic_reward=341.21\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 15550    \n",
      "    reward=200.08\n",
      "\n",
      "Test run after episode 15550:\n",
      "    reward=152.76\n",
      "    greedy_reward=236.15\n",
      "    deterministic_reward=239.28\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 15600    \n",
      "    reward=205.70\n",
      "\n",
      "Test run after episode 15600:\n",
      "    reward=144.02\n",
      "    greedy_reward=321.02\n",
      "    deterministic_reward=325.52\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 15650    \n",
      "    reward=195.36\n",
      "\n",
      "Test run after episode 15650:\n",
      "    reward=273.85\n",
      "    greedy_reward=292.00\n",
      "    deterministic_reward=341.25\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 15700    \n",
      "    reward=198.45\n",
      "\n",
      "Test run after episode 15700:\n",
      "    reward=238.61\n",
      "    greedy_reward=279.60\n",
      "    deterministic_reward=288.63\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 15750    \n",
      "    reward=216.49\n",
      "\n",
      "Test run after episode 15750:\n",
      "    reward=291.87\n",
      "    greedy_reward=384.32\n",
      "    deterministic_reward=383.49\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 15800    \n",
      "    reward=215.21\n",
      "\n",
      "Test run after episode 15800:\n",
      "    reward=178.60\n",
      "    greedy_reward=286.83\n",
      "    deterministic_reward=308.88\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 15850    \n",
      "    reward=203.71\n",
      "\n",
      "Test run after episode 15850:\n",
      "    reward=206.05\n",
      "    greedy_reward=276.59\n",
      "    deterministic_reward=294.32\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 15900    \n",
      "    reward=203.94\n",
      "\n",
      "Test run after episode 15900:\n",
      "    reward=302.04\n",
      "    greedy_reward=433.90\n",
      "    deterministic_reward=452.91\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 15950    \n",
      "    reward=211.09\n",
      "\n",
      "Test run after episode 15950:\n",
      "    reward=166.14\n",
      "    greedy_reward=267.32\n",
      "    deterministic_reward=275.53\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 16000    \n",
      "    reward=214.37\n",
      "\n",
      "Test run after episode 16000:\n",
      "    reward=139.40\n",
      "    greedy_reward=282.46\n",
      "    deterministic_reward=288.86\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 16050    \n",
      "    reward=206.23\n",
      "\n",
      "Test run after episode 16050:\n",
      "    reward=134.50\n",
      "    greedy_reward=217.56\n",
      "    deterministic_reward=227.24\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 16100    \n",
      "    reward=205.43\n",
      "\n",
      "Test run after episode 16100:\n",
      "    reward=213.21\n",
      "    greedy_reward=287.61\n",
      "    deterministic_reward=301.00\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 16150    \n",
      "    reward=200.26\n",
      "\n",
      "Test run after episode 16150:\n",
      "    reward=158.70\n",
      "    greedy_reward=369.80\n",
      "    deterministic_reward=388.27\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 16200    \n",
      "    reward=194.37\n",
      "\n",
      "Test run after episode 16200:\n",
      "    reward=223.30\n",
      "    greedy_reward=356.01\n",
      "    deterministic_reward=373.13\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 16250    \n",
      "    reward=203.40\n",
      "\n",
      "Test run after episode 16250:\n",
      "    reward=168.22\n",
      "    greedy_reward=282.29\n",
      "    deterministic_reward=312.62\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 16300    \n",
      "    reward=209.16\n",
      "\n",
      "Test run after episode 16300:\n",
      "    reward=186.10\n",
      "    greedy_reward=306.37\n",
      "    deterministic_reward=316.07\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 16350    \n",
      "    reward=216.89\n",
      "\n",
      "Test run after episode 16350:\n",
      "    reward=226.28\n",
      "    greedy_reward=379.97\n",
      "    deterministic_reward=397.82\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 16400    \n",
      "    reward=205.35\n",
      "\n",
      "Test run after episode 16400:\n",
      "    reward=200.97\n",
      "    greedy_reward=279.63\n",
      "    deterministic_reward=308.88\n",
      "    max_reward=319.32\n",
      "\n",
      "Training episode 16450    \n",
      "    reward=194.65\n",
      "\n",
      "Test run after episode 16450:\n",
      "    reward=106.58\n",
      "    greedy_reward=217.55\n",
      "    deterministic_reward=222.05\n",
      "    max_reward=225.34\n",
      "\n",
      "Training episode 16500    \n",
      "    reward=210.51\n",
      "\n",
      "Test run after episode 16500:\n",
      "    reward=262.44\n",
      "    greedy_reward=404.77\n",
      "    deterministic_reward=406.51\n",
      "    max_reward=546.74\n",
      "\n",
      "Training episode 16550    \n",
      "    reward=207.74\n",
      "\n",
      "Test run after episode 16550:\n",
      "    reward=139.36\n",
      "    greedy_reward=306.85\n",
      "    deterministic_reward=313.14\n",
      "    max_reward=319.65\n",
      "\n",
      "Training episode 16600    \n",
      "    reward=204.09\n",
      "\n",
      "Test run after episode 16600:\n",
      "    reward=129.16\n",
      "    greedy_reward=230.57\n",
      "    deterministic_reward=233.14\n",
      "    max_reward=243.54\n",
      "\n",
      "Training episode 16650    \n",
      "    reward=195.63\n",
      "\n",
      "Test run after episode 16650:\n",
      "    reward=155.87\n",
      "    greedy_reward=204.92\n",
      "    deterministic_reward=216.78\n",
      "    max_reward=230.71\n",
      "\n",
      "Training episode 16700    \n",
      "    reward=216.61\n",
      "\n",
      "Test run after episode 16700:\n",
      "    reward=206.40\n",
      "    greedy_reward=388.94\n",
      "    deterministic_reward=402.57\n",
      "    max_reward=410.50\n",
      "\n",
      "Training episode 16750    \n",
      "    reward=207.26\n",
      "\n",
      "Test run after episode 16750:\n",
      "    reward=206.52\n",
      "    greedy_reward=318.67\n",
      "    deterministic_reward=343.33\n",
      "    max_reward=403.17\n",
      "\n",
      "Training episode 16800    \n",
      "    reward=220.44\n",
      "\n",
      "Test run after episode 16800:\n",
      "    reward=239.05\n",
      "    greedy_reward=340.03\n",
      "    deterministic_reward=393.78\n",
      "    max_reward=411.02\n",
      "\n",
      "Training episode 16850    \n",
      "    reward=201.25\n",
      "\n",
      "Test run after episode 16850:\n",
      "    reward=179.38\n",
      "    greedy_reward=292.27\n",
      "    deterministic_reward=296.21\n",
      "    max_reward=300.75\n",
      "\n",
      "Training episode 16900    \n",
      "    reward=207.75\n",
      "\n",
      "Test run after episode 16900:\n",
      "    reward=211.00\n",
      "    greedy_reward=350.63\n",
      "    deterministic_reward=352.23\n",
      "    max_reward=375.10\n",
      "\n",
      "Training episode 16950    \n",
      "    reward=219.09\n",
      "\n",
      "Test run after episode 16950:\n",
      "    reward=125.24\n",
      "    greedy_reward=295.39\n",
      "    deterministic_reward=333.78\n",
      "    max_reward=347.72\n",
      "\n",
      "Training episode 17000    \n",
      "    reward=207.65\n",
      "\n",
      "Test run after episode 17000:\n",
      "    reward=213.84\n",
      "    greedy_reward=288.11\n",
      "    deterministic_reward=306.19\n",
      "    max_reward=333.23\n",
      "\n",
      "Training episode 17050    \n",
      "    reward=205.19\n",
      "\n",
      "Test run after episode 17050:\n",
      "    reward=187.12\n",
      "    greedy_reward=244.18\n",
      "    deterministic_reward=250.78\n",
      "    max_reward=315.38\n",
      "\n",
      "Training episode 17100    \n",
      "    reward=206.76\n",
      "\n",
      "Test run after episode 17100:\n",
      "    reward=157.27\n",
      "    greedy_reward=297.36\n",
      "    deterministic_reward=316.10\n",
      "    max_reward=344.52\n",
      "\n",
      "Training episode 17150    \n",
      "    reward=209.63\n",
      "\n",
      "Test run after episode 17150:\n",
      "    reward=200.97\n",
      "    greedy_reward=395.88\n",
      "    deterministic_reward=398.58\n",
      "    max_reward=501.64\n",
      "\n",
      "Training episode 17200    \n",
      "    reward=212.40\n",
      "\n",
      "Test run after episode 17200:\n",
      "    reward=141.12\n",
      "    greedy_reward=211.03\n",
      "    deterministic_reward=231.41\n",
      "    max_reward=240.74\n",
      "\n",
      "Training episode 17250    \n",
      "    reward=208.31\n",
      "\n",
      "Test run after episode 17250:\n",
      "    reward=222.64\n",
      "    greedy_reward=375.83\n",
      "    deterministic_reward=379.38\n",
      "    max_reward=429.00\n",
      "\n",
      "Training episode 17300    \n",
      "    reward=191.01\n",
      "\n",
      "Test run after episode 17300:\n",
      "    reward=213.76\n",
      "    greedy_reward=292.38\n",
      "    deterministic_reward=327.19\n",
      "    max_reward=332.83\n",
      "\n",
      "Training episode 17350    \n",
      "    reward=220.15\n",
      "\n",
      "Test run after episode 17350:\n",
      "    reward=127.55\n",
      "    greedy_reward=274.46\n",
      "    deterministic_reward=291.08\n",
      "    max_reward=292.08\n",
      "\n",
      "Training episode 17400    \n",
      "    reward=219.80\n",
      "\n",
      "Test run after episode 17400:\n",
      "    reward=74.56\n",
      "    greedy_reward=223.31\n",
      "    deterministic_reward=232.80\n",
      "    max_reward=237.14\n",
      "\n",
      "Training episode 17450    \n",
      "    reward=201.02\n",
      "\n",
      "Test run after episode 17450:\n",
      "    reward=178.13\n",
      "    greedy_reward=325.49\n",
      "    deterministic_reward=369.20\n",
      "    max_reward=395.37\n",
      "\n",
      "Training episode 17500    \n",
      "    reward=208.35\n",
      "\n",
      "Test run after episode 17500:\n",
      "    reward=149.58\n",
      "    greedy_reward=407.59\n",
      "    deterministic_reward=424.53\n",
      "    max_reward=434.18\n",
      "\n",
      "Training episode 17550    \n",
      "    reward=201.44\n",
      "\n",
      "Test run after episode 17550:\n",
      "    reward=176.53\n",
      "    greedy_reward=295.04\n",
      "    deterministic_reward=304.67\n",
      "    max_reward=312.22\n",
      "\n",
      "Training episode 17600    \n",
      "    reward=211.38\n",
      "\n",
      "Test run after episode 17600:\n",
      "    reward=133.80\n",
      "    greedy_reward=364.30\n",
      "    deterministic_reward=360.30\n",
      "    max_reward=470.55\n",
      "\n",
      "Training episode 17650    \n",
      "    reward=212.23\n",
      "\n",
      "Test run after episode 17650:\n",
      "    reward=169.88\n",
      "    greedy_reward=346.50\n",
      "    deterministic_reward=354.09\n",
      "    max_reward=360.32\n",
      "\n",
      "Training episode 17700    \n",
      "    reward=198.43\n",
      "\n",
      "Test run after episode 17700:\n",
      "    reward=248.64\n",
      "    greedy_reward=357.49\n",
      "    deterministic_reward=370.85\n",
      "    max_reward=389.11\n",
      "\n",
      "Training episode 17750    \n",
      "    reward=212.92\n",
      "\n",
      "Test run after episode 17750:\n",
      "    reward=216.15\n",
      "    greedy_reward=382.35\n",
      "    deterministic_reward=403.21\n",
      "    max_reward=441.06\n",
      "\n",
      "Training episode 17800    \n",
      "    reward=207.31\n",
      "\n",
      "Test run after episode 17800:\n",
      "    reward=187.38\n",
      "    greedy_reward=401.54\n",
      "    deterministic_reward=411.51\n",
      "    max_reward=430.66\n",
      "\n",
      "Training episode 17850    \n",
      "    reward=215.21\n",
      "\n",
      "Test run after episode 17850:\n",
      "    reward=175.22\n",
      "    greedy_reward=376.19\n",
      "    deterministic_reward=382.73\n",
      "    max_reward=402.56\n",
      "\n",
      "Training episode 17900    \n",
      "    reward=199.81\n",
      "\n",
      "Test run after episode 17900:\n",
      "    reward=173.25\n",
      "    greedy_reward=270.35\n",
      "    deterministic_reward=292.91\n",
      "    max_reward=298.77\n",
      "\n",
      "Training episode 17950    \n",
      "    reward=195.03\n",
      "\n",
      "Test run after episode 17950:\n",
      "    reward=233.29\n",
      "    greedy_reward=368.55\n",
      "    deterministic_reward=384.14\n",
      "    max_reward=448.30\n",
      "\n",
      "Training episode 18000    \n",
      "    reward=213.63\n",
      "\n",
      "Test run after episode 18000:\n",
      "    reward=198.66\n",
      "    greedy_reward=374.38\n",
      "    deterministic_reward=373.52\n",
      "    max_reward=398.83\n",
      "\n",
      "Training episode 18050    \n",
      "    reward=211.54\n",
      "\n",
      "Test run after episode 18050:\n",
      "    reward=246.92\n",
      "    greedy_reward=415.53\n",
      "    deterministic_reward=429.44\n",
      "    max_reward=495.48\n",
      "\n",
      "Training episode 18100    \n",
      "    reward=199.75\n",
      "\n",
      "Test run after episode 18100:\n",
      "    reward=202.31\n",
      "    greedy_reward=368.18\n",
      "    deterministic_reward=371.92\n",
      "    max_reward=469.99\n",
      "\n",
      "Training episode 18150    \n",
      "    reward=198.87\n",
      "\n",
      "Test run after episode 18150:\n",
      "    reward=218.39\n",
      "    greedy_reward=329.61\n",
      "    deterministic_reward=358.00\n",
      "    max_reward=363.07\n",
      "\n",
      "Training episode 18200    \n",
      "    reward=203.13\n",
      "\n",
      "Test run after episode 18200:\n",
      "    reward=227.97\n",
      "    greedy_reward=301.57\n",
      "    deterministic_reward=334.35\n",
      "    max_reward=371.89\n",
      "\n",
      "Training episode 18250    \n",
      "    reward=213.33\n",
      "\n",
      "Test run after episode 18250:\n",
      "    reward=166.91\n",
      "    greedy_reward=286.02\n",
      "    deterministic_reward=306.38\n",
      "    max_reward=310.52\n",
      "\n",
      "Training episode 18300    \n",
      "    reward=211.75\n",
      "\n",
      "Test run after episode 18300:\n",
      "    reward=347.28\n",
      "    greedy_reward=393.80\n",
      "    deterministic_reward=401.53\n",
      "    max_reward=485.30\n",
      "\n",
      "Training episode 18350    \n",
      "    reward=212.67\n",
      "\n",
      "Test run after episode 18350:\n",
      "    reward=271.73\n",
      "    greedy_reward=376.64\n",
      "    deterministic_reward=372.96\n",
      "    max_reward=526.27\n",
      "\n",
      "Training episode 18400    \n",
      "    reward=203.01\n",
      "\n",
      "Test run after episode 18400:\n",
      "    reward=210.47\n",
      "    greedy_reward=328.86\n",
      "    deterministic_reward=341.32\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 18450    \n",
      "    reward=215.75\n",
      "\n",
      "Test run after episode 18450:\n",
      "    reward=165.05\n",
      "    greedy_reward=294.89\n",
      "    deterministic_reward=316.74\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 18500    \n",
      "    reward=202.11\n",
      "\n",
      "Test run after episode 18500:\n",
      "    reward=212.26\n",
      "    greedy_reward=297.50\n",
      "    deterministic_reward=310.86\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 18550    \n",
      "    reward=213.12\n",
      "\n",
      "Test run after episode 18550:\n",
      "    reward=166.39\n",
      "    greedy_reward=256.70\n",
      "    deterministic_reward=290.01\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 18600    \n",
      "    reward=209.49\n",
      "\n",
      "Test run after episode 18600:\n",
      "    reward=204.21\n",
      "    greedy_reward=359.04\n",
      "    deterministic_reward=373.75\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 18650    \n",
      "    reward=206.81\n",
      "\n",
      "Test run after episode 18650:\n",
      "    reward=304.61\n",
      "    greedy_reward=340.04\n",
      "    deterministic_reward=337.57\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 18700    \n",
      "    reward=205.49\n",
      "\n",
      "Test run after episode 18700:\n",
      "    reward=209.78\n",
      "    greedy_reward=440.61\n",
      "    deterministic_reward=472.27\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 18750    \n",
      "    reward=207.65\n",
      "\n",
      "Test run after episode 18750:\n",
      "    reward=187.46\n",
      "    greedy_reward=305.73\n",
      "    deterministic_reward=332.26\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 18800    \n",
      "    reward=213.52\n",
      "\n",
      "Test run after episode 18800:\n",
      "    reward=161.25\n",
      "    greedy_reward=266.30\n",
      "    deterministic_reward=284.51\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 18850    \n",
      "    reward=207.53\n",
      "\n",
      "Test run after episode 18850:\n",
      "    reward=168.65\n",
      "    greedy_reward=286.99\n",
      "    deterministic_reward=293.34\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 18900    \n",
      "    reward=197.45\n",
      "\n",
      "Test run after episode 18900:\n",
      "    reward=188.04\n",
      "    greedy_reward=328.10\n",
      "    deterministic_reward=357.09\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 18950    \n",
      "    reward=208.83\n",
      "\n",
      "Test run after episode 18950:\n",
      "    reward=151.89\n",
      "    greedy_reward=284.83\n",
      "    deterministic_reward=293.22\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 19000    \n",
      "    reward=206.28\n",
      "\n",
      "Test run after episode 19000:\n",
      "    reward=201.82\n",
      "    greedy_reward=307.52\n",
      "    deterministic_reward=319.96\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 19050    \n",
      "    reward=204.20\n",
      "\n",
      "Test run after episode 19050:\n",
      "    reward=194.55\n",
      "    greedy_reward=276.19\n",
      "    deterministic_reward=281.16\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 19100    \n",
      "    reward=206.04\n",
      "\n",
      "Test run after episode 19100:\n",
      "    reward=171.84\n",
      "    greedy_reward=282.19\n",
      "    deterministic_reward=326.36\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 19150    \n",
      "    reward=206.23\n",
      "\n",
      "Test run after episode 19150:\n",
      "    reward=198.32\n",
      "    greedy_reward=355.14\n",
      "    deterministic_reward=368.07\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 19200    \n",
      "    reward=198.26\n",
      "\n",
      "Test run after episode 19200:\n",
      "    reward=190.01\n",
      "    greedy_reward=342.24\n",
      "    deterministic_reward=360.80\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 19250    \n",
      "    reward=191.96\n",
      "\n",
      "Test run after episode 19250:\n",
      "    reward=247.93\n",
      "    greedy_reward=388.98\n",
      "    deterministic_reward=437.04\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 19300    \n",
      "    reward=209.77\n",
      "\n",
      "Test run after episode 19300:\n",
      "    reward=178.47\n",
      "    greedy_reward=231.18\n",
      "    deterministic_reward=259.51\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 19350    \n",
      "    reward=210.31\n",
      "\n",
      "Test run after episode 19350:\n",
      "    reward=213.45\n",
      "    greedy_reward=410.23\n",
      "    deterministic_reward=437.88\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 19400    \n",
      "    reward=203.61\n",
      "\n",
      "Test run after episode 19400:\n",
      "    reward=199.08\n",
      "    greedy_reward=334.06\n",
      "    deterministic_reward=357.08\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 19450    \n",
      "    reward=221.01\n",
      "\n",
      "Test run after episode 19450:\n",
      "    reward=219.03\n",
      "    greedy_reward=307.23\n",
      "    deterministic_reward=327.81\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 19500    \n",
      "    reward=206.26\n",
      "\n",
      "Test run after episode 19500:\n",
      "    reward=350.38\n",
      "    greedy_reward=381.63\n",
      "    deterministic_reward=432.07\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 19550    \n",
      "    reward=201.90\n",
      "\n",
      "Test run after episode 19550:\n",
      "    reward=200.85\n",
      "    greedy_reward=298.40\n",
      "    deterministic_reward=334.44\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 19600    \n",
      "    reward=218.01\n",
      "\n",
      "Test run after episode 19600:\n",
      "    reward=245.20\n",
      "    greedy_reward=302.12\n",
      "    deterministic_reward=309.90\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 19650    \n",
      "    reward=211.10\n",
      "\n",
      "Test run after episode 19650:\n",
      "    reward=188.85\n",
      "    greedy_reward=295.22\n",
      "    deterministic_reward=313.87\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 19700    \n",
      "    reward=211.81\n",
      "\n",
      "Test run after episode 19700:\n",
      "    reward=232.80\n",
      "    greedy_reward=311.05\n",
      "    deterministic_reward=322.34\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 19750    \n",
      "    reward=222.45\n",
      "\n",
      "Test run after episode 19750:\n",
      "    reward=146.71\n",
      "    greedy_reward=227.10\n",
      "    deterministic_reward=232.54\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 19800    \n",
      "    reward=210.26\n",
      "\n",
      "Test run after episode 19800:\n",
      "    reward=197.55\n",
      "    greedy_reward=389.44\n",
      "    deterministic_reward=403.32\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 19850    \n",
      "    reward=214.27\n",
      "\n",
      "Test run after episode 19850:\n",
      "    reward=162.36\n",
      "    greedy_reward=296.58\n",
      "    deterministic_reward=310.38\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 19900    \n",
      "    reward=207.82\n",
      "\n",
      "Test run after episode 19900:\n",
      "    reward=191.56\n",
      "    greedy_reward=404.00\n",
      "    deterministic_reward=416.35\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 19950    \n",
      "    reward=210.10\n",
      "\n",
      "Test run after episode 19950:\n",
      "    reward=224.40\n",
      "    greedy_reward=351.77\n",
      "    deterministic_reward=370.13\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 20000    \n",
      "    reward=208.88\n",
      "\n",
      "Test run after episode 20000:\n",
      "    reward=168.43\n",
      "    greedy_reward=291.68\n",
      "    deterministic_reward=303.10\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 20050    \n",
      "    reward=192.53\n",
      "\n",
      "Test run after episode 20050:\n",
      "    reward=99.43\n",
      "    greedy_reward=210.70\n",
      "    deterministic_reward=213.79\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 20100    \n",
      "    reward=198.57\n",
      "\n",
      "Test run after episode 20100:\n",
      "    reward=173.92\n",
      "    greedy_reward=292.91\n",
      "    deterministic_reward=319.00\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 20150    \n",
      "    reward=207.01\n",
      "\n",
      "Test run after episode 20150:\n",
      "    reward=177.30\n",
      "    greedy_reward=263.88\n",
      "    deterministic_reward=277.92\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 20200    \n",
      "    reward=207.00\n",
      "\n",
      "Test run after episode 20200:\n",
      "    reward=228.25\n",
      "    greedy_reward=365.34\n",
      "    deterministic_reward=372.92\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 20250    \n",
      "    reward=195.16\n",
      "\n",
      "Test run after episode 20250:\n",
      "    reward=218.95\n",
      "    greedy_reward=350.85\n",
      "    deterministic_reward=358.20\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 20300    \n",
      "    reward=197.49\n",
      "\n",
      "Test run after episode 20300:\n",
      "    reward=218.46\n",
      "    greedy_reward=321.16\n",
      "    deterministic_reward=348.36\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 20350    \n",
      "    reward=214.20\n",
      "\n",
      "Test run after episode 20350:\n",
      "    reward=211.16\n",
      "    greedy_reward=332.14\n",
      "    deterministic_reward=373.87\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 20400    \n",
      "    reward=196.49\n",
      "\n",
      "Test run after episode 20400:\n",
      "    reward=259.59\n",
      "    greedy_reward=323.15\n",
      "    deterministic_reward=358.27\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 20450    \n",
      "    reward=219.15\n",
      "\n",
      "Test run after episode 20450:\n",
      "    reward=94.18\n",
      "    greedy_reward=325.93\n",
      "    deterministic_reward=334.31\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 20500    \n",
      "    reward=206.13\n",
      "\n",
      "Test run after episode 20500:\n",
      "    reward=110.28\n",
      "    greedy_reward=299.87\n",
      "    deterministic_reward=332.76\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 20550    \n",
      "    reward=209.94\n",
      "\n",
      "Test run after episode 20550:\n",
      "    reward=139.73\n",
      "    greedy_reward=209.03\n",
      "    deterministic_reward=225.19\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 20600    \n",
      "    reward=202.92\n",
      "\n",
      "Test run after episode 20600:\n",
      "    reward=312.10\n",
      "    greedy_reward=346.79\n",
      "    deterministic_reward=346.97\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 20650    \n",
      "    reward=199.47\n",
      "\n",
      "Test run after episode 20650:\n",
      "    reward=152.77\n",
      "    greedy_reward=237.51\n",
      "    deterministic_reward=240.29\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 20700    \n",
      "    reward=205.51\n",
      "\n",
      "Test run after episode 20700:\n",
      "    reward=144.02\n",
      "    greedy_reward=310.71\n",
      "    deterministic_reward=323.46\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 20750    \n",
      "    reward=195.31\n",
      "\n",
      "Test run after episode 20750:\n",
      "    reward=273.83\n",
      "    greedy_reward=293.59\n",
      "    deterministic_reward=342.93\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 20800    \n",
      "    reward=198.72\n",
      "\n",
      "Test run after episode 20800:\n",
      "    reward=238.58\n",
      "    greedy_reward=271.77\n",
      "    deterministic_reward=286.55\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 20850    \n",
      "    reward=216.62\n",
      "\n",
      "Test run after episode 20850:\n",
      "    reward=291.79\n",
      "    greedy_reward=378.79\n",
      "    deterministic_reward=378.19\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 20900    \n",
      "    reward=214.94\n",
      "\n",
      "Test run after episode 20900:\n",
      "    reward=178.63\n",
      "    greedy_reward=285.78\n",
      "    deterministic_reward=305.61\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 20950    \n",
      "    reward=203.42\n",
      "\n",
      "Test run after episode 20950:\n",
      "    reward=206.06\n",
      "    greedy_reward=282.56\n",
      "    deterministic_reward=301.54\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 21000    \n",
      "    reward=203.88\n",
      "\n",
      "Test run after episode 21000:\n",
      "    reward=302.03\n",
      "    greedy_reward=375.24\n",
      "    deterministic_reward=370.79\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 21050    \n",
      "    reward=210.97\n",
      "\n",
      "Test run after episode 21050:\n",
      "    reward=166.15\n",
      "    greedy_reward=270.72\n",
      "    deterministic_reward=278.17\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 21100    \n",
      "    reward=214.11\n",
      "\n",
      "Test run after episode 21100:\n",
      "    reward=139.33\n",
      "    greedy_reward=250.13\n",
      "    deterministic_reward=264.99\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 21150    \n",
      "    reward=206.15\n",
      "\n",
      "Test run after episode 21150:\n",
      "    reward=134.51\n",
      "    greedy_reward=222.11\n",
      "    deterministic_reward=229.57\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 21200    \n",
      "    reward=205.42\n",
      "\n",
      "Test run after episode 21200:\n",
      "    reward=213.27\n",
      "    greedy_reward=269.56\n",
      "    deterministic_reward=300.45\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 21250    \n",
      "    reward=200.25\n",
      "\n",
      "Test run after episode 21250:\n",
      "    reward=158.70\n",
      "    greedy_reward=374.63\n",
      "    deterministic_reward=399.09\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 21300    \n",
      "    reward=194.20\n",
      "\n",
      "Test run after episode 21300:\n",
      "    reward=223.29\n",
      "    greedy_reward=355.54\n",
      "    deterministic_reward=376.38\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 21350    \n",
      "    reward=203.48\n",
      "\n",
      "Test run after episode 21350:\n",
      "    reward=168.24\n",
      "    greedy_reward=278.58\n",
      "    deterministic_reward=312.53\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 21400    \n",
      "    reward=209.50\n",
      "\n",
      "Test run after episode 21400:\n",
      "    reward=186.04\n",
      "    greedy_reward=305.24\n",
      "    deterministic_reward=315.72\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 21450    \n",
      "    reward=216.88\n",
      "\n",
      "Test run after episode 21450:\n",
      "    reward=226.31\n",
      "    greedy_reward=386.89\n",
      "    deterministic_reward=396.97\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 21500    \n",
      "    reward=205.04\n",
      "\n",
      "Test run after episode 21500:\n",
      "    reward=200.98\n",
      "    greedy_reward=289.75\n",
      "    deterministic_reward=314.98\n",
      "    max_reward=319.32\n",
      "\n",
      "Training episode 21550    \n",
      "    reward=194.31\n",
      "\n",
      "Test run after episode 21550:\n",
      "    reward=106.55\n",
      "    greedy_reward=215.13\n",
      "    deterministic_reward=222.10\n",
      "    max_reward=225.34\n",
      "\n",
      "Training episode 21600    \n",
      "    reward=210.55\n",
      "\n",
      "Test run after episode 21600:\n",
      "    reward=262.48\n",
      "    greedy_reward=426.73\n",
      "    deterministic_reward=431.75\n",
      "    max_reward=546.74\n",
      "\n",
      "Training episode 21650    \n",
      "    reward=208.03\n",
      "\n",
      "Test run after episode 21650:\n",
      "    reward=139.33\n",
      "    greedy_reward=302.66\n",
      "    deterministic_reward=312.08\n",
      "    max_reward=319.65\n",
      "\n",
      "Training episode 21700    \n",
      "    reward=204.14\n",
      "\n",
      "Test run after episode 21700:\n",
      "    reward=129.16\n",
      "    greedy_reward=231.47\n",
      "    deterministic_reward=234.50\n",
      "    max_reward=243.54\n",
      "\n",
      "Training episode 21750    \n",
      "    reward=195.63\n",
      "\n",
      "Test run after episode 21750:\n",
      "    reward=155.97\n",
      "    greedy_reward=220.18\n",
      "    deterministic_reward=227.65\n",
      "    max_reward=230.71\n",
      "\n",
      "Training episode 21800    \n",
      "    reward=216.90\n",
      "\n",
      "Test run after episode 21800:\n",
      "    reward=206.42\n",
      "    greedy_reward=394.76\n",
      "    deterministic_reward=405.32\n",
      "    max_reward=410.50\n",
      "\n",
      "Training episode 21850    \n",
      "    reward=207.17\n",
      "\n",
      "Test run after episode 21850:\n",
      "    reward=206.50\n",
      "    greedy_reward=357.17\n",
      "    deterministic_reward=387.80\n",
      "    max_reward=403.17\n",
      "\n",
      "Training episode 21900    \n",
      "    reward=220.73\n",
      "\n",
      "Test run after episode 21900:\n",
      "    reward=239.10\n",
      "    greedy_reward=333.73\n",
      "    deterministic_reward=388.35\n",
      "    max_reward=411.02\n",
      "\n",
      "Training episode 21950    \n",
      "    reward=200.93\n",
      "\n",
      "Test run after episode 21950:\n",
      "    reward=179.32\n",
      "    greedy_reward=290.04\n",
      "    deterministic_reward=294.54\n",
      "    max_reward=300.75\n",
      "\n",
      "Training episode 22000    \n",
      "    reward=207.67\n",
      "\n",
      "Test run after episode 22000:\n",
      "    reward=211.00\n",
      "    greedy_reward=350.37\n",
      "    deterministic_reward=350.88\n",
      "    max_reward=375.10\n",
      "\n",
      "Training episode 22050    \n",
      "    reward=218.92\n",
      "\n",
      "Test run after episode 22050:\n",
      "    reward=125.30\n",
      "    greedy_reward=310.39\n",
      "    deterministic_reward=342.55\n",
      "    max_reward=347.72\n",
      "\n",
      "Training episode 22100    \n",
      "    reward=206.82\n",
      "\n",
      "Test run after episode 22100:\n",
      "    reward=213.83\n",
      "    greedy_reward=300.52\n",
      "    deterministic_reward=317.98\n",
      "    max_reward=333.23\n",
      "\n",
      "Training episode 22150    \n",
      "    reward=205.13\n",
      "\n",
      "Test run after episode 22150:\n",
      "    reward=187.16\n",
      "    greedy_reward=248.86\n",
      "    deterministic_reward=251.68\n",
      "    max_reward=315.38\n",
      "\n",
      "Training episode 22200    \n",
      "    reward=206.99\n",
      "\n",
      "Test run after episode 22200:\n",
      "    reward=157.24\n",
      "    greedy_reward=288.50\n",
      "    deterministic_reward=307.95\n",
      "    max_reward=344.52\n",
      "\n",
      "Training episode 22250    \n",
      "    reward=209.58\n",
      "\n",
      "Test run after episode 22250:\n",
      "    reward=200.94\n",
      "    greedy_reward=383.59\n",
      "    deterministic_reward=392.33\n",
      "    max_reward=501.64\n",
      "\n",
      "Training episode 22300    \n",
      "    reward=212.81\n",
      "\n",
      "Test run after episode 22300:\n",
      "    reward=141.17\n",
      "    greedy_reward=229.59\n",
      "    deterministic_reward=237.30\n",
      "    max_reward=240.74\n",
      "\n",
      "Training episode 22350    \n",
      "    reward=208.60\n",
      "\n",
      "Test run after episode 22350:\n",
      "    reward=222.65\n",
      "    greedy_reward=329.97\n",
      "    deterministic_reward=329.25\n",
      "    max_reward=429.00\n",
      "\n",
      "Training episode 22400    \n",
      "    reward=190.77\n",
      "\n",
      "Test run after episode 22400:\n",
      "    reward=213.68\n",
      "    greedy_reward=294.73\n",
      "    deterministic_reward=327.71\n",
      "    max_reward=332.83\n",
      "\n",
      "Training episode 22450    \n",
      "    reward=220.03\n",
      "\n",
      "Test run after episode 22450:\n",
      "    reward=127.52\n",
      "    greedy_reward=242.16\n",
      "    deterministic_reward=278.10\n",
      "    max_reward=292.08\n",
      "\n",
      "Training episode 22500    \n",
      "    reward=219.78\n",
      "\n",
      "Test run after episode 22500:\n",
      "    reward=74.54\n",
      "    greedy_reward=227.52\n",
      "    deterministic_reward=233.99\n",
      "    max_reward=237.14\n",
      "\n",
      "Training episode 22550    \n",
      "    reward=201.10\n",
      "\n",
      "Test run after episode 22550:\n",
      "    reward=178.10\n",
      "    greedy_reward=323.04\n",
      "    deterministic_reward=365.60\n",
      "    max_reward=395.37\n",
      "\n",
      "Training episode 22600    \n",
      "    reward=207.99\n",
      "\n",
      "Test run after episode 22600:\n",
      "    reward=149.60\n",
      "    greedy_reward=402.04\n",
      "    deterministic_reward=417.10\n",
      "    max_reward=434.18\n",
      "\n",
      "Training episode 22650    \n",
      "    reward=201.20\n",
      "\n",
      "Test run after episode 22650:\n",
      "    reward=176.51\n",
      "    greedy_reward=295.64\n",
      "    deterministic_reward=305.19\n",
      "    max_reward=312.22\n",
      "\n",
      "Training episode 22700    \n",
      "    reward=211.29\n",
      "\n",
      "Test run after episode 22700:\n",
      "    reward=133.80\n",
      "    greedy_reward=343.03\n",
      "    deterministic_reward=346.17\n",
      "    max_reward=470.55\n",
      "\n",
      "Training episode 22750    \n",
      "    reward=212.50\n",
      "\n",
      "Test run after episode 22750:\n",
      "    reward=169.82\n",
      "    greedy_reward=342.04\n",
      "    deterministic_reward=351.82\n",
      "    max_reward=360.32\n",
      "\n",
      "Training episode 22800    \n",
      "    reward=198.66\n",
      "\n",
      "Test run after episode 22800:\n",
      "    reward=248.62\n",
      "    greedy_reward=347.48\n",
      "    deterministic_reward=360.57\n",
      "    max_reward=389.11\n",
      "\n",
      "Training episode 22850    \n",
      "    reward=212.99\n",
      "\n",
      "Test run after episode 22850:\n",
      "    reward=216.17\n",
      "    greedy_reward=391.58\n",
      "    deterministic_reward=411.53\n",
      "    max_reward=441.06\n",
      "\n",
      "Training episode 22900    \n",
      "    reward=207.61\n",
      "\n",
      "Test run after episode 22900:\n",
      "    reward=187.41\n",
      "    greedy_reward=343.93\n",
      "    deterministic_reward=343.99\n",
      "    max_reward=430.66\n",
      "\n",
      "Training episode 22950    \n",
      "    reward=215.21\n",
      "\n",
      "Test run after episode 22950:\n",
      "    reward=175.25\n",
      "    greedy_reward=379.73\n",
      "    deterministic_reward=389.58\n",
      "    max_reward=402.56\n",
      "\n",
      "Training episode 23000    \n",
      "    reward=200.21\n",
      "\n",
      "Test run after episode 23000:\n",
      "    reward=173.24\n",
      "    greedy_reward=243.16\n",
      "    deterministic_reward=272.70\n",
      "    max_reward=298.77\n",
      "\n",
      "Training episode 23050    \n",
      "    reward=195.01\n",
      "\n",
      "Test run after episode 23050:\n",
      "    reward=233.30\n",
      "    greedy_reward=393.55\n",
      "    deterministic_reward=406.19\n",
      "    max_reward=448.30\n",
      "\n",
      "Training episode 23100    \n",
      "    reward=213.57\n",
      "\n",
      "Test run after episode 23100:\n",
      "    reward=198.67\n",
      "    greedy_reward=362.66\n",
      "    deterministic_reward=363.44\n",
      "    max_reward=398.83\n",
      "\n",
      "Training episode 23150    \n",
      "    reward=211.78\n",
      "\n",
      "Test run after episode 23150:\n",
      "    reward=247.00\n",
      "    greedy_reward=425.28\n",
      "    deterministic_reward=444.16\n",
      "    max_reward=495.48\n",
      "\n",
      "Training episode 23200    \n",
      "    reward=199.61\n",
      "\n",
      "Test run after episode 23200:\n",
      "    reward=202.32\n",
      "    greedy_reward=373.65\n",
      "    deterministic_reward=378.69\n",
      "    max_reward=469.99\n",
      "\n",
      "Training episode 23250    \n",
      "    reward=199.18\n",
      "\n",
      "Test run after episode 23250:\n",
      "    reward=218.41\n",
      "    greedy_reward=317.72\n",
      "    deterministic_reward=354.90\n",
      "    max_reward=363.07\n",
      "\n",
      "Training episode 23300    \n",
      "    reward=203.49\n",
      "\n",
      "Test run after episode 23300:\n",
      "    reward=227.96\n",
      "    greedy_reward=310.25\n",
      "    deterministic_reward=342.66\n",
      "    max_reward=371.89\n",
      "\n",
      "Training episode 23350    \n",
      "    reward=213.33\n",
      "\n",
      "Test run after episode 23350:\n",
      "    reward=166.87\n",
      "    greedy_reward=283.73\n",
      "    deterministic_reward=301.91\n",
      "    max_reward=310.52\n",
      "\n",
      "Training episode 23400    \n",
      "    reward=211.56\n",
      "\n",
      "Test run after episode 23400:\n",
      "    reward=347.30\n",
      "    greedy_reward=413.51\n",
      "    deterministic_reward=427.03\n",
      "    max_reward=485.30\n",
      "\n",
      "Training episode 23450    \n",
      "    reward=212.45\n",
      "\n",
      "Test run after episode 23450:\n",
      "    reward=271.74\n",
      "    greedy_reward=428.31\n",
      "    deterministic_reward=435.31\n",
      "    max_reward=526.27\n",
      "\n",
      "Training episode 23500    \n",
      "    reward=202.79\n",
      "\n",
      "Test run after episode 23500:\n",
      "    reward=210.48\n",
      "    greedy_reward=339.16\n",
      "    deterministic_reward=349.95\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 23550    \n",
      "    reward=215.75\n",
      "\n",
      "Test run after episode 23550:\n",
      "    reward=165.03\n",
      "    greedy_reward=296.21\n",
      "    deterministic_reward=317.30\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 23600    \n",
      "    reward=202.00\n",
      "\n",
      "Test run after episode 23600:\n",
      "    reward=212.23\n",
      "    greedy_reward=296.73\n",
      "    deterministic_reward=309.90\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 23650    \n",
      "    reward=213.11\n",
      "\n",
      "Test run after episode 23650:\n",
      "    reward=166.31\n",
      "    greedy_reward=272.38\n",
      "    deterministic_reward=295.78\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 23700    \n",
      "    reward=209.26\n",
      "\n",
      "Test run after episode 23700:\n",
      "    reward=204.24\n",
      "    greedy_reward=365.89\n",
      "    deterministic_reward=379.90\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 23750    \n",
      "    reward=206.66\n",
      "\n",
      "Test run after episode 23750:\n",
      "    reward=304.62\n",
      "    greedy_reward=348.59\n",
      "    deterministic_reward=345.29\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 23800    \n",
      "    reward=205.96\n",
      "\n",
      "Test run after episode 23800:\n",
      "    reward=209.76\n",
      "    greedy_reward=429.89\n",
      "    deterministic_reward=461.46\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 23850    \n",
      "    reward=207.47\n",
      "\n",
      "Test run after episode 23850:\n",
      "    reward=187.46\n",
      "    greedy_reward=315.55\n",
      "    deterministic_reward=339.41\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 23900    \n",
      "    reward=213.67\n",
      "\n",
      "Test run after episode 23900:\n",
      "    reward=161.18\n",
      "    greedy_reward=272.51\n",
      "    deterministic_reward=283.27\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 23950    \n",
      "    reward=207.09\n",
      "\n",
      "Test run after episode 23950:\n",
      "    reward=168.66\n",
      "    greedy_reward=291.82\n",
      "    deterministic_reward=296.45\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 24000    \n",
      "    reward=197.39\n",
      "\n",
      "Test run after episode 24000:\n",
      "    reward=188.10\n",
      "    greedy_reward=353.13\n",
      "    deterministic_reward=383.80\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 24050    \n",
      "    reward=209.33\n",
      "\n",
      "Test run after episode 24050:\n",
      "    reward=151.89\n",
      "    greedy_reward=275.50\n",
      "    deterministic_reward=285.93\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 24100    \n",
      "    reward=206.29\n",
      "\n",
      "Test run after episode 24100:\n",
      "    reward=201.80\n",
      "    greedy_reward=303.06\n",
      "    deterministic_reward=316.32\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 24150    \n",
      "    reward=203.84\n",
      "\n",
      "Test run after episode 24150:\n",
      "    reward=194.56\n",
      "    greedy_reward=260.42\n",
      "    deterministic_reward=266.07\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 24200    \n",
      "    reward=206.26\n",
      "\n",
      "Test run after episode 24200:\n",
      "    reward=171.79\n",
      "    greedy_reward=314.00\n",
      "    deterministic_reward=343.67\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 24250    \n",
      "    reward=206.20\n",
      "\n",
      "Test run after episode 24250:\n",
      "    reward=198.35\n",
      "    greedy_reward=285.27\n",
      "    deterministic_reward=311.39\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 24300    \n",
      "    reward=198.34\n",
      "\n",
      "Test run after episode 24300:\n",
      "    reward=190.02\n",
      "    greedy_reward=373.94\n",
      "    deterministic_reward=374.99\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 24350    \n",
      "    reward=192.21\n",
      "\n",
      "Test run after episode 24350:\n",
      "    reward=247.90\n",
      "    greedy_reward=287.29\n",
      "    deterministic_reward=331.78\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 24400    \n",
      "    reward=209.81\n",
      "\n",
      "Test run after episode 24400:\n",
      "    reward=178.52\n",
      "    greedy_reward=250.41\n",
      "    deterministic_reward=265.11\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 24450    \n",
      "    reward=210.69\n",
      "\n",
      "Test run after episode 24450:\n",
      "    reward=213.42\n",
      "    greedy_reward=395.24\n",
      "    deterministic_reward=428.14\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 24500    \n",
      "    reward=203.74\n",
      "\n",
      "Test run after episode 24500:\n",
      "    reward=199.08\n",
      "    greedy_reward=334.30\n",
      "    deterministic_reward=356.30\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 24550    \n",
      "    reward=220.71\n",
      "\n",
      "Test run after episode 24550:\n",
      "    reward=219.12\n",
      "    greedy_reward=316.11\n",
      "    deterministic_reward=337.12\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 24600    \n",
      "    reward=206.39\n",
      "\n",
      "Test run after episode 24600:\n",
      "    reward=350.39\n",
      "    greedy_reward=333.05\n",
      "    deterministic_reward=354.89\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 24650    \n",
      "    reward=201.88\n",
      "\n",
      "Test run after episode 24650:\n",
      "    reward=200.83\n",
      "    greedy_reward=294.30\n",
      "    deterministic_reward=334.00\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 24700    \n",
      "    reward=218.12\n",
      "\n",
      "Test run after episode 24700:\n",
      "    reward=245.25\n",
      "    greedy_reward=303.05\n",
      "    deterministic_reward=309.65\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 24750    \n",
      "    reward=211.03\n",
      "\n",
      "Test run after episode 24750:\n",
      "    reward=188.79\n",
      "    greedy_reward=296.52\n",
      "    deterministic_reward=311.87\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 24800    \n",
      "    reward=212.20\n",
      "\n",
      "Test run after episode 24800:\n",
      "    reward=232.80\n",
      "    greedy_reward=288.55\n",
      "    deterministic_reward=308.23\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 24850    \n",
      "    reward=222.32\n",
      "\n",
      "Test run after episode 24850:\n",
      "    reward=146.76\n",
      "    greedy_reward=232.16\n",
      "    deterministic_reward=236.91\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 24900    \n",
      "    reward=210.50\n",
      "\n",
      "Test run after episode 24900:\n",
      "    reward=197.54\n",
      "    greedy_reward=351.47\n",
      "    deterministic_reward=357.90\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 24950    \n",
      "    reward=214.59\n",
      "\n",
      "Test run after episode 24950:\n",
      "    reward=162.39\n",
      "    greedy_reward=305.43\n",
      "    deterministic_reward=316.17\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 25000    \n",
      "    reward=208.08\n",
      "\n",
      "Test run after episode 25000:\n",
      "    reward=191.53\n",
      "    greedy_reward=350.34\n",
      "    deterministic_reward=366.59\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 25050    \n",
      "    reward=210.04\n",
      "\n",
      "Test run after episode 25050:\n",
      "    reward=224.36\n",
      "    greedy_reward=355.04\n",
      "    deterministic_reward=370.11\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 25100    \n",
      "    reward=208.83\n",
      "\n",
      "Test run after episode 25100:\n",
      "    reward=168.48\n",
      "    greedy_reward=299.17\n",
      "    deterministic_reward=305.26\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 25150    \n",
      "    reward=192.33\n",
      "\n",
      "Test run after episode 25150:\n",
      "    reward=99.44\n",
      "    greedy_reward=207.30\n",
      "    deterministic_reward=214.07\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 25200    \n",
      "    reward=198.77\n",
      "\n",
      "Test run after episode 25200:\n",
      "    reward=173.85\n",
      "    greedy_reward=292.36\n",
      "    deterministic_reward=318.05\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 25250    \n",
      "    reward=207.25\n",
      "\n",
      "Test run after episode 25250:\n",
      "    reward=177.27\n",
      "    greedy_reward=262.98\n",
      "    deterministic_reward=277.74\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 25300    \n",
      "    reward=207.35\n",
      "\n",
      "Test run after episode 25300:\n",
      "    reward=228.23\n",
      "    greedy_reward=368.07\n",
      "    deterministic_reward=374.03\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 25350    \n",
      "    reward=195.63\n",
      "\n",
      "Test run after episode 25350:\n",
      "    reward=218.92\n",
      "    greedy_reward=396.14\n",
      "    deterministic_reward=407.24\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 25400    \n",
      "    reward=197.13\n",
      "\n",
      "Test run after episode 25400:\n",
      "    reward=218.48\n",
      "    greedy_reward=340.46\n",
      "    deterministic_reward=361.31\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 25450    \n",
      "    reward=214.77\n",
      "\n",
      "Test run after episode 25450:\n",
      "    reward=211.13\n",
      "    greedy_reward=342.37\n",
      "    deterministic_reward=380.89\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 25500    \n",
      "    reward=196.05\n",
      "\n",
      "Test run after episode 25500:\n",
      "    reward=259.60\n",
      "    greedy_reward=326.16\n",
      "    deterministic_reward=363.79\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 25550    \n",
      "    reward=218.70\n",
      "\n",
      "Test run after episode 25550:\n",
      "    reward=94.12\n",
      "    greedy_reward=339.93\n",
      "    deterministic_reward=339.66\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 25600    \n",
      "    reward=206.50\n",
      "\n",
      "Test run after episode 25600:\n",
      "    reward=110.25\n",
      "    greedy_reward=297.03\n",
      "    deterministic_reward=330.02\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 25650    \n",
      "    reward=210.45\n",
      "\n",
      "Test run after episode 25650:\n",
      "    reward=139.75\n",
      "    greedy_reward=223.59\n",
      "    deterministic_reward=229.46\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 25700    \n",
      "    reward=203.17\n",
      "\n",
      "Test run after episode 25700:\n",
      "    reward=312.13\n",
      "    greedy_reward=348.10\n",
      "    deterministic_reward=347.05\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 25750    \n",
      "    reward=199.83\n",
      "\n",
      "Test run after episode 25750:\n",
      "    reward=152.80\n",
      "    greedy_reward=240.19\n",
      "    deterministic_reward=242.44\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 25800    \n",
      "    reward=205.29\n",
      "\n",
      "Test run after episode 25800:\n",
      "    reward=144.01\n",
      "    greedy_reward=307.23\n",
      "    deterministic_reward=323.78\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 25850    \n",
      "    reward=195.32\n",
      "\n",
      "Test run after episode 25850:\n",
      "    reward=273.84\n",
      "    greedy_reward=308.22\n",
      "    deterministic_reward=356.98\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 25900    \n",
      "    reward=198.55\n",
      "\n",
      "Test run after episode 25900:\n",
      "    reward=238.59\n",
      "    greedy_reward=276.09\n",
      "    deterministic_reward=287.24\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 25950    \n",
      "    reward=216.39\n",
      "\n",
      "Test run after episode 25950:\n",
      "    reward=291.87\n",
      "    greedy_reward=368.95\n",
      "    deterministic_reward=363.95\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 26000    \n",
      "    reward=215.22\n",
      "\n",
      "Test run after episode 26000:\n",
      "    reward=178.65\n",
      "    greedy_reward=285.90\n",
      "    deterministic_reward=308.92\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 26050    \n",
      "    reward=203.20\n",
      "\n",
      "Test run after episode 26050:\n",
      "    reward=206.08\n",
      "    greedy_reward=271.34\n",
      "    deterministic_reward=294.00\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 26100    \n",
      "    reward=204.26\n",
      "\n",
      "Test run after episode 26100:\n",
      "    reward=302.02\n",
      "    greedy_reward=435.41\n",
      "    deterministic_reward=451.30\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 26150    \n",
      "    reward=211.10\n",
      "\n",
      "Test run after episode 26150:\n",
      "    reward=166.11\n",
      "    greedy_reward=254.52\n",
      "    deterministic_reward=264.51\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 26200    \n",
      "    reward=214.44\n",
      "\n",
      "Test run after episode 26200:\n",
      "    reward=139.35\n",
      "    greedy_reward=277.76\n",
      "    deterministic_reward=285.98\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 26250    \n",
      "    reward=206.04\n",
      "\n",
      "Test run after episode 26250:\n",
      "    reward=134.52\n",
      "    greedy_reward=212.07\n",
      "    deterministic_reward=228.34\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 26300    \n",
      "    reward=205.67\n",
      "\n",
      "Test run after episode 26300:\n",
      "    reward=213.27\n",
      "    greedy_reward=287.57\n",
      "    deterministic_reward=301.86\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 26350    \n",
      "    reward=199.87\n",
      "\n",
      "Test run after episode 26350:\n",
      "    reward=158.68\n",
      "    greedy_reward=372.14\n",
      "    deterministic_reward=393.67\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 26400    \n",
      "    reward=194.31\n",
      "\n",
      "Test run after episode 26400:\n",
      "    reward=223.25\n",
      "    greedy_reward=348.82\n",
      "    deterministic_reward=366.13\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 26450    \n",
      "    reward=203.41\n",
      "\n",
      "Test run after episode 26450:\n",
      "    reward=168.16\n",
      "    greedy_reward=282.72\n",
      "    deterministic_reward=311.12\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 26500    \n",
      "    reward=209.26\n",
      "\n",
      "Test run after episode 26500:\n",
      "    reward=186.08\n",
      "    greedy_reward=288.83\n",
      "    deterministic_reward=305.80\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 26550    \n",
      "    reward=216.83\n",
      "\n",
      "Test run after episode 26550:\n",
      "    reward=226.33\n",
      "    greedy_reward=380.07\n",
      "    deterministic_reward=393.68\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 26600    \n",
      "    reward=205.11\n",
      "\n",
      "Test run after episode 26600:\n",
      "    reward=200.97\n",
      "    greedy_reward=277.85\n",
      "    deterministic_reward=307.60\n",
      "    max_reward=319.32\n",
      "\n",
      "Training episode 26650    \n",
      "    reward=194.34\n",
      "\n",
      "Test run after episode 26650:\n",
      "    reward=106.55\n",
      "    greedy_reward=221.72\n",
      "    deterministic_reward=223.95\n",
      "    max_reward=225.34\n",
      "\n",
      "Training episode 26700    \n",
      "    reward=210.83\n",
      "\n",
      "Test run after episode 26700:\n",
      "    reward=262.41\n",
      "    greedy_reward=374.84\n",
      "    deterministic_reward=371.38\n",
      "    max_reward=546.74\n",
      "\n",
      "Training episode 26750    \n",
      "    reward=207.79\n",
      "\n",
      "Test run after episode 26750:\n",
      "    reward=139.34\n",
      "    greedy_reward=307.60\n",
      "    deterministic_reward=314.48\n",
      "    max_reward=319.65\n",
      "\n",
      "Training episode 26800    \n",
      "    reward=203.73\n",
      "\n",
      "Test run after episode 26800:\n",
      "    reward=129.22\n",
      "    greedy_reward=231.86\n",
      "    deterministic_reward=234.07\n",
      "    max_reward=243.54\n",
      "\n",
      "Training episode 26850    \n",
      "    reward=195.46\n",
      "\n",
      "Test run after episode 26850:\n",
      "    reward=155.97\n",
      "    greedy_reward=224.45\n",
      "    deterministic_reward=229.02\n",
      "    max_reward=230.71\n",
      "\n",
      "Training episode 26900    \n",
      "    reward=216.45\n",
      "\n",
      "Test run after episode 26900:\n",
      "    reward=206.40\n",
      "    greedy_reward=369.97\n",
      "    deterministic_reward=389.28\n",
      "    max_reward=410.50\n",
      "\n",
      "Training episode 26950    \n",
      "    reward=207.61\n",
      "\n",
      "Test run after episode 26950:\n",
      "    reward=206.52\n",
      "    greedy_reward=372.44\n",
      "    deterministic_reward=390.48\n",
      "    max_reward=403.17\n",
      "\n",
      "Training episode 27000    \n",
      "    reward=220.86\n",
      "\n",
      "Test run after episode 27000:\n",
      "    reward=239.04\n",
      "    greedy_reward=343.14\n",
      "    deterministic_reward=393.37\n",
      "    max_reward=411.02\n",
      "\n",
      "Training episode 27050    \n",
      "    reward=200.86\n",
      "\n",
      "Test run after episode 27050:\n",
      "    reward=179.35\n",
      "    greedy_reward=283.92\n",
      "    deterministic_reward=292.35\n",
      "    max_reward=300.75\n",
      "\n",
      "Training episode 27100    \n",
      "    reward=207.60\n",
      "\n",
      "Test run after episode 27100:\n",
      "    reward=211.01\n",
      "    greedy_reward=355.10\n",
      "    deterministic_reward=356.81\n",
      "    max_reward=375.10\n",
      "\n",
      "Training episode 27150    \n",
      "    reward=218.93\n",
      "\n",
      "Test run after episode 27150:\n",
      "    reward=125.27\n",
      "    greedy_reward=301.33\n",
      "    deterministic_reward=337.73\n",
      "    max_reward=347.72\n",
      "\n",
      "Training episode 27200    \n",
      "    reward=207.10\n",
      "\n",
      "Test run after episode 27200:\n",
      "    reward=213.87\n",
      "    greedy_reward=309.03\n",
      "    deterministic_reward=322.51\n",
      "    max_reward=333.23\n",
      "\n",
      "Training episode 27250    \n",
      "    reward=205.04\n",
      "\n",
      "Test run after episode 27250:\n",
      "    reward=187.13\n",
      "    greedy_reward=245.74\n",
      "    deterministic_reward=247.91\n",
      "    max_reward=315.38\n",
      "\n",
      "Training episode 27300    \n",
      "    reward=206.90\n",
      "\n",
      "Test run after episode 27300:\n",
      "    reward=157.24\n",
      "    greedy_reward=295.97\n",
      "    deterministic_reward=312.62\n",
      "    max_reward=344.52\n",
      "\n",
      "Training episode 27350    \n",
      "    reward=209.11\n",
      "\n",
      "Test run after episode 27350:\n",
      "    reward=201.03\n",
      "    greedy_reward=395.25\n",
      "    deterministic_reward=397.54\n",
      "    max_reward=501.64\n",
      "\n",
      "Training episode 27400    \n",
      "    reward=212.55\n",
      "\n",
      "Test run after episode 27400:\n",
      "    reward=141.18\n",
      "    greedy_reward=231.33\n",
      "    deterministic_reward=238.22\n",
      "    max_reward=240.74\n",
      "\n",
      "Training episode 27450    \n",
      "    reward=208.43\n",
      "\n",
      "Test run after episode 27450:\n",
      "    reward=222.63\n",
      "    greedy_reward=364.04\n",
      "    deterministic_reward=364.21\n",
      "    max_reward=429.00\n",
      "\n",
      "Training episode 27500    \n",
      "    reward=191.05\n",
      "\n",
      "Test run after episode 27500:\n",
      "    reward=213.74\n",
      "    greedy_reward=297.55\n",
      "    deterministic_reward=328.65\n",
      "    max_reward=332.83\n",
      "\n",
      "Training episode 27550    \n",
      "    reward=220.09\n",
      "\n",
      "Test run after episode 27550:\n",
      "    reward=127.47\n",
      "    greedy_reward=259.27\n",
      "    deterministic_reward=284.99\n",
      "    max_reward=292.08\n",
      "\n",
      "Training episode 27600    \n",
      "    reward=219.94\n",
      "\n",
      "Test run after episode 27600:\n",
      "    reward=74.54\n",
      "    greedy_reward=224.61\n",
      "    deterministic_reward=233.09\n",
      "    max_reward=237.14\n",
      "\n",
      "Training episode 27650    \n",
      "    reward=200.73\n",
      "\n",
      "Test run after episode 27650:\n",
      "    reward=178.16\n",
      "    greedy_reward=326.63\n",
      "    deterministic_reward=375.10\n",
      "    max_reward=395.37\n",
      "\n",
      "Training episode 27700    \n",
      "    reward=208.29\n",
      "\n",
      "Test run after episode 27700:\n",
      "    reward=149.59\n",
      "    greedy_reward=399.39\n",
      "    deterministic_reward=424.72\n",
      "    max_reward=434.18\n",
      "\n",
      "Training episode 27750    \n",
      "    reward=201.52\n",
      "\n",
      "Test run after episode 27750:\n",
      "    reward=176.54\n",
      "    greedy_reward=297.95\n",
      "    deterministic_reward=307.38\n",
      "    max_reward=312.22\n",
      "\n",
      "Training episode 27800    \n",
      "    reward=211.34\n",
      "\n",
      "Test run after episode 27800:\n",
      "    reward=133.77\n",
      "    greedy_reward=351.12\n",
      "    deterministic_reward=347.67\n",
      "    max_reward=470.55\n",
      "\n",
      "Training episode 27850    \n",
      "    reward=211.97\n",
      "\n",
      "Test run after episode 27850:\n",
      "    reward=169.78\n",
      "    greedy_reward=326.92\n",
      "    deterministic_reward=347.69\n",
      "    max_reward=360.32\n",
      "\n",
      "Training episode 27900    \n",
      "    reward=198.37\n",
      "\n",
      "Test run after episode 27900:\n",
      "    reward=248.67\n",
      "    greedy_reward=346.22\n",
      "    deterministic_reward=358.53\n",
      "    max_reward=389.11\n",
      "\n",
      "Training episode 27950    \n",
      "    reward=212.92\n",
      "\n",
      "Test run after episode 27950:\n",
      "    reward=216.18\n",
      "    greedy_reward=388.44\n",
      "    deterministic_reward=408.60\n",
      "    max_reward=441.06\n",
      "\n",
      "Training episode 28000    \n",
      "    reward=207.49\n",
      "\n",
      "Test run after episode 28000:\n",
      "    reward=187.34\n",
      "    greedy_reward=404.88\n",
      "    deterministic_reward=411.44\n",
      "    max_reward=430.66\n",
      "\n",
      "Training episode 28050    \n",
      "    reward=215.52\n",
      "\n",
      "Test run after episode 28050:\n",
      "    reward=175.22\n",
      "    greedy_reward=347.85\n",
      "    deterministic_reward=349.63\n",
      "    max_reward=402.56\n",
      "\n",
      "Training episode 28100    \n",
      "    reward=200.04\n",
      "\n",
      "Test run after episode 28100:\n",
      "    reward=173.21\n",
      "    greedy_reward=263.90\n",
      "    deterministic_reward=291.39\n",
      "    max_reward=298.77\n",
      "\n",
      "Training episode 28150    \n",
      "    reward=194.83\n",
      "\n",
      "Test run after episode 28150:\n",
      "    reward=233.27\n",
      "    greedy_reward=334.21\n",
      "    deterministic_reward=349.14\n",
      "    max_reward=448.30\n",
      "\n",
      "Training episode 28200    \n",
      "    reward=214.09\n",
      "\n",
      "Test run after episode 28200:\n",
      "    reward=198.69\n",
      "    greedy_reward=374.91\n",
      "    deterministic_reward=373.02\n",
      "    max_reward=398.83\n",
      "\n",
      "Training episode 28250    \n",
      "    reward=211.25\n",
      "\n",
      "Test run after episode 28250:\n",
      "    reward=246.97\n",
      "    greedy_reward=422.90\n",
      "    deterministic_reward=433.38\n",
      "    max_reward=495.48\n",
      "\n",
      "Training episode 28300    \n",
      "    reward=199.76\n",
      "\n",
      "Test run after episode 28300:\n",
      "    reward=202.33\n",
      "    greedy_reward=360.42\n",
      "    deterministic_reward=362.25\n",
      "    max_reward=469.99\n",
      "\n",
      "Training episode 28350    \n",
      "    reward=199.42\n",
      "\n",
      "Test run after episode 28350:\n",
      "    reward=218.34\n",
      "    greedy_reward=321.14\n",
      "    deterministic_reward=354.51\n",
      "    max_reward=363.07\n",
      "\n",
      "Training episode 28400    \n",
      "    reward=203.47\n",
      "\n",
      "Test run after episode 28400:\n",
      "    reward=227.94\n",
      "    greedy_reward=288.51\n",
      "    deterministic_reward=323.43\n",
      "    max_reward=371.89\n",
      "\n",
      "Training episode 28450    \n",
      "    reward=213.69\n",
      "\n",
      "Test run after episode 28450:\n",
      "    reward=166.89\n",
      "    greedy_reward=285.59\n",
      "    deterministic_reward=302.26\n",
      "    max_reward=310.52\n",
      "\n",
      "Training episode 28500    \n",
      "    reward=211.59\n",
      "\n",
      "Test run after episode 28500:\n",
      "    reward=347.33\n",
      "    greedy_reward=404.79\n",
      "    deterministic_reward=418.98\n",
      "    max_reward=485.30\n",
      "\n",
      "Training episode 28550    \n",
      "    reward=212.62\n",
      "\n",
      "Test run after episode 28550:\n",
      "    reward=271.77\n",
      "    greedy_reward=437.71\n",
      "    deterministic_reward=445.85\n",
      "    max_reward=526.27\n",
      "\n",
      "Training episode 28600    \n",
      "    reward=203.00\n",
      "\n",
      "Test run after episode 28600:\n",
      "    reward=210.46\n",
      "    greedy_reward=304.66\n",
      "    deterministic_reward=333.75\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 28650    \n",
      "    reward=215.87\n",
      "\n",
      "Test run after episode 28650:\n",
      "    reward=165.04\n",
      "    greedy_reward=305.97\n",
      "    deterministic_reward=317.26\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 28700    \n",
      "    reward=202.09\n",
      "\n",
      "Test run after episode 28700:\n",
      "    reward=212.24\n",
      "    greedy_reward=293.89\n",
      "    deterministic_reward=303.79\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 28750    \n",
      "    reward=213.27\n",
      "\n",
      "Test run after episode 28750:\n",
      "    reward=166.38\n",
      "    greedy_reward=279.65\n",
      "    deterministic_reward=298.34\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 28800    \n",
      "    reward=209.49\n",
      "\n",
      "Test run after episode 28800:\n",
      "    reward=204.26\n",
      "    greedy_reward=335.11\n",
      "    deterministic_reward=356.03\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 28850    \n",
      "    reward=207.10\n",
      "\n",
      "Test run after episode 28850:\n",
      "    reward=304.64\n",
      "    greedy_reward=350.79\n",
      "    deterministic_reward=348.52\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 28900    \n",
      "    reward=205.90\n",
      "\n",
      "Test run after episode 28900:\n",
      "    reward=209.75\n",
      "    greedy_reward=445.23\n",
      "    deterministic_reward=476.25\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 28950    \n",
      "    reward=207.83\n",
      "\n",
      "Test run after episode 28950:\n",
      "    reward=187.42\n",
      "    greedy_reward=280.99\n",
      "    deterministic_reward=297.80\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 29000    \n",
      "    reward=213.42\n",
      "\n",
      "Test run after episode 29000:\n",
      "    reward=161.20\n",
      "    greedy_reward=279.01\n",
      "    deterministic_reward=286.42\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 29050    \n",
      "    reward=207.18\n",
      "\n",
      "Test run after episode 29050:\n",
      "    reward=168.67\n",
      "    greedy_reward=293.89\n",
      "    deterministic_reward=298.85\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 29100    \n",
      "    reward=197.44\n",
      "\n",
      "Test run after episode 29100:\n",
      "    reward=188.11\n",
      "    greedy_reward=360.56\n",
      "    deterministic_reward=385.60\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 29150    \n",
      "    reward=209.87\n",
      "\n",
      "Test run after episode 29150:\n",
      "    reward=151.87\n",
      "    greedy_reward=290.30\n",
      "    deterministic_reward=298.79\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 29200    \n",
      "    reward=206.54\n",
      "\n",
      "Test run after episode 29200:\n",
      "    reward=201.77\n",
      "    greedy_reward=313.49\n",
      "    deterministic_reward=320.00\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 29250    \n",
      "    reward=204.26\n",
      "\n",
      "Test run after episode 29250:\n",
      "    reward=194.48\n",
      "    greedy_reward=275.08\n",
      "    deterministic_reward=281.42\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 29300    \n",
      "    reward=206.35\n",
      "\n",
      "Test run after episode 29300:\n",
      "    reward=171.82\n",
      "    greedy_reward=320.18\n",
      "    deterministic_reward=346.17\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 29350    \n",
      "    reward=206.56\n",
      "\n",
      "Test run after episode 29350:\n",
      "    reward=198.36\n",
      "    greedy_reward=339.02\n",
      "    deterministic_reward=369.41\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 29400    \n",
      "    reward=198.06\n",
      "\n",
      "Test run after episode 29400:\n",
      "    reward=190.01\n",
      "    greedy_reward=373.24\n",
      "    deterministic_reward=372.51\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 29450    \n",
      "    reward=192.11\n",
      "\n",
      "Test run after episode 29450:\n",
      "    reward=247.90\n",
      "    greedy_reward=349.35\n",
      "    deterministic_reward=395.83\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 29500    \n",
      "    reward=209.94\n",
      "\n",
      "Test run after episode 29500:\n",
      "    reward=178.45\n",
      "    greedy_reward=242.46\n",
      "    deterministic_reward=259.27\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 29550    \n",
      "    reward=210.20\n",
      "\n",
      "Test run after episode 29550:\n",
      "    reward=213.44\n",
      "    greedy_reward=403.48\n",
      "    deterministic_reward=436.64\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 29600    \n",
      "    reward=204.18\n",
      "\n",
      "Test run after episode 29600:\n",
      "    reward=199.14\n",
      "    greedy_reward=329.05\n",
      "    deterministic_reward=362.17\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 29650    \n",
      "    reward=220.70\n",
      "\n",
      "Test run after episode 29650:\n",
      "    reward=219.12\n",
      "    greedy_reward=312.65\n",
      "    deterministic_reward=334.81\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 29700    \n",
      "    reward=206.16\n",
      "\n",
      "Test run after episode 29700:\n",
      "    reward=350.38\n",
      "    greedy_reward=369.31\n",
      "    deterministic_reward=415.98\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 29750    \n",
      "    reward=201.89\n",
      "\n",
      "Test run after episode 29750:\n",
      "    reward=200.85\n",
      "    greedy_reward=258.78\n",
      "    deterministic_reward=300.14\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 29800    \n",
      "    reward=217.61\n",
      "\n",
      "Test run after episode 29800:\n",
      "    reward=245.19\n",
      "    greedy_reward=299.89\n",
      "    deterministic_reward=307.60\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 29850    \n",
      "    reward=211.18\n",
      "\n",
      "Test run after episode 29850:\n",
      "    reward=188.83\n",
      "    greedy_reward=292.13\n",
      "    deterministic_reward=310.52\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 29900    \n",
      "    reward=211.67\n",
      "\n",
      "Test run after episode 29900:\n",
      "    reward=232.81\n",
      "    greedy_reward=314.81\n",
      "    deterministic_reward=325.15\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 29950    \n",
      "    reward=222.52\n",
      "\n",
      "Test run after episode 29950:\n",
      "    reward=146.73\n",
      "    greedy_reward=191.94\n",
      "    deterministic_reward=207.75\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 30000    \n",
      "    reward=210.28\n",
      "\n",
      "Test run after episode 30000:\n",
      "    reward=197.59\n",
      "    greedy_reward=391.35\n",
      "    deterministic_reward=406.42\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 30050    \n",
      "    reward=214.12\n",
      "\n",
      "Test run after episode 30050:\n",
      "    reward=162.37\n",
      "    greedy_reward=280.08\n",
      "    deterministic_reward=300.41\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 30100    \n",
      "    reward=207.95\n",
      "\n",
      "Test run after episode 30100:\n",
      "    reward=191.53\n",
      "    greedy_reward=389.97\n",
      "    deterministic_reward=405.12\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 30150    \n",
      "    reward=210.06\n",
      "\n",
      "Test run after episode 30150:\n",
      "    reward=224.46\n",
      "    greedy_reward=356.02\n",
      "    deterministic_reward=372.06\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 30200    \n",
      "    reward=208.82\n",
      "\n",
      "Test run after episode 30200:\n",
      "    reward=168.49\n",
      "    greedy_reward=295.83\n",
      "    deterministic_reward=305.40\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 30250    \n",
      "    reward=192.06\n",
      "\n",
      "Test run after episode 30250:\n",
      "    reward=99.42\n",
      "    greedy_reward=206.72\n",
      "    deterministic_reward=212.89\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 30300    \n",
      "    reward=198.76\n",
      "\n",
      "Test run after episode 30300:\n",
      "    reward=173.90\n",
      "    greedy_reward=291.21\n",
      "    deterministic_reward=316.20\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 30350    \n",
      "    reward=207.24\n",
      "\n",
      "Test run after episode 30350:\n",
      "    reward=177.22\n",
      "    greedy_reward=262.52\n",
      "    deterministic_reward=274.99\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 30400    \n",
      "    reward=207.12\n",
      "\n",
      "Test run after episode 30400:\n",
      "    reward=228.23\n",
      "    greedy_reward=367.09\n",
      "    deterministic_reward=371.94\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 30450    \n",
      "    reward=195.45\n",
      "\n",
      "Test run after episode 30450:\n",
      "    reward=218.98\n",
      "    greedy_reward=403.90\n",
      "    deterministic_reward=413.09\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 30500    \n",
      "    reward=197.57\n",
      "\n",
      "Test run after episode 30500:\n",
      "    reward=218.47\n",
      "    greedy_reward=317.21\n",
      "    deterministic_reward=337.62\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 30550    \n",
      "    reward=214.42\n",
      "\n",
      "Test run after episode 30550:\n",
      "    reward=211.17\n",
      "    greedy_reward=345.54\n",
      "    deterministic_reward=386.37\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 30600    \n",
      "    reward=196.07\n",
      "\n",
      "Test run after episode 30600:\n",
      "    reward=259.56\n",
      "    greedy_reward=275.35\n",
      "    deterministic_reward=306.58\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 30650    \n",
      "    reward=241.71\n",
      "\n",
      "Test run after episode 30650:\n",
      "    reward=151.38\n",
      "    greedy_reward=345.06\n",
      "    deterministic_reward=344.94\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 30700    \n",
      "    reward=228.88\n",
      "\n",
      "Test run after episode 30700:\n",
      "    reward=135.96\n",
      "    greedy_reward=287.70\n",
      "    deterministic_reward=328.59\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 30750    \n",
      "    reward=237.12\n",
      "\n",
      "Test run after episode 30750:\n",
      "    reward=148.31\n",
      "    greedy_reward=228.83\n",
      "    deterministic_reward=232.05\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 30800    \n",
      "    reward=231.55\n",
      "\n",
      "Test run after episode 30800:\n",
      "    reward=314.57\n",
      "    greedy_reward=346.00\n",
      "    deterministic_reward=347.61\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 30850    \n",
      "    reward=224.55\n",
      "\n",
      "Test run after episode 30850:\n",
      "    reward=169.98\n",
      "    greedy_reward=223.32\n",
      "    deterministic_reward=238.88\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 30900    \n",
      "    reward=234.85\n",
      "\n",
      "Test run after episode 30900:\n",
      "    reward=169.47\n",
      "    greedy_reward=315.01\n",
      "    deterministic_reward=322.98\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 30950    \n",
      "    reward=218.63\n",
      "\n",
      "Test run after episode 30950:\n",
      "    reward=280.31\n",
      "    greedy_reward=307.05\n",
      "    deterministic_reward=352.84\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 31000    \n",
      "    reward=223.98\n",
      "\n",
      "Test run after episode 31000:\n",
      "    reward=250.74\n",
      "    greedy_reward=282.62\n",
      "    deterministic_reward=289.61\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 31050    \n",
      "    reward=242.37\n",
      "\n",
      "Test run after episode 31050:\n",
      "    reward=296.09\n",
      "    greedy_reward=384.47\n",
      "    deterministic_reward=383.72\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 31100    \n",
      "    reward=238.43\n",
      "\n",
      "Test run after episode 31100:\n",
      "    reward=202.77\n",
      "    greedy_reward=289.85\n",
      "    deterministic_reward=308.06\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 31150    \n",
      "    reward=229.39\n",
      "\n",
      "Test run after episode 31150:\n",
      "    reward=216.85\n",
      "    greedy_reward=277.34\n",
      "    deterministic_reward=296.21\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 31200    \n",
      "    reward=234.45\n",
      "\n",
      "Test run after episode 31200:\n",
      "    reward=318.88\n",
      "    greedy_reward=432.30\n",
      "    deterministic_reward=443.93\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 31250    \n",
      "    reward=238.55\n",
      "\n",
      "Test run after episode 31250:\n",
      "    reward=166.03\n",
      "    greedy_reward=263.49\n",
      "    deterministic_reward=273.52\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 31300    \n",
      "    reward=236.65\n",
      "\n",
      "Test run after episode 31300:\n",
      "    reward=183.73\n",
      "    greedy_reward=282.09\n",
      "    deterministic_reward=288.07\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 31350    \n",
      "    reward=231.22\n",
      "\n",
      "Test run after episode 31350:\n",
      "    reward=140.52\n",
      "    greedy_reward=223.54\n",
      "    deterministic_reward=231.50\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 31400    \n",
      "    reward=229.27\n",
      "\n",
      "Test run after episode 31400:\n",
      "    reward=232.84\n",
      "    greedy_reward=282.84\n",
      "    deterministic_reward=302.08\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 31450    \n",
      "    reward=226.91\n",
      "\n",
      "Test run after episode 31450:\n",
      "    reward=164.34\n",
      "    greedy_reward=370.92\n",
      "    deterministic_reward=395.25\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 31500    \n",
      "    reward=216.39\n",
      "\n",
      "Test run after episode 31500:\n",
      "    reward=251.36\n",
      "    greedy_reward=343.38\n",
      "    deterministic_reward=366.24\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 31550    \n",
      "    reward=230.43\n",
      "\n",
      "Test run after episode 31550:\n",
      "    reward=211.48\n",
      "    greedy_reward=276.98\n",
      "    deterministic_reward=308.55\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 31600    \n",
      "    reward=236.45\n",
      "\n",
      "Test run after episode 31600:\n",
      "    reward=199.92\n",
      "    greedy_reward=305.28\n",
      "    deterministic_reward=317.05\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 31650    \n",
      "    reward=242.06\n",
      "\n",
      "Test run after episode 31650:\n",
      "    reward=266.27\n",
      "    greedy_reward=357.25\n",
      "    deterministic_reward=372.18\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 31700    \n",
      "    reward=235.15\n",
      "\n",
      "Test run after episode 31700:\n",
      "    reward=215.86\n",
      "    greedy_reward=281.58\n",
      "    deterministic_reward=308.21\n",
      "    max_reward=319.32\n",
      "\n",
      "Training episode 31750    \n",
      "    reward=220.23\n",
      "\n",
      "Test run after episode 31750:\n",
      "    reward=113.47\n",
      "    greedy_reward=211.91\n",
      "    deterministic_reward=219.68\n",
      "    max_reward=225.34\n",
      "\n",
      "Training episode 31800    \n",
      "    reward=238.16\n",
      "\n",
      "Test run after episode 31800:\n",
      "    reward=317.62\n",
      "    greedy_reward=424.08\n",
      "    deterministic_reward=427.58\n",
      "    max_reward=546.74\n",
      "\n",
      "Training episode 31850    \n",
      "    reward=237.16\n",
      "\n",
      "Test run after episode 31850:\n",
      "    reward=164.18\n",
      "    greedy_reward=265.56\n",
      "    deterministic_reward=269.57\n",
      "    max_reward=319.65\n",
      "\n",
      "Training episode 31900    \n",
      "    reward=233.24\n",
      "\n",
      "Test run after episode 31900:\n",
      "    reward=145.61\n",
      "    greedy_reward=234.16\n",
      "    deterministic_reward=235.77\n",
      "    max_reward=243.54\n",
      "\n",
      "Training episode 31950    \n",
      "    reward=225.13\n",
      "\n",
      "Test run after episode 31950:\n",
      "    reward=163.67\n",
      "    greedy_reward=212.00\n",
      "    deterministic_reward=224.51\n",
      "    max_reward=230.71\n",
      "\n",
      "Training episode 32000    \n",
      "    reward=244.41\n",
      "\n",
      "Test run after episode 32000:\n",
      "    reward=214.12\n",
      "    greedy_reward=386.99\n",
      "    deterministic_reward=403.32\n",
      "    max_reward=410.50\n",
      "\n",
      "Training episode 32050    \n",
      "    reward=230.30\n",
      "\n",
      "Test run after episode 32050:\n",
      "    reward=215.96\n",
      "    greedy_reward=361.42\n",
      "    deterministic_reward=386.99\n",
      "    max_reward=403.17\n",
      "\n",
      "Training episode 32100    \n",
      "    reward=253.62\n",
      "\n",
      "Test run after episode 32100:\n",
      "    reward=262.49\n",
      "    greedy_reward=320.51\n",
      "    deterministic_reward=377.79\n",
      "    max_reward=411.02\n",
      "\n",
      "Training episode 32150    \n",
      "    reward=225.39\n",
      "\n",
      "Test run after episode 32150:\n",
      "    reward=223.15\n",
      "    greedy_reward=286.76\n",
      "    deterministic_reward=296.23\n",
      "    max_reward=300.75\n",
      "\n",
      "Training episode 32200    \n",
      "    reward=235.40\n",
      "\n",
      "Test run after episode 32200:\n",
      "    reward=215.63\n",
      "    greedy_reward=344.32\n",
      "    deterministic_reward=348.37\n",
      "    max_reward=375.10\n",
      "\n",
      "Training episode 32250    \n",
      "    reward=246.52\n",
      "\n",
      "Test run after episode 32250:\n",
      "    reward=151.59\n",
      "    greedy_reward=300.71\n",
      "    deterministic_reward=338.14\n",
      "    max_reward=347.72\n",
      "\n",
      "Training episode 32300    \n",
      "    reward=235.90\n",
      "\n",
      "Test run after episode 32300:\n",
      "    reward=225.87\n",
      "    greedy_reward=300.47\n",
      "    deterministic_reward=318.99\n",
      "    max_reward=333.23\n",
      "\n",
      "Training episode 32350    \n",
      "    reward=231.33\n",
      "\n",
      "Test run after episode 32350:\n",
      "    reward=265.73\n",
      "    greedy_reward=251.70\n",
      "    deterministic_reward=251.68\n",
      "    max_reward=315.38\n",
      "\n",
      "Training episode 32400    \n",
      "    reward=238.65\n",
      "\n",
      "Test run after episode 32400:\n",
      "    reward=169.22\n",
      "    greedy_reward=288.65\n",
      "    deterministic_reward=312.84\n",
      "    max_reward=344.52\n",
      "\n",
      "Training episode 32450    \n",
      "    reward=237.47\n",
      "\n",
      "Test run after episode 32450:\n",
      "    reward=261.60\n",
      "    greedy_reward=399.29\n",
      "    deterministic_reward=401.44\n",
      "    max_reward=501.64\n",
      "\n",
      "Training episode 32500    \n",
      "    reward=232.61\n",
      "\n",
      "Test run after episode 32500:\n",
      "    reward=153.88\n",
      "    greedy_reward=218.81\n",
      "    deterministic_reward=235.44\n",
      "    max_reward=240.74\n",
      "\n",
      "Training episode 32550    \n",
      "    reward=236.50\n",
      "\n",
      "Test run after episode 32550:\n",
      "    reward=281.75\n",
      "    greedy_reward=379.96\n",
      "    deterministic_reward=384.11\n",
      "    max_reward=429.00\n",
      "\n",
      "Training episode 32600    \n",
      "    reward=218.00\n",
      "\n",
      "Test run after episode 32600:\n",
      "    reward=226.41\n",
      "    greedy_reward=292.31\n",
      "    deterministic_reward=323.28\n",
      "    max_reward=332.83\n",
      "\n",
      "Training episode 32650    \n",
      "    reward=243.17\n",
      "\n",
      "Test run after episode 32650:\n",
      "    reward=163.16\n",
      "    greedy_reward=262.49\n",
      "    deterministic_reward=285.69\n",
      "    max_reward=292.08\n",
      "\n",
      "Training episode 32700    \n",
      "    reward=247.23\n",
      "\n",
      "Test run after episode 32700:\n",
      "    reward=91.61\n",
      "    greedy_reward=229.05\n",
      "    deterministic_reward=235.25\n",
      "    max_reward=237.14\n",
      "\n",
      "Training episode 32750    \n",
      "    reward=224.92\n",
      "\n",
      "Test run after episode 32750:\n",
      "    reward=225.35\n",
      "    greedy_reward=321.96\n",
      "    deterministic_reward=362.79\n",
      "    max_reward=395.37\n",
      "\n",
      "Training episode 32800    \n",
      "    reward=235.74\n",
      "\n",
      "Test run after episode 32800:\n",
      "    reward=201.98\n",
      "    greedy_reward=409.19\n",
      "    deterministic_reward=428.06\n",
      "    max_reward=434.18\n",
      "\n",
      "Training episode 32850    \n",
      "    reward=229.95\n",
      "\n",
      "Test run after episode 32850:\n",
      "    reward=182.50\n",
      "    greedy_reward=295.77\n",
      "    deterministic_reward=304.17\n",
      "    max_reward=312.22\n",
      "\n",
      "Training episode 32900    \n",
      "    reward=239.32\n",
      "\n",
      "Test run after episode 32900:\n",
      "    reward=177.11\n",
      "    greedy_reward=364.27\n",
      "    deterministic_reward=361.25\n",
      "    max_reward=470.55\n",
      "\n",
      "Training episode 32950    \n",
      "    reward=242.17\n",
      "\n",
      "Test run after episode 32950:\n",
      "    reward=177.64\n",
      "    greedy_reward=348.98\n",
      "    deterministic_reward=355.03\n",
      "    max_reward=360.32\n",
      "\n",
      "Training episode 33000    \n",
      "    reward=224.69\n",
      "\n",
      "Test run after episode 33000:\n",
      "    reward=309.59\n",
      "    greedy_reward=360.06\n",
      "    deterministic_reward=374.23\n",
      "    max_reward=389.11\n",
      "\n",
      "Training episode 33050    \n",
      "    reward=242.13\n",
      "\n",
      "Test run after episode 33050:\n",
      "    reward=261.03\n",
      "    greedy_reward=386.25\n",
      "    deterministic_reward=408.10\n",
      "    max_reward=441.06\n",
      "\n",
      "Training episode 33100    \n",
      "    reward=240.97\n",
      "\n",
      "Test run after episode 33100:\n",
      "    reward=217.99\n",
      "    greedy_reward=401.40\n",
      "    deterministic_reward=406.67\n",
      "    max_reward=430.66\n",
      "\n",
      "Training episode 33150    \n",
      "    reward=241.21\n",
      "\n",
      "Test run after episode 33150:\n",
      "    reward=222.02\n",
      "    greedy_reward=365.70\n",
      "    deterministic_reward=371.64\n",
      "    max_reward=402.56\n",
      "\n",
      "Training episode 33200    \n",
      "    reward=223.51\n",
      "\n",
      "Test run after episode 33200:\n",
      "    reward=211.24\n",
      "    greedy_reward=267.64\n",
      "    deterministic_reward=291.93\n",
      "    max_reward=298.77\n",
      "\n",
      "Training episode 33250    \n",
      "    reward=219.55\n",
      "\n",
      "Test run after episode 33250:\n",
      "    reward=248.45\n",
      "    greedy_reward=370.77\n",
      "    deterministic_reward=384.25\n",
      "    max_reward=448.30\n",
      "\n",
      "Training episode 33300    \n",
      "    reward=240.07\n",
      "\n",
      "Test run after episode 33300:\n",
      "    reward=259.00\n",
      "    greedy_reward=367.74\n",
      "    deterministic_reward=366.53\n",
      "    max_reward=398.83\n",
      "\n",
      "Training episode 33350    \n",
      "    reward=236.66\n",
      "\n",
      "Test run after episode 33350:\n",
      "    reward=252.14\n",
      "    greedy_reward=432.76\n",
      "    deterministic_reward=441.42\n",
      "    max_reward=495.48\n",
      "\n",
      "Training episode 33400    \n",
      "    reward=224.60\n",
      "\n",
      "Test run after episode 33400:\n",
      "    reward=252.83\n",
      "    greedy_reward=353.19\n",
      "    deterministic_reward=359.06\n",
      "    max_reward=469.99\n",
      "\n",
      "Training episode 33450    \n",
      "    reward=224.92\n",
      "\n",
      "Test run after episode 33450:\n",
      "    reward=239.98\n",
      "    greedy_reward=322.00\n",
      "    deterministic_reward=353.14\n",
      "    max_reward=363.07\n",
      "\n",
      "Training episode 33500    \n",
      "    reward=225.93\n",
      "\n",
      "Test run after episode 33500:\n",
      "    reward=240.38\n",
      "    greedy_reward=304.62\n",
      "    deterministic_reward=337.07\n",
      "    max_reward=371.89\n",
      "\n",
      "Training episode 33550    \n",
      "    reward=243.78\n",
      "\n",
      "Test run after episode 33550:\n",
      "    reward=208.26\n",
      "    greedy_reward=275.05\n",
      "    deterministic_reward=291.97\n",
      "    max_reward=310.52\n",
      "\n",
      "Training episode 33600    \n",
      "    reward=232.97\n",
      "\n",
      "Test run after episode 33600:\n",
      "    reward=351.33\n",
      "    greedy_reward=400.72\n",
      "    deterministic_reward=414.87\n",
      "    max_reward=485.30\n",
      "\n",
      "Training episode 33650    \n",
      "    reward=241.41\n",
      "\n",
      "Test run after episode 33650:\n",
      "    reward=301.68\n",
      "    greedy_reward=418.73\n",
      "    deterministic_reward=420.18\n",
      "    max_reward=526.27\n",
      "\n",
      "Training episode 33700    \n",
      "    reward=230.31\n",
      "\n",
      "Test run after episode 33700:\n",
      "    reward=222.28\n",
      "    greedy_reward=337.20\n",
      "    deterministic_reward=348.02\n",
      "    max_reward=366.67\n",
      "\n",
      "Training episode 33750    \n",
      "    reward=246.92\n",
      "\n",
      "Test run after episode 33750:\n",
      "    reward=190.29\n",
      "    greedy_reward=285.18\n",
      "    deterministic_reward=312.68\n",
      "    max_reward=321.25\n",
      "\n",
      "Training episode 33800    \n",
      "    reward=224.67\n",
      "\n",
      "Test run after episode 33800:\n",
      "    reward=226.19\n",
      "    greedy_reward=299.90\n",
      "    deterministic_reward=313.97\n",
      "    max_reward=332.15\n",
      "\n",
      "Training episode 33850    \n",
      "    reward=237.86\n",
      "\n",
      "Test run after episode 33850:\n",
      "    reward=168.62\n",
      "    greedy_reward=252.45\n",
      "    deterministic_reward=286.37\n",
      "    max_reward=302.53\n",
      "\n",
      "Training episode 33900    \n",
      "    reward=239.41\n",
      "\n",
      "Test run after episode 33900:\n",
      "    reward=278.72\n",
      "    greedy_reward=357.45\n",
      "    deterministic_reward=372.16\n",
      "    max_reward=414.05\n",
      "\n",
      "Training episode 33950    \n",
      "    reward=229.99\n",
      "\n",
      "Test run after episode 33950:\n",
      "    reward=347.78\n",
      "    greedy_reward=347.13\n",
      "    deterministic_reward=344.52\n",
      "    max_reward=517.60\n",
      "\n",
      "Training episode 34000    \n",
      "    reward=232.21\n",
      "\n",
      "Test run after episode 34000:\n",
      "    reward=294.02\n",
      "    greedy_reward=410.85\n",
      "    deterministic_reward=428.22\n",
      "    max_reward=493.55\n",
      "\n",
      "Training episode 34050    \n",
      "    reward=237.91\n",
      "\n",
      "Test run after episode 34050:\n",
      "    reward=191.67\n",
      "    greedy_reward=299.51\n",
      "    deterministic_reward=316.62\n",
      "    max_reward=343.50\n",
      "\n",
      "Training episode 34100    \n",
      "    reward=244.27\n",
      "\n",
      "Test run after episode 34100:\n",
      "    reward=203.15\n",
      "    greedy_reward=263.75\n",
      "    deterministic_reward=282.86\n",
      "    max_reward=292.06\n",
      "\n",
      "Training episode 34150    \n",
      "    reward=235.12\n",
      "\n",
      "Test run after episode 34150:\n",
      "    reward=217.47\n",
      "    greedy_reward=295.82\n",
      "    deterministic_reward=301.07\n",
      "    max_reward=302.76\n",
      "\n",
      "Training episode 34200    \n",
      "    reward=220.01\n",
      "\n",
      "Test run after episode 34200:\n",
      "    reward=276.19\n",
      "    greedy_reward=353.49\n",
      "    deterministic_reward=380.59\n",
      "    max_reward=394.24\n",
      "\n",
      "Training episode 34250    \n",
      "    reward=240.53\n",
      "\n",
      "Test run after episode 34250:\n",
      "    reward=164.09\n",
      "    greedy_reward=290.05\n",
      "    deterministic_reward=297.95\n",
      "    max_reward=306.67\n",
      "\n",
      "Training episode 34300    \n",
      "    reward=238.75\n",
      "\n",
      "Test run after episode 34300:\n",
      "    reward=201.70\n",
      "    greedy_reward=296.75\n",
      "    deterministic_reward=309.20\n",
      "    max_reward=324.58\n",
      "\n",
      "Training episode 34350    \n",
      "    reward=230.40\n",
      "\n",
      "Test run after episode 34350:\n",
      "    reward=197.16\n",
      "    greedy_reward=278.26\n",
      "    deterministic_reward=282.20\n",
      "    max_reward=295.82\n",
      "\n",
      "Training episode 34400    \n",
      "    reward=236.39\n",
      "\n",
      "Test run after episode 34400:\n",
      "    reward=190.21\n",
      "    greedy_reward=288.45\n",
      "    deterministic_reward=341.72\n",
      "    max_reward=351.94\n",
      "\n",
      "Training episode 34450    \n",
      "    reward=231.65\n",
      "\n",
      "Test run after episode 34450:\n",
      "    reward=197.97\n",
      "    greedy_reward=357.07\n",
      "    deterministic_reward=370.21\n",
      "    max_reward=375.31\n",
      "\n",
      "Training episode 34500    \n",
      "    reward=225.87\n",
      "\n",
      "Test run after episode 34500:\n",
      "    reward=226.53\n",
      "    greedy_reward=351.17\n",
      "    deterministic_reward=363.67\n",
      "    max_reward=407.53\n",
      "\n",
      "Training episode 34550    \n",
      "    reward=218.73\n",
      "\n",
      "Test run after episode 34550:\n",
      "    reward=287.98\n",
      "    greedy_reward=362.25\n",
      "    deterministic_reward=404.22\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 34600    \n",
      "    reward=238.75\n",
      "\n",
      "Test run after episode 34600:\n",
      "    reward=196.68\n",
      "    greedy_reward=248.69\n",
      "    deterministic_reward=263.87\n",
      "    max_reward=268.69\n",
      "\n",
      "Training episode 34650    \n",
      "    reward=236.73\n",
      "\n",
      "Test run after episode 34650:\n",
      "    reward=222.76\n",
      "    greedy_reward=381.67\n",
      "    deterministic_reward=399.32\n",
      "    max_reward=446.97\n",
      "\n",
      "Training episode 34700    \n",
      "    reward=225.87\n",
      "\n",
      "Test run after episode 34700:\n",
      "    reward=207.48\n",
      "    greedy_reward=338.45\n",
      "    deterministic_reward=362.03\n",
      "    max_reward=368.46\n",
      "\n",
      "Training episode 34750    \n",
      "    reward=254.76\n",
      "\n",
      "Test run after episode 34750:\n",
      "    reward=230.26\n",
      "    greedy_reward=315.09\n",
      "    deterministic_reward=338.55\n",
      "    max_reward=345.42\n",
      "\n",
      "Training episode 34800    \n",
      "    reward=230.91\n",
      "\n",
      "Test run after episode 34800:\n",
      "    reward=362.14\n",
      "    greedy_reward=391.41\n",
      "    deterministic_reward=449.52\n",
      "    max_reward=531.17\n",
      "\n",
      "Training episode 34850    \n",
      "    reward=228.37\n",
      "\n",
      "Test run after episode 34850:\n",
      "    reward=255.51\n",
      "    greedy_reward=302.90\n",
      "    deterministic_reward=334.49\n",
      "    max_reward=343.69\n",
      "\n",
      "Training episode 34900    \n",
      "    reward=246.64\n",
      "\n",
      "Test run after episode 34900:\n",
      "    reward=267.24\n",
      "    greedy_reward=303.27\n",
      "    deterministic_reward=310.60\n",
      "    max_reward=345.63\n",
      "\n",
      "Training episode 34950    \n",
      "    reward=237.93\n",
      "\n",
      "Test run after episode 34950:\n",
      "    reward=195.54\n",
      "    greedy_reward=297.19\n",
      "    deterministic_reward=314.47\n",
      "    max_reward=318.45\n",
      "\n",
      "Training episode 35000    \n",
      "    reward=237.34\n",
      "\n",
      "Test run after episode 35000:\n",
      "    reward=261.39\n",
      "    greedy_reward=308.91\n",
      "    deterministic_reward=322.99\n",
      "    max_reward=329.58\n",
      "\n",
      "Training episode 35050    \n",
      "    reward=251.65\n",
      "\n",
      "Test run after episode 35050:\n",
      "    reward=149.41\n",
      "    greedy_reward=218.03\n",
      "    deterministic_reward=231.86\n",
      "    max_reward=242.62\n",
      "\n",
      "Training episode 35100    \n",
      "    reward=237.96\n",
      "\n",
      "Test run after episode 35100:\n",
      "    reward=260.59\n",
      "    greedy_reward=387.12\n",
      "    deterministic_reward=400.84\n",
      "    max_reward=412.47\n",
      "\n",
      "Training episode 35150    \n",
      "    reward=241.81\n",
      "\n",
      "Test run after episode 35150:\n",
      "    reward=173.61\n",
      "    greedy_reward=294.37\n",
      "    deterministic_reward=308.72\n",
      "    max_reward=319.74\n",
      "\n",
      "Training episode 35200    \n",
      "    reward=237.25\n",
      "\n",
      "Test run after episode 35200:\n",
      "    reward=237.88\n",
      "    greedy_reward=388.88\n",
      "    deterministic_reward=404.19\n",
      "    max_reward=450.24\n",
      "\n",
      "Training episode 35250    \n",
      "    reward=238.01\n",
      "\n",
      "Test run after episode 35250:\n",
      "    reward=286.44\n",
      "    greedy_reward=359.57\n",
      "    deterministic_reward=374.39\n",
      "    max_reward=381.28\n",
      "\n",
      "Training episode 35300    \n",
      "    reward=238.50\n",
      "\n",
      "Test run after episode 35300:\n",
      "    reward=221.25\n",
      "    greedy_reward=289.40\n",
      "    deterministic_reward=304.60\n",
      "    max_reward=310.19\n",
      "\n",
      "Training episode 35350    \n",
      "    reward=217.68\n",
      "\n",
      "Test run after episode 35350:\n",
      "    reward=117.64\n",
      "    greedy_reward=209.46\n",
      "    deterministic_reward=214.15\n",
      "    max_reward=217.23\n",
      "\n",
      "Training episode 35400    \n",
      "    reward=224.91\n",
      "\n",
      "Test run after episode 35400:\n",
      "    reward=198.71\n",
      "    greedy_reward=289.10\n",
      "    deterministic_reward=316.02\n",
      "    max_reward=323.24\n",
      "\n",
      "Training episode 35450    \n",
      "    reward=235.88\n",
      "\n",
      "Test run after episode 35450:\n",
      "    reward=214.36\n",
      "    greedy_reward=256.65\n",
      "    deterministic_reward=268.31\n",
      "    max_reward=282.39\n",
      "\n",
      "Training episode 35500    \n",
      "    reward=232.31\n",
      "\n",
      "Test run after episode 35500:\n",
      "    reward=283.77\n",
      "    greedy_reward=368.00\n",
      "    deterministic_reward=370.67\n",
      "    max_reward=407.23\n",
      "\n",
      "Training episode 35550    \n",
      "    reward=218.24\n",
      "\n",
      "Test run after episode 35550:\n",
      "    reward=249.30\n",
      "    greedy_reward=384.29\n",
      "    deterministic_reward=392.90\n",
      "    max_reward=435.30\n",
      "\n",
      "Training episode 35600    \n",
      "    reward=228.00\n",
      "\n",
      "Test run after episode 35600:\n",
      "    reward=242.73\n",
      "    greedy_reward=339.44\n",
      "    deterministic_reward=361.46\n",
      "    max_reward=379.22\n",
      "\n",
      "Training episode 35650    \n",
      "    reward=240.76\n",
      "\n",
      "Test run after episode 35650:\n",
      "    reward=237.26\n",
      "    greedy_reward=291.75\n",
      "    deterministic_reward=329.48\n",
      "    max_reward=396.11\n",
      "\n",
      "Training episode 35700    \n",
      "    reward=222.63\n",
      "\n",
      "Test run after episode 35700:\n",
      "    reward=262.90\n",
      "    greedy_reward=321.85\n",
      "    deterministic_reward=357.52\n",
      "    max_reward=399.03\n",
      "\n",
      "Training episode 35750    \n",
      "    reward=244.16\n",
      "\n",
      "Test run after episode 35750:\n",
      "    reward=157.54\n",
      "    greedy_reward=328.15\n",
      "    deterministic_reward=335.58\n",
      "    max_reward=395.65\n",
      "\n",
      "Training episode 35800    \n",
      "    reward=229.49\n",
      "\n",
      "Test run after episode 35800:\n",
      "    reward=136.34\n",
      "    greedy_reward=300.99\n",
      "    deterministic_reward=332.69\n",
      "    max_reward=336.86\n",
      "\n",
      "Training episode 35850    \n",
      "    reward=238.03\n",
      "\n",
      "Test run after episode 35850:\n",
      "    reward=148.00\n",
      "    greedy_reward=224.34\n",
      "    deterministic_reward=230.48\n",
      "    max_reward=234.16\n",
      "\n",
      "Training episode 35900    \n",
      "    reward=231.96\n",
      "\n",
      "Test run after episode 35900:\n",
      "    reward=314.65\n",
      "    greedy_reward=344.63\n",
      "    deterministic_reward=346.38\n",
      "    max_reward=477.05\n",
      "\n",
      "Training episode 35950    \n",
      "    reward=224.63\n",
      "\n",
      "Test run after episode 35950:\n",
      "    reward=169.87\n",
      "    greedy_reward=221.81\n",
      "    deterministic_reward=238.10\n",
      "    max_reward=243.14\n",
      "\n",
      "Training episode 36000    \n",
      "    reward=235.09\n",
      "\n",
      "Test run after episode 36000:\n",
      "    reward=169.62\n",
      "    greedy_reward=288.54\n",
      "    deterministic_reward=302.05\n",
      "    max_reward=330.58\n",
      "\n",
      "Training episode 36050    \n",
      "    reward=218.86\n",
      "\n",
      "Test run after episode 36050:\n",
      "    reward=280.41\n",
      "    greedy_reward=304.34\n",
      "    deterministic_reward=350.50\n",
      "    max_reward=397.70\n",
      "\n",
      "Training episode 36100    \n",
      "    reward=223.96\n",
      "\n",
      "Test run after episode 36100:\n",
      "    reward=250.61\n",
      "    greedy_reward=278.00\n",
      "    deterministic_reward=288.39\n",
      "    max_reward=293.25\n",
      "\n",
      "Training episode 36150    \n",
      "    reward=242.52\n",
      "\n",
      "Test run after episode 36150:\n",
      "    reward=296.14\n",
      "    greedy_reward=392.74\n",
      "    deterministic_reward=391.87\n",
      "    max_reward=525.98\n",
      "\n",
      "Training episode 36200    \n",
      "    reward=238.45\n",
      "\n",
      "Test run after episode 36200:\n",
      "    reward=202.77\n",
      "    greedy_reward=241.79\n",
      "    deterministic_reward=268.57\n",
      "    max_reward=319.04\n",
      "\n",
      "Training episode 36250    \n",
      "    reward=230.05\n",
      "\n",
      "Test run after episode 36250:\n",
      "    reward=221.55\n",
      "    greedy_reward=279.86\n",
      "    deterministic_reward=299.02\n",
      "    max_reward=310.55\n",
      "\n",
      "Training episode 36300    \n",
      "    reward=234.86\n",
      "\n",
      "Test run after episode 36300:\n",
      "    reward=318.98\n",
      "    greedy_reward=397.58\n",
      "    deterministic_reward=407.87\n",
      "    max_reward=545.27\n",
      "\n",
      "Training episode 36350    \n",
      "    reward=239.20\n",
      "\n",
      "Test run after episode 36350:\n",
      "    reward=166.06\n",
      "    greedy_reward=270.10\n",
      "    deterministic_reward=277.56\n",
      "    max_reward=281.16\n",
      "\n",
      "Training episode 36400    \n",
      "    reward=236.78\n",
      "\n",
      "Test run after episode 36400:\n",
      "    reward=183.59\n",
      "    greedy_reward=257.55\n",
      "    deterministic_reward=271.53\n",
      "    max_reward=298.73\n",
      "\n",
      "Training episode 36450    \n",
      "    reward=231.45\n",
      "\n",
      "Test run after episode 36450:\n",
      "    reward=140.46\n",
      "    greedy_reward=222.07\n",
      "    deterministic_reward=230.22\n",
      "    max_reward=232.93\n",
      "\n",
      "Training episode 36500    \n",
      "    reward=229.69\n",
      "\n",
      "Test run after episode 36500:\n",
      "    reward=232.80\n",
      "    greedy_reward=286.64\n",
      "    deterministic_reward=301.15\n",
      "    max_reward=306.11\n",
      "\n",
      "Training episode 36550    \n",
      "    reward=227.23\n",
      "\n",
      "Test run after episode 36550:\n",
      "    reward=164.25\n",
      "    greedy_reward=341.24\n",
      "    deterministic_reward=351.91\n",
      "    max_reward=410.51\n",
      "\n",
      "Training episode 36600    \n",
      "    reward=217.04\n",
      "\n",
      "Test run after episode 36600:\n",
      "    reward=251.41\n",
      "    greedy_reward=356.28\n",
      "    deterministic_reward=374.35\n",
      "    max_reward=385.17\n",
      "\n",
      "Training episode 36650    \n",
      "    reward=231.22\n",
      "\n",
      "Test run after episode 36650:\n",
      "    reward=216.90\n",
      "    greedy_reward=280.51\n",
      "    deterministic_reward=312.88\n",
      "    max_reward=319.40\n",
      "\n",
      "Training episode 36700    \n",
      "    reward=237.26\n",
      "\n",
      "Test run after episode 36700:\n",
      "    reward=199.78\n",
      "    greedy_reward=310.52\n",
      "    deterministic_reward=320.29\n",
      "    max_reward=329.77\n",
      "\n",
      "Training episode 36750    \n",
      "    reward=242.03\n",
      "\n",
      "Test run after episode 36750:\n",
      "    reward=266.51\n",
      "    greedy_reward=392.02\n",
      "    deterministic_reward=402.85\n",
      "    max_reward=432.89\n",
      "\n",
      "Training episode 36800    \n",
      "    reward=235.58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_bare_reward</td><td></td></tr><tr><td>test_deterministic_reward</td><td></td></tr><tr><td>test_env_time</td><td></td></tr><tr><td>test_greedy_reward</td><td></td></tr><tr><td>test_length</td><td></td></tr><tr><td>test_max_reward</td><td></td></tr><tr><td>test_reward</td><td></td></tr><tr><td>test_sampling_time</td><td></td></tr><tr><td>test_total_evs_social_welfare</td><td></td></tr><tr><td>test_total_feeders_power_price</td><td></td></tr><tr><td>test_total_i</td><td></td></tr><tr><td>test_total_i_constraints_violation</td><td></td></tr><tr><td>test_total_loads_social_welfare</td><td></td></tr><tr><td>test_total_max_i</td><td></td></tr><tr><td>test_total_power</td><td></td></tr><tr><td>test_total_power_flow_constraints_violation</td><td></td></tr><tr><td>test_total_pvs_power_price</td><td></td></tr><tr><td>test_total_requested_max_power</td><td></td></tr><tr><td>test_total_requested_min_power</td><td></td></tr><tr><td>test_total_target_power</td><td></td></tr><tr><td>test_training_time</td><td></td></tr><tr><td>train_bare_reward</td><td></td></tr><tr><td>train_env_time</td><td></td></tr><tr><td>train_length</td><td></td></tr><tr><td>train_reward</td><td></td></tr><tr><td>train_sampling_time</td><td></td></tr><tr><td>train_total_evs_social_welfare</td><td></td></tr><tr><td>train_total_feeders_power_price</td><td></td></tr><tr><td>train_total_i</td><td></td></tr><tr><td>train_total_i_constraints_violation</td><td></td></tr><tr><td>train_total_loads_social_welfare</td><td></td></tr><tr><td>train_total_max_i</td><td></td></tr><tr><td>train_total_power</td><td></td></tr><tr><td>train_total_power_flow_constraints_violation</td><td></td></tr><tr><td>train_total_pvs_power_price</td><td></td></tr><tr><td>train_total_requested_max_power</td><td></td></tr><tr><td>train_total_requested_min_power</td><td></td></tr><tr><td>train_total_target_power</td><td></td></tr><tr><td>train_training_time</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>36800</td></tr><tr><td>test_bare_reward</td><td>266.51323</td></tr><tr><td>test_deterministic_reward</td><td>402.84852</td></tr><tr><td>test_env_time</td><td>0.20649</td></tr><tr><td>test_greedy_reward</td><td>392.01895</td></tr><tr><td>test_length</td><td>47.0</td></tr><tr><td>test_max_reward</td><td>432.89248</td></tr><tr><td>test_reward</td><td>266.51323</td></tr><tr><td>test_sampling_time</td><td>0.0</td></tr><tr><td>test_total_evs_social_welfare</td><td>266.73373</td></tr><tr><td>test_total_feeders_power_price</td><td>-0.22051</td></tr><tr><td>test_total_i</td><td>259954.19145</td></tr><tr><td>test_total_i_constraints_violation</td><td>243678.65791</td></tr><tr><td>test_total_loads_social_welfare</td><td>0.0</td></tr><tr><td>test_total_max_i</td><td>25850.0</td></tr><tr><td>test_total_power</td><td>640.87817</td></tr><tr><td>test_total_power_flow_constraints_violation</td><td>182014.07823</td></tr><tr><td>test_total_pvs_power_price</td><td>0.0</td></tr><tr><td>test_total_requested_max_power</td><td>-968.83698</td></tr><tr><td>test_total_requested_min_power</td><td>968.83698</td></tr><tr><td>test_total_target_power</td><td>181947.59626</td></tr><tr><td>test_training_time</td><td>0.0</td></tr><tr><td>train_bare_reward</td><td>128.7349</td></tr><tr><td>train_env_time</td><td>0.1686</td></tr><tr><td>train_length</td><td>47</td></tr><tr><td>train_reward</td><td>128.7349</td></tr><tr><td>train_sampling_time</td><td>0.0258</td></tr><tr><td>train_total_evs_social_welfare</td><td>129.39143</td></tr><tr><td>train_total_feeders_power_price</td><td>-0.65654</td></tr><tr><td>train_total_i</td><td>254494.51168</td></tr><tr><td>train_total_i_constraints_violation</td><td>234209.72091</td></tr><tr><td>train_total_loads_social_welfare</td><td>0</td></tr><tr><td>train_total_max_i</td><td>25850.0</td></tr><tr><td>train_total_power</td><td>341.86034</td></tr><tr><td>train_total_power_flow_constraints_violation</td><td>175562.09828</td></tr><tr><td>train_total_pvs_power_price</td><td>0.0</td></tr><tr><td>train_total_requested_max_power</td><td>-793.45363</td></tr><tr><td>train_total_requested_min_power</td><td>793.45363</td></tr><tr><td>train_total_target_power</td><td>175515.10736</td></tr><tr><td>train_training_time</td><td>0.11484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-hill-155</strong>: <a href=\"https://wandb.ai/electric-vehicle-charging/electric-vehicle-charging-rl/runs/2c1qeiul\" target=\"_blank\">https://wandb.ai/electric-vehicle-charging/electric-vehicle-charging-rl/runs/2c1qeiul</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220603_034202-2c1qeiul/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/fransdeboer/Projects/RL-EVCP/Run TD3 gym.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000018?line=1'>2</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m) \u001b[39m# make the\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000018?line=3'>4</a>\u001b[0m train()\n",
      "\u001b[1;32m/Users/fransdeboer/Projects/RL-EVCP/Run TD3 gym.ipynb Cell 19'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000017?line=46'>47</a>\u001b[0m current_test_results \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000017?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m test_ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_test_episodes):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000017?line=49'>50</a>\u001b[0m     episode_results \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mrun(train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_to_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000017?line=51'>52</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m episode_results\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fransdeboer/Projects/RL-EVCP/Run%20TD3%20gym.ipynb#ch0000017?line=52'>53</a>\u001b[0m         current_test_results[key]\u001b[39m.\u001b[39mappend(val)\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/src/td3_code/runners/runner.py:149\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, train, save_to_memory, train_bath_size, final)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=146'>147</a>\u001b[0m reshaped_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mn_devices)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=147'>148</a>\u001b[0m p_lbs_t, p_ubs_t, v_lbs_t, v_ubs_t, u_t \u001b[39m=\u001b[39m reshaped_state[\u001b[39m0\u001b[39m], reshaped_state[\u001b[39m1\u001b[39m], reshaped_state[\u001b[39m2\u001b[39m], reshaped_state[\u001b[39m3\u001b[39m], reshaped_state[\u001b[39m4\u001b[39m]\n\u001b[0;32m--> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=148'>149</a>\u001b[0m p, v, model \u001b[39m=\u001b[39m compute_greedy_heuristic(u_t, p_lbs_t, p_ubs_t, v_lbs_t, v_ubs_t, \n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=149'>150</a>\u001b[0m                                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mconductance_matrix, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mi_max_matrix, \n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=150'>151</a>\u001b[0m                                     lossless\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, tee\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=151'>152</a>\u001b[0m action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((p,v), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/td3_code/runners/runner.py?line=152'>153</a>\u001b[0m _, _, _, result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/src/optimization/heuristic_greedy.py:31\u001b[0m, in \u001b[0;36mcompute_greedy_heuristic\u001b[0;34m(u_t, p_lbs_t, p_ubs_t, v_lbs_t, v_ubs_t, conductance_matrix, i_max_matrix, lossless, tee)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/optimization/heuristic_greedy.py?line=28'>29</a>\u001b[0m             i_line \u001b[39m=\u001b[39m conductance_matrix[i, j] \u001b[39m*\u001b[39m (model\u001b[39m.\u001b[39mv[i] \u001b[39m-\u001b[39m model\u001b[39m.\u001b[39mv[j])\n\u001b[1;32m     <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/optimization/heuristic_greedy.py?line=29'>30</a>\u001b[0m             i_line_max \u001b[39m=\u001b[39m i_max_matrix[i, j]\n\u001b[0;32m---> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/optimization/heuristic_greedy.py?line=30'>31</a>\u001b[0m             model\u001b[39m.\u001b[39;49mline_constraints\u001b[39m.\u001b[39;49madd(inequality(\u001b[39m-\u001b[39;49mi_line_max, i_line, i_line_max))\n\u001b[1;32m     <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/optimization/heuristic_greedy.py?line=31'>32</a>\u001b[0m \u001b[39m# Objective\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/fransdeboer/Projects/RL-EVCP/src/optimization/heuristic_greedy.py?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39mper_device_utility \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py:1029\u001b[0m, in \u001b[0;36mConstraintList.add\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=1026'>1027</a>\u001b[0m next_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_set) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_starting_index\n\u001b[1;32m   <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=1027'>1028</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_set\u001b[39m.\u001b[39madd(next_idx)\n\u001b[0;32m-> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=1028'>1029</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setitem__\u001b[39;49m(next_idx, expr)\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py:626\u001b[0m, in \u001b[0;36mIndexedComponent.__setitem__\u001b[0;34m(self, index, val)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=623'>624</a>\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mget(index, _NotFound)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=624'>625</a>\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m _NotFound:\n\u001b[0;32m--> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=625'>626</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_when_not_present(index, val)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=626'>627</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=627'>628</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_impl(index, obj, val)\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py:1000\u001b[0m, in \u001b[0;36mIndexedComponent._setitem_when_not_present\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=997'>998</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=998'>999</a>\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _NotSpecified:\n\u001b[0;32m-> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=999'>1000</a>\u001b[0m         obj\u001b[39m.\u001b[39;49mset_value(value)\n\u001b[1;32m   <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=1000'>1001</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py?line=1001'>1002</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mpop(index, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py:551\u001b[0m, in \u001b[0;36m_GeneralConstraintData.set_value\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=546'>547</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=547'>548</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=548'>549</a>\u001b[0m \u001b[39m# Normalize the incoming expressions, if we can\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=549'>550</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=550'>551</a>\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expr\u001b[39m.\u001b[39;49margs\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=551'>552</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expr\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39mis\u001b[39;00m logical_expr\u001b[39m.\u001b[39mInequalityExpression:\n\u001b[1;32m    <a href='file:///Users/fransdeboer/Projects/RL-EVCP/venv/lib/python3.9/site-packages/pyomo/core/base/constraint.py?line=552'>553</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expr\u001b[39m.\u001b[39mstrict:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning) # make the\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run a wandb parameter sweep to find the best performing hyperparpameters\n",
    "\n",
    "see https://docs.wandb.ai/guides/sweeps/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\" : \"my-test-sweep\",\n",
    "  \"method\" : \"bayes\",\n",
    "  \"metric\" : {\n",
    "      \"name\" : \"test_reward\",\n",
    "      \"goal\" : \"maximize\"\n",
    "  },\n",
    "  \"parameters\" : {\n",
    "    \"nlp_width\" : {\n",
    "        \"min\" : 5,\n",
    "        \"max\" : 9,\n",
    "    },\n",
    "    \"nlp_length\" : {\n",
    "        \"min\" : 2,\n",
    "        \"max\" : 6,\n",
    "    },\n",
    "    \"lstm_width\" : {\n",
    "        \"min\" : 2,\n",
    "        \"max\" : 7,\n",
    "    },\n",
    "    \"lstm_length\" : {\n",
    "        \"min\" : 0,\n",
    "        \"max\" : 5,\n",
    "    },\n",
    "    \"policy_update_freq\" : {\n",
    "        \"values\" : [1, 2, 3, 4]\n",
    "    },\n",
    "    \"actor_lr\" : {\n",
    "        \"min\" : 8e-6,\n",
    "        \"max\" : 8e-4,\n",
    "    },\n",
    "    \"critic_lr\" : {\n",
    "        \"min\" : 8e-6,\n",
    "        \"max\" : 8e-4,\n",
    "    },\n",
    "    \"discount\" : {\n",
    "        \"min\" : 0.9,\n",
    "        \"max\" : 0.999,\n",
    "    },\n",
    "    \"tau\" : {\n",
    "        \"min\" : 0.001,\n",
    "        \"max\" : 0.01,\n",
    "    },\n",
    "    \"policy_noise\": {\n",
    "        \"min\" : 0.04,\n",
    "        \"max\" : 0.5,\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "manual_id = \"dm3gga2x\"\n",
    "\n",
    "count = 1 # number of runs to execute\n",
    "wandb.agent(manual_id, function=train, count=count, project=\"electric-vehicle-charging-rl\", entity=\"electric-vehicle-charging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89dffcf",
   "metadata": {},
   "source": [
    "## Plot results locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_results['reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1eec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_results, final_results_list = runner.run(train=False, save_to_memory=False, final=True)\n",
    "\n",
    "print('Reward = %.2f' % episode_results['reward'])\n",
    "plot_results(env, final_results_list, figsize=(12, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428de757",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"constraints_violation\" : wandb.plot.line_series(\n",
    "          xs=list(range(len(env.timesteps_str[:-1]))),\n",
    "          ys=[[res['i_constraints_violation'] for res in final_results_list],\n",
    "          [res['power_flow_constraints_violation'] for res in final_results_list]],\n",
    "          keys=[\"I violation\", \"P violation\"],\n",
    "          title=\"Constraint violations\",\n",
    "          xname=\"Time\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [res['reward'] for res in final_results_list]\n",
    "feeders_price = [res['feeders_power_price'] for res in final_results_list]\n",
    "pvs_price = [res['pvs_power_price'] for res in final_results_list]\n",
    "evs_welfare = [res['evs_social_welfare'] for res in final_results_list]\n",
    "\n",
    "wandb.log({\"objective\" : wandb.plot.line_series(\n",
    "          xs=list(range(len(env.timesteps_str[:-1]))),\n",
    "          ys=[rewards, feeders_price, pvs_price, evs_welfare],\n",
    "          keys=[\"Total reward\", \"Feeders price\", \"PVs price\", \"EVs welfare\"],\n",
    "          title=\"Objective\",\n",
    "          xname=\"Time\")})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad96f5e9cd6d467318bf15c6be1d9bcdfbc0d0800f27162604e062abc89e5b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
