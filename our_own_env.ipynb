{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import gym, ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune import register_env\n",
    "\n",
    "from src.environments.create_env import create_env\n",
    "from src.environments.gym_power_voltage_env import GymPowerVoltageEnv\n",
    "from src.samplers.load_samplers import load_samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'path_to_data':   'data/',\n",
    "          't0_hr': 6.,  # When the episode start (default value 6AM)\n",
    "          'dt_min': 30,  # Timestep size\n",
    "          'ev_dt_min': 60,  # Timestep size for EV arrivals\n",
    "          'ev_sampling_dt_min': 60,  # How EV sessions are sampled from the data\n",
    "          'apply_gaussian_noise': False,  # Make data noisy\n",
    "          'ev_utility_coef_mean': 1,  # Mean value of the utility coefficient for the EVs\n",
    "          'ev_utility_coef_scale': 0.13,  # STD of the utility coefficient for the EVs\n",
    "          'days_per_month_train': 20,  # Days per month for training\n",
    "          'ev_session_months_train': ['01', '02', '03', '04', '06', '07', '08', '09', '10', '11', ],\n",
    "          # Months to sample EV sessions for training\n",
    "          'grid_to_use': 'ieee16',  # What grid topology to use. Now supports only IEEE16.\n",
    "          'ev_session_months_test': ['05', '12'],  # Months to sample EV sessions for test\n",
    "          'n_ps_pvs': 4,  # Amount of solar panels that use PecanStreet data\n",
    "          'n_canopy_pvs': 0,  # Amount of solar panels that use canopy data\n",
    "          'canopy_pv_rated_power': 250,  # Rated power of these panels\n",
    "          'n_loads': 0,  # Amount of inflexible loads\n",
    "          'n_feeders': 1,  # Amount of feeders\n",
    "          'n_ev_chargers': 4,  # Amount of EV chargers\n",
    "\n",
    "          'ps_pvs_rated_power': 4,  # Rated power of these panels\n",
    "          'avg_evs_per_day': 3.5,  # Scaling of the EV arrival rate\n",
    "          'feeder_p_min': -5,  # Capacity of the feeders\n",
    "          'g': 4,  # Conductance of each line\n",
    "          'i_max': 25,  # Capacity of each line\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(a):\n",
    "    # Preload samplers, it is necessary to avoid re-loading data each time env is created\n",
    "    (ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    "     price_sampler, price_metadata, ev_sampler, elaadnl_metadata) = load_samplers(config)\n",
    "\n",
    "    return create_env(\n",
    "        config,\n",
    "        ps_samplers_dict,\n",
    "        ps_metadata,\n",
    "        canopy_sampler,\n",
    "        canopy_metadata,\n",
    "        price_sampler,\n",
    "        price_metadata,\n",
    "        ev_sampler,\n",
    "        elaadnl_metadata\n",
    "    )  # return an env instance\n",
    "\n",
    "\n",
    "# Read this on how to run our own environments\n",
    "# https://docs.ray.io/en/latest/rllib/rllib-env.html\n",
    "\n",
    "ray.init()\n",
    "register_env(\"my_env\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    \"DDPG\",\n",
    "\n",
    "    # Stopping condition\n",
    "    stop={\"episode_reward_mean\":200},\n",
    "\n",
    "    # Config\n",
    "    # The default DDPG specific config is used with required \n",
    "    # Options for the config are in the default DDPG config: \n",
    "    # https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ddpg\n",
    "    config={\n",
    "        \"env\": \"my_env\",\n",
    "        \"framework\": \"torch\",\n",
    "        \"num_gpus\":0,\n",
    "        \"num_workers\":1,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = ppo.PPOTrainer(env=\"my_env\", config={\n",
    "#     \"env_config\": config,  # config to pass to env class\n",
    "#     \"framework\": \"torch\",\n",
    "# })\n",
    "\n",
    "# while True:\n",
    "#     print(trainer.train())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
