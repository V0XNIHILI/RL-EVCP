{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import gym, ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents import ppo, ddpg\n",
    "from ray.tune import register_env\n",
    "\n",
    "from src.environments.create_env import create_env\n",
    "from src.environments.gym_power_voltage_env import GymPowerVoltageEnv\n",
    "from src.samplers.load_samplers import load_samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'path_to_data':   'data/',\n",
    "          't0_hr': 6.,  # When the episode start (default value 6AM)\n",
    "          'dt_min': 30,  # Timestep size\n",
    "          'ev_dt_min': 60,  # Timestep size for EV arrivals\n",
    "          'ev_sampling_dt_min': 60,  # How EV sessions are sampled from the data\n",
    "          'apply_gaussian_noise': False,  # Make data noisy\n",
    "          'ev_utility_coef_mean': 1,  # Mean value of the utility coefficient for the EVs\n",
    "          'ev_utility_coef_scale': 0.13,  # STD of the utility coefficient for the EVs\n",
    "          'days_per_month_train': 20,  # Days per month for training\n",
    "          'ev_session_months_train': ['01', '02', '03', '04', '06', '07', '08', '09', '10', '11', ],\n",
    "          # Months to sample EV sessions for training\n",
    "          'grid_to_use': 'ieee16',  # What grid topology to use. Now supports only IEEE16.\n",
    "          'ev_session_months_test': ['05', '12'],  # Months to sample EV sessions for test\n",
    "          'n_ps_pvs': 4,  # Amount of solar panels that use PecanStreet data\n",
    "          'n_canopy_pvs': 0,  # Amount of solar panels that use canopy data\n",
    "          'canopy_pv_rated_power': 250,  # Rated power of these panels\n",
    "          'n_loads': 0,  # Amount of inflexible loads\n",
    "          'n_feeders': 1,  # Amount of feeders\n",
    "          'n_ev_chargers': 4,  # Amount of EV chargers\n",
    "\n",
    "          'ps_pvs_rated_power': 4,  # Rated power of these panels\n",
    "          'avg_evs_per_day': 3.5,  # Scaling of the EV arrival rate\n",
    "          'feeder_p_min': -5,  # Capacity of the feeders\n",
    "          'g': 4,  # Conductance of each line\n",
    "          'i_max': 25,  # Capacity of each line\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(a):\n",
    "    # Preload samplers, it is necessary to avoid re-loading data each time env is created\n",
    "    (ps_samplers_dict, ps_metadata, canopy_sampler, canopy_metadata,\n",
    "     price_sampler, price_metadata, ev_sampler, elaadnl_metadata) = load_samplers(config)\n",
    "\n",
    "    return create_env(\n",
    "        config,\n",
    "        ps_samplers_dict,\n",
    "        ps_metadata,\n",
    "        canopy_sampler,\n",
    "        canopy_metadata,\n",
    "        price_sampler,\n",
    "        price_metadata,\n",
    "        ev_sampler,\n",
    "        elaadnl_metadata\n",
    "    )  # return an env instance\n",
    "\n",
    "\n",
    "# Read this on how to run our own environments\n",
    "# https://docs.ray.io/en/latest/rllib/rllib-env.html\n",
    "\n",
    "ray.init()\n",
    "register_env(\"my_env\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 19:51:03,175\tINFO simple_q.py:161 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "2022-05-16 19:51:03,178\tINFO trainer.py:864 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=5928)\u001b[0m {'path_to_data': 'data/', 't0_hr': 6.0, 'dt_min': 30, 'ev_dt_min': 60, 'ev_sampling_dt_min': 60, 'apply_gaussian_noise': False, 'ev_utility_coef_mean': 1, 'ev_utility_coef_scale': 0.13, 'days_per_month_train': 20, 'ev_session_months_train': ['01', '02', '03', '04', '06', '07', '08', '09', '10', '11'], 'grid_to_use': 'ieee16', 'ev_session_months_test': ['05', '12'], 'n_ps_pvs': 4, 'n_canopy_pvs': 0, 'canopy_pv_rated_power': 250, 'n_loads': 0, 'n_feeders': 1, 'n_ev_chargers': 4, 'ps_pvs_rated_power': 4, 'avg_evs_per_day': 3.5, 'feeder_p_min': -5, 'g': 4, 'i_max': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=5928)\u001b[0m 2022-05-16 19:53:41,389\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=5928)\u001b[0m 2022-05-16 19:53:41,389\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "/Users/fransdeboer/.pyenv/versions/3.9.6/lib/python3.9/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.from_numpy(self.action_space.low).float()\n",
      "2022-05-16 19:53:41,624\tINFO trainable.py:152 -- Trainable.setup took 158.455 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-05-16 19:53:41,626\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': 451.1024208964704,\n",
       " 'episode_reward_min': 140.17882372613917,\n",
       " 'episode_reward_mean': 299.4716468125054,\n",
       " 'episode_len_mean': 47.0,\n",
       " 'episode_media': {},\n",
       " 'episodes_this_iter': 31,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [434.62222078957916,\n",
       "   344.64107935347465,\n",
       "   404.55860787608924,\n",
       "   451.1024208964704,\n",
       "   232.61883043846652,\n",
       "   330.28486646341975,\n",
       "   349.8367106543632,\n",
       "   297.51965905303155,\n",
       "   263.71013849729894,\n",
       "   287.5411051444022,\n",
       "   302.7718862200873,\n",
       "   399.50292471997136,\n",
       "   339.32341093025195,\n",
       "   319.8965938093133,\n",
       "   279.26307283532,\n",
       "   272.0093919674605,\n",
       "   224.60744414973527,\n",
       "   247.29895706889977,\n",
       "   379.10225512802987,\n",
       "   305.25093242293445,\n",
       "   192.7317190537429,\n",
       "   353.1363935910019,\n",
       "   263.22432648117405,\n",
       "   246.30434060199119,\n",
       "   372.5339313909495,\n",
       "   307.82443542966735,\n",
       "   285.9229746659906,\n",
       "   213.26370113366164,\n",
       "   140.17882372613917,\n",
       "   276.9457553816766,\n",
       "   166.09214131307198],\n",
       "  'episode_lengths': [47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47]},\n",
       " 'sampler_perf': {'mean_raw_obs_processing_ms': 2.65331954498596,\n",
       "  'mean_inference_ms': 1.1354240872397725,\n",
       "  'mean_action_processing_ms': 0.13840540022471998,\n",
       "  'mean_env_wait_ms': 1.34282299552577,\n",
       "  'mean_env_render_ms': 0.0},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 1,\n",
       " 'timesteps_total': 1500,\n",
       " 'timesteps_this_iter': 256,\n",
       " 'agent_timesteps_total': 1500,\n",
       " 'timers': {'load_time_ms': 0.174,\n",
       "  'load_throughput': 1472896.878,\n",
       "  'learn_time_ms': 37.246,\n",
       "  'learn_throughput': 6873.223,\n",
       "  'update_time_ms': 1.427},\n",
       " 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0,\n",
       "     'actor_loss': 224.8135986328125,\n",
       "     'critic_loss': 892.3441772460938,\n",
       "     'mean_q': -211.985595703125,\n",
       "     'max_q': -190.35049438476562,\n",
       "     'min_q': -226.13677978515625},\n",
       "    'td_error': array([-1.90850983e+01, -4.47488403e+00,  1.81069794e+01, -7.34100342e+00,\n",
       "            1.02880096e+01,  9.52168274e+00, -6.48118591e+00, -2.89187622e+00,\n",
       "            9.21572876e+00,  1.57005310e+01,  5.74023438e+00, -9.15296936e+00,\n",
       "           -5.40943909e+00,  8.45994568e+00, -2.31281281e+01,  1.48376312e+01,\n",
       "            1.59554291e+01,  1.70325775e+01, -2.05130264e+02, -7.24923706e+00,\n",
       "           -1.03636627e+01,  2.18016510e+01,  1.15225525e+01, -1.23893127e+01,\n",
       "           -1.71798706e+00,  1.49001465e+01, -7.91316223e+00,  1.38153076e+00,\n",
       "            1.90176544e+01,  7.16485596e+00,  7.11282349e+00,  8.41661072e+00,\n",
       "            1.34143829e+01, -2.22312927e+00,  2.71783447e+00,  2.41965027e+01,\n",
       "           -1.56683350e+00, -2.23201553e+02, -6.58470154e+00,  9.50827026e+00,\n",
       "           -2.24929810e+00,  1.72264252e+01,  1.18897858e+01,  1.31901855e+01,\n",
       "            2.76041107e+01,  1.80945282e+01,  7.84042358e-01, -9.95101929e+00,\n",
       "           -1.16635284e+01,  3.43122864e+00, -1.76086426e+01, -2.06193542e+00,\n",
       "            2.49469452e+01,  1.19495850e+01,  5.19213867e+00, -1.59815826e+01,\n",
       "            2.11419525e+01, -7.04083252e+00, -1.07684784e+01,  9.30374146e+00,\n",
       "           -1.37436218e+01, -4.47311401e+00, -1.51666107e+01, -1.01239014e+00,\n",
       "            1.32119751e+01,  1.66854401e+01,  7.76045227e+00, -1.88044739e+00,\n",
       "            1.68059998e+01,  2.73266907e+01, -7.61189270e+00, -5.04724121e+00,\n",
       "           -7.56632996e+00,  2.62335205e+00, -1.01239014e+00,  2.53665314e+01,\n",
       "           -1.51666107e+01, -5.61662292e+00, -4.94764709e+00, -1.59422302e+00,\n",
       "           -8.51658630e+00,  1.92245483e-01,  1.74305878e+01, -1.73395081e+01,\n",
       "           -2.45741272e+00, -6.04756165e+00,  5.54792786e+00,  1.12387238e+01,\n",
       "            1.72391663e+01, -8.12924194e+00,  1.34767609e+01,  5.84788513e+00,\n",
       "           -1.09252319e+01,  4.02027893e+00,  1.69139099e+01,  1.57955933e+01,\n",
       "           -2.21864319e+00,  1.96607056e+01, -7.29034424e+00, -6.72610474e+00,\n",
       "            3.98306274e+00,  1.05193787e+01, -2.23615448e+02, -5.93525696e+00,\n",
       "           -1.63144531e+01, -4.69952393e+00,  1.13959656e+01, -5.23588562e+00,\n",
       "           -1.03458557e+01,  1.90177155e+01, -6.83689880e+00,  1.49338226e+01,\n",
       "            1.30006104e+01,  7.19570923e+00, -1.30841522e+01,  2.71783447e+00,\n",
       "           -1.69744873e+00,  1.56374054e+01, -1.55718384e+01, -1.20565643e+01,\n",
       "           -1.76731873e+00, -5.66253662e-02, -2.30232697e+01,  1.47343750e+01,\n",
       "            2.62335205e+00,  1.15225525e+01, -9.90777588e+00,  2.23990784e+01,\n",
       "           -2.07287598e+00, -2.23621429e+02,  1.34143829e+01,  9.52168274e+00,\n",
       "            7.96382141e+00,  1.83489990e+01,  3.61364746e+00,  4.01252747e+00,\n",
       "            7.95219421e+00,  6.74247742e+00,  1.96146240e+01, -6.25007629e+00,\n",
       "            1.80390930e+01, -2.65303040e+00, -1.81391907e+00,  5.56971741e+00,\n",
       "            1.40210876e+01,  1.57005310e+01,  1.30463867e+01, -4.47488403e+00,\n",
       "            7.98645020e+00, -1.36060181e+01, -7.77027893e+00, -1.06593781e+01,\n",
       "           -1.32376099e+00,  4.13793945e+00, -1.49113464e+00, -8.89068604e-01,\n",
       "           -1.82028809e+01,  9.21572876e+00,  7.84042358e-01,  1.59843750e+01,\n",
       "           -1.11397552e+01,  1.88775635e+01, -1.63194275e+00, -1.05411377e+01,\n",
       "           -6.64567566e+00, -7.33044434e+00, -7.47343445e+00,  1.30787811e+01,\n",
       "            1.93488312e+01,  1.69584656e+00, -1.28269653e+01, -1.08264465e+01,\n",
       "            5.61215210e+00, -3.46376038e+00,  1.07566681e+01, -2.75971985e+00,\n",
       "            1.20800323e+01,  1.33334961e+01,  5.52992249e+00,  1.09336853e+01,\n",
       "            1.88775635e+01, -8.23437500e+00,  4.81736755e+00,  2.13865662e+01,\n",
       "            2.62335205e+00, -1.93269958e+01, -1.85218811e+00,  5.95800781e+00,\n",
       "           -1.77212524e+00, -6.05314636e+00, -2.61288605e+01,  6.49465942e+00,\n",
       "           -6.22969055e+00,  2.84592285e+01, -1.17769470e+01,  1.60802155e+01,\n",
       "            1.68754578e+01,  2.91688690e+01,  7.91911316e+00,  1.69584656e+00,\n",
       "           -4.54623413e+00,  7.49600220e+00, -1.71798706e+00,  7.04345703e-01,\n",
       "            9.78872681e+00,  2.88096619e+00, -5.71087646e+00,  1.80080414e+01,\n",
       "           -2.23823349e+02,  2.92100830e+01,  1.15438843e+00,  9.88821411e+00,\n",
       "            1.28864136e+01,  1.21572876e+01,  1.72391663e+01,  1.74182587e+01,\n",
       "           -1.00495911e+00,  6.82386780e+00, -6.80482483e+00,  1.83460388e+01,\n",
       "           -1.02274017e+01, -1.04126892e+01,  4.45353699e+00, -1.02322388e+00,\n",
       "            1.16438446e+01,  7.58338928e+00, -2.23615448e+02, -1.47223206e+01,\n",
       "           -2.35238647e+00,  6.65156555e+00, -1.94430573e+02, -1.63686676e+01,\n",
       "           -1.38807220e+01, -4.79907227e+00, -1.99818893e+02, -2.20950317e+00,\n",
       "           -9.15296936e+00, -2.23615448e+02,  4.77299500e+00, -1.31083832e+01,\n",
       "            1.92006683e+01,  1.04409485e+01,  2.09826508e+01,  1.02335968e+01,\n",
       "           -7.55934143e+00,  1.92669525e+01,  2.08562469e+01,  1.19076538e+01,\n",
       "            1.16888733e+01, -9.15296936e+00, -7.22402954e+00,  1.52402344e+01,\n",
       "           -5.71087646e+00,  2.86205139e+01,  1.39128265e+01, -7.86111450e+00],\n",
       "          dtype=float32),\n",
       "    'mean_td_error': -4.467343330383301,\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': 256.0}},\n",
       "  'num_steps_sampled': 1500,\n",
       "  'num_agent_steps_sampled': 1500,\n",
       "  'num_steps_trained': 256,\n",
       "  'num_steps_trained_this_iter': 256,\n",
       "  'num_agent_steps_trained': 256,\n",
       "  'last_target_update_ts': 1500,\n",
       "  'num_target_updates': 1},\n",
       " 'done': False,\n",
       " 'episodes_total': 31,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'default',\n",
       " 'experiment_id': '65a3da4e246d491ab7d326afcfe74dd6',\n",
       " 'date': '2022-05-16_19-53-53',\n",
       " 'timestamp': 1652723633,\n",
       " 'time_this_iter_s': 11.418123960494995,\n",
       " 'time_total_s': 11.418123960494995,\n",
       " 'pid': 5864,\n",
       " 'hostname': 'macbook-frans.local',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'num_workers': 1,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'create_env_on_driver': False,\n",
       "  'rollout_fragment_length': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'lr': 0.0001,\n",
       "  'train_batch_size': 256,\n",
       "  'model': {'_use_default_native_models': False,\n",
       "   '_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': True,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1},\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'my_env',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {},\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'eager_max_retraces': 20,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "   'random_timesteps': 1000,\n",
       "   'ou_base_scale': 0.1,\n",
       "   'ou_theta': 0.15,\n",
       "   'ou_sigma': 0.2,\n",
       "   'initial_scale': 1.0,\n",
       "   'final_scale': 0.02,\n",
       "   'scale_timesteps': 10000},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'num_workers': 1,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 0.0001,\n",
       "   'train_batch_size': 256,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': False,\n",
       "    '_disable_action_flattening': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'my_env',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': None,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': False,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 0.02,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_duration': 10,\n",
       "   'evaluation_duration_unit': 'episodes',\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'always_attach_evaluation_results': False,\n",
       "   'keep_per_episode_custom_metrics': False,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'metrics_episode_collection_timeout_s': 180,\n",
       "   'metrics_num_episodes_for_smoothing': 100,\n",
       "   'min_time_s_per_reporting': 1,\n",
       "   'min_train_timesteps_per_reporting': None,\n",
       "   'min_sample_timesteps_per_reporting': 1000,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_config': {},\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.policy.policy_template.DDPGTorchPolicy'>, observation_space=Box([ -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.\n",
       "       -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.   0.   0.   0.   0.   0.   0.\n",
       "        0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
       "        0.   0. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300.\n",
       "      300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 400. 400. 400. 400.\n",
       "      400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400.\n",
       "      400. 400. 400. 400.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
       "       -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.], [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "        0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   10.   10.\n",
       "       10.   10.   10.   10.   10.   10.   10.   10.   10.   10.   10.   10.\n",
       "       10.   10.   10.   10.   10.   10.   10.   10.  300.  300.  300.  300.\n",
       "      300.  300.  300.  300.  300.  300.  300.  300.  300.  300.  300.  300.\n",
       "      300.  300.  300.  300.  300.  300.  400.  400.  400.  400.  400.  400.\n",
       "      400.  400.  400.  400.  400.  400.  400.  400.  400.  400.  400.  400.\n",
       "      400.  400.  400.  400.    1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5\n",
       "        1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5\n",
       "        1.5   1.5], (110,), float64), action_space=Box([ -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.\n",
       "       -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5. 300. 300. 300. 300. 300. 300.\n",
       "      300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300.\n",
       "      300. 300.], [ 10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.\n",
       "       10.  10.  10.  10.  10.  10.  10.  10. 400. 400. 400. 400. 400. 400.\n",
       "      400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400.\n",
       "      400. 400.], (44,), float64), config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   '_disable_execution_plan_api': False,\n",
       "   'disable_env_checking': False,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'evaluation_num_episodes': -1,\n",
       "   'metrics_smoothing_episodes': -1,\n",
       "   'timesteps_per_iteration': 1000,\n",
       "   'min_iter_time_s': -1,\n",
       "   'collect_metrics_timeout': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.2,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [400, 300],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [400, 300],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': -1,\n",
       "   'replay_buffer_config': {'type': 'MultiAgentReplayBuffer',\n",
       "    'capacity': 50000},\n",
       "   'store_buffer_in_checkpoints': False,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.001,\n",
       "   'actor_lr': 0.001,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'always_attach_evaluation_results': False,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'sample_async': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'metrics_episode_collection_timeout_s': 180,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_reporting': 1,\n",
       "  'min_train_timesteps_per_reporting': None,\n",
       "  'min_sample_timesteps_per_reporting': 1000,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'input': 'sampler',\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.policy.policy_template.DDPGTorchPolicy'>, observation_space=Box([ -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.\n",
       "      -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.   0.   0.   0.   0.   0.   0.\n",
       "       0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
       "       0.   0. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300.\n",
       "     300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 400. 400. 400. 400.\n",
       "     400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400.\n",
       "     400. 400. 400. 400.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
       "      -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.], [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "       0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   10.   10.\n",
       "      10.   10.   10.   10.   10.   10.   10.   10.   10.   10.   10.   10.\n",
       "      10.   10.   10.   10.   10.   10.   10.   10.  300.  300.  300.  300.\n",
       "     300.  300.  300.  300.  300.  300.  300.  300.  300.  300.  300.  300.\n",
       "     300.  300.  300.  300.  300.  300.  400.  400.  400.  400.  400.  400.\n",
       "     400.  400.  400.  400.  400.  400.  400.  400.  400.  400.  400.  400.\n",
       "     400.  400.  400.  400.    1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5\n",
       "       1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5\n",
       "       1.5   1.5], (110,), float64), action_space=Box([ -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.\n",
       "      -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5. 300. 300. 300. 300. 300. 300.\n",
       "     300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300.\n",
       "     300. 300.], [ 10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.\n",
       "      10.  10.  10.  10.  10.  10.  10.  10. 400. 400. 400. 400. 400. 400.\n",
       "     400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400.\n",
       "     400. 400.], (44,), float64), config={})},\n",
       "   'policy_map_capacity': 100,\n",
       "   'policy_map_cache': None,\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent',\n",
       "   'count_steps_by': 'env_steps'},\n",
       "  'logger_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_execution_plan_api': False,\n",
       "  'disable_env_checking': False,\n",
       "  'simple_optimizer': False,\n",
       "  'monitor': -1,\n",
       "  'evaluation_num_episodes': -1,\n",
       "  'metrics_smoothing_episodes': -1,\n",
       "  'timesteps_per_iteration': 1000,\n",
       "  'min_iter_time_s': -1,\n",
       "  'collect_metrics_timeout': -1,\n",
       "  'twin_q': False,\n",
       "  'policy_delay': 1,\n",
       "  'smooth_target_policy': False,\n",
       "  'target_noise': 0.2,\n",
       "  'target_noise_clip': 0.5,\n",
       "  'use_state_preprocessor': False,\n",
       "  'actor_hiddens': [400, 300],\n",
       "  'actor_hidden_activation': 'relu',\n",
       "  'critic_hiddens': [400, 300],\n",
       "  'critic_hidden_activation': 'relu',\n",
       "  'n_step': 1,\n",
       "  'buffer_size': -1,\n",
       "  'replay_buffer_config': {'type': 'MultiAgentReplayBuffer',\n",
       "   'capacity': 50000},\n",
       "  'store_buffer_in_checkpoints': False,\n",
       "  'prioritized_replay': True,\n",
       "  'prioritized_replay_alpha': 0.6,\n",
       "  'prioritized_replay_beta': 0.4,\n",
       "  'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "  'final_prioritized_replay_beta': 0.4,\n",
       "  'prioritized_replay_eps': 1e-06,\n",
       "  'training_intensity': None,\n",
       "  'critic_lr': 0.001,\n",
       "  'actor_lr': 0.001,\n",
       "  'target_network_update_freq': 0,\n",
       "  'tau': 0.002,\n",
       "  'use_huber': False,\n",
       "  'huber_threshold': 1.0,\n",
       "  'l2_reg': 1e-06,\n",
       "  'grad_clip': None,\n",
       "  'learning_starts': 1500,\n",
       "  'worker_side_prioritization': False},\n",
       " 'time_since_restore': 11.418123960494995,\n",
       " 'timesteps_since_restore': 256,\n",
       " 'iterations_since_restore': 1,\n",
       " 'warmup_time': 158.4615650177002,\n",
       " 'perf': {'cpu_util_percent': 46.36470588235294,\n",
       "  'ram_util_percent': 58.923529411764704}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = ddpg.DDPGTrainer(\n",
    "    env=\"my_env\",\n",
    "    # Stopping condition\n",
    "    # stop={\"episode_reward_mean\":200},\n",
    "\n",
    "    # Config\n",
    "    # The default DDPG specific config is used with required \n",
    "    # Options for the config are in the default DDPG config: \n",
    "    # https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ddpg\n",
    "    config={\n",
    "        \"env\": \"my_env\",\n",
    "        \"framework\": \"torch\",\n",
    "        \"num_gpus\":0,\n",
    "        \"num_workers\":1,\n",
    "    },\n",
    "    # checkpoint_freq=1\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# trainer = ppo.PPOTrainer(env=\"my_env\", config={\n",
    "#     \"env_config\": config,  # config to pass to env class\n",
    "#     \"framework\": \"torch\",\n",
    "# })\n",
    "\n",
    "# while True:\n",
    "#     print(trainer.train())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([ -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5.\n",
      "  -5.  -5.  -5.  -5.  -5.  -5.  -5.  -5. 300. 300. 300. 300. 300. 300.\n",
      " 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300. 300.\n",
      " 300. 300.], [ 10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.\n",
      "  10.  10.  10.  10.  10.  10.  10.  10. 400. 400. 400. 400. 400. 400.\n",
      " 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400. 400.\n",
      " 400. 400.], (44,), float64)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d7053eaf1f44e4ba09689f8d46ffe60bb595916505f14727b0e14a5d0bba04d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
